{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JkBKubyZ7na7"
   },
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"float: left; width: 50%;\">\n",
    "<img src=\"https://www.uoc.edu/portal/_resources/common/imatges/sala_de_premsa/noticies/2016/202-nova-marca-uoc.jpg\", align=\"left\" width=\"380\" height=\"120\">\n",
    "\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">M2.893 · Anàlisi de textos</p>\n",
    "<p style=\"margin: 0; text-align:right;\">Màster en Ciència de Dades Aplicada</p>\n",
    "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudis d'Informàtica, Multimèdia i Telecomunicacions</p>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"width:100%;\">&nbsp;</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmR4EFjtn8Z8"
   },
   "source": [
    "# PRA 2: Deep Learning per a l'anàlisi de textos\n",
    "\n",
    "En aquesta pràctica revisarem i aplicarem els coneixements apresos en el últims mòduls del curs. Treballarem els següents temes:\n",
    "\n",
    "1. **Traducció automàtica(TA)**: amb 'custom embeddings' i amb 'embeddings preentrenats'.\n",
    "2. **NER i NEL**: Entrenament de models de detecció d'entitats anomenades (NER), detecció i classificació.  Detección de entitats anomenades basant-nos en Wikidata aplicada a NER.\n",
    "\n",
    "També inclourem altres temes transversals treballats al llarg de l'assignatura."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9fjgWxUJK1kQ"
   },
   "source": [
    "#0 Connexió amb 'Google Drive'\n",
    "\n",
    "Aquesta secció realitza la connexió amb `drive` i estableix el directori arrel en el que s'emmagatzemem tots els recursos necessaris per a executar el notebook.\n",
    "\n",
    "El 'path' de treball s'emmagatzema a la variable `my_path_pra2`.\n",
    "\n",
    "**Estructura de directoris**\n",
    "\n",
    "S'estableix el directori arrel segons la variable `my_path_pra2`. En aquest directori s'emmagatzemaran els arxius i directoris necessaris per a l'execució del notebook. L'estructura i continguts són els següents:\n",
    "\n",
    "    * directori `TA` on s'emmagatzemen les dades i recursos per a realitzar la traducció automàtica; conté:\n",
    "      * glove.42B.300d.txt    # carregat per l'usuari.\n",
    "      * nld.txt      # carregat per l'usuari.\n",
    "      * directori `model` on s'emmagatzemen els *best model* de l'entrenament dels models de traducció automàtica:\n",
    "        * model_ta_en_de-g.keras    # 'best model' generat per l'entrenament de TA amb 'embeddings' preentrenats\n",
    "        * model_ta_en_de.keras      # 'best model' generat por l'entrenament de TA amb 'custom' embeddings.\n",
    "    * directori `NER` amb els arxius necessaris per a la pràctica NER:\n",
    "        * Directori `output_ner`   on s'hi trobaran els *model-best* y *model-last* entrenats per aquest notebook.\n",
    "        * config.cfg    # carregat per l'usuari.\n",
    "        * test.txt      # carregat per l'usuari.\n",
    "        * test.spacy    # Conversió de test.txt al format spacy\n",
    "        * train.txt     # carregat per l'usuari.\n",
    "        * train.spacy   # Conversió de train.txt al format spacy\n",
    "        * valid.txt     # carregat per l'usuari.\n",
    "        * valid.spacy   # Conversió de valid.txt al format spacy\n",
    "\n",
    "\n",
    "\n",
    "**Execució d'aquest notebook en un entorno no `Colab`.**\n",
    "\n",
    "Si no s'executa aquest notebook a Google Colab, substituir aquesta secció (*0. Connexió amb Google Drive*) per la corresponent a la configuració desitjada, tenint en compte que cal disposar d'una GPU amb, almenys, 15 GB de memòria RAM.\n",
    "\n",
    "**Execució d'aquest notebook en un entorno `Colab`.**\n",
    "\n",
    "Si s'executa aquest notebook a Colab, cal utilitzar al menys una GPU del tipus 'T4 GPU' o superior. Tenir en compte que si s'utilitza el servei gratuït de Colab, aquestes GPU no estan disponibles permanentment i, quan ho estan, només se'n pot disposar mentre duren les 'compute units' assignades a l'usuari o per límits de disponibilitat de GPUs de Google. Quan no hi ha disponibilitat, cal esperar a una nova assignació. Google no publica el mètode d'assignació o els [terminis de disposició](https://research.google.com/colaboratory/faq.html#usage-limits) de GPUs. Consulta a Colab (Opció de menú 'Runtime' >>>> 'View resources') la disponibilitat en cada moment de Compute Units i GPUs.\n",
    "\n",
    "En tots els casos, aquest notebook pressuposa l'estructura de directoris de treball descrita."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b0SAvIANW9Js"
   },
   "source": [
    "# 1 Traducció Automàtica (TA) (7 puntos)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pugvMCkoUa8-"
   },
   "source": [
    "En aquesta primera part de la pràctica es demana resoldre els exercicis usant la llibreria **KERAS**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T5OjUVQ5W9Jv"
   },
   "source": [
    "## 1.1 TA amb Custom Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0r9X2PrW9Jv"
   },
   "source": [
    "L'objectiu d'aquest apartat és entrenar un model de traducció automàtica entre dos idiomes escollits a partir de l'arxiu escollit, seguint els mateixos passos que el notebook de *Machine Translation*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rf18DFPhW9Jw"
   },
   "source": [
    "**Implementació:** Seguint els passos treballats en el notebook de traducció automàtica, implementar i entrenar un model de traducció automàtica, de l'**idioma origen** a l'**idioma destí**.\n",
    "* En aquest notebook d'exemple s'utilitza com a dimensión de la capa d'embedding (*embedding_vec_length*) el valor de 200. Més endavant, es variarà aquesta dimensió i es revisaran els resultats.\n",
    "* La longitud de seqüència es determinant en la duració del temps de procés i en el consumo de memoria del processador durant l'entrenament. A Google Colab es pot cancel·lar el programa si es consumeix tota la memòria disponible. Provar amb diferents longituds, des de 4 (molt reduïda i, per tant, produirà una qualitat baixa de traducció), fins a longituds més grans (8, 12, 16).\n",
    "\n",
    "* Finalment, es mostrarà com aplicar el model entrenat amb exemples de l'arxiu de dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxvOKWl-Bv_R"
   },
   "source": [
    "### 1.1.1 Preparació de dades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ah2HeuK5W9Jx"
   },
   "source": [
    "* Primer prepararem les dades seleccionades (tingueu en compte que l'*idioma origen* ha de ser **anglès**), per a que es puguin llegir correctament i tinguin el format adequat per a la pràctica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oOwwao4NBv_R"
   },
   "source": [
    "**a. Carreguem les dades des de la font seleccionada.**\n",
    "\n",
    "*Sortides esperades:*\n",
    "- Longitud del dataset.\n",
    "- Almenys 3 files de dades que mostrin els textos de l'idioma origen i la respectiva traducció."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T08:50:48.119133Z",
     "iopub.status.busy": "2025-05-29T08:50:48.118823Z",
     "iopub.status.idle": "2025-05-29T08:50:48.261652Z",
     "shell.execute_reply": "2025-05-29T08:50:48.261019Z",
     "shell.execute_reply.started": "2025-05-29T08:50:48.119113Z"
    },
    "id": "oVYldy9c7nbG",
    "outputId": "130f5b9d-61aa-4a77-cf78-0491f871e586"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud del dataset: 52696\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENGLISH</th>\n",
       "      <th>CATALAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>With all the legitimate concerns about AIDS and avian flu -- and we'll hear about that from the brilliant Dr. Brilliant later today -- I want to talk about the other pandemic, which is cardiovascular disease, diabetes, hypertension -- all of which are completely preventable for at least 95 percent of people just by changing diet and lifestyle.</td>\n",
       "      <td>Amb tot el respecte per la SIDA i la grip aviar —que avui en parlarà el brillant Dr Brilliant— vull parlar d'una altra pandèmia, les malalties cardiovasculars, la diabetis, la hipertensió... Totes es poden evitar en el 95 % dels casos canviant la dieta i l'estil de vida.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>And what's happening is that there's a globalization of illness occurring, that people are starting to eat like us, and live like us, and die like us. And in one generation, for example, Asia's gone from having one of the lowest rates of heart disease and obesity and diabetes to one of the highest. And in Africa, cardiovascular disease equals the HIV and AIDS deaths in most countries.</td>\n",
       "      <td>Existeix una 'globalització de malalties'. La gent menja, viu i mor com nosaltres, els americans. En una generació, l'Àsia ha pujat d'entre les menors taxes de malalties del cor, obesitat i diabetis, a una de les majors taxes del món. A l'Àfrica, les malalties cardiovasculars, igualen les morts per VIH i SIDA en molts països.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So there's a critical window of opportunity we have to make an important difference that can affect the lives of literally millions of people, and practice preventive medicine on a global scale.</td>\n",
       "      <td>Tenim un marge crític d'oportunitat per fer un canvi prou important, que afecti la vida de milions de gent i de practicar la medicina preventiva a escala mundial.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                               ENGLISH  \\\n",
       "0                                            With all the legitimate concerns about AIDS and avian flu -- and we'll hear about that from the brilliant Dr. Brilliant later today -- I want to talk about the other pandemic, which is cardiovascular disease, diabetes, hypertension -- all of which are completely preventable for at least 95 percent of people just by changing diet and lifestyle.   \n",
       "1  And what's happening is that there's a globalization of illness occurring, that people are starting to eat like us, and live like us, and die like us. And in one generation, for example, Asia's gone from having one of the lowest rates of heart disease and obesity and diabetes to one of the highest. And in Africa, cardiovascular disease equals the HIV and AIDS deaths in most countries.   \n",
       "2                                                                                                                                                                                                   So there's a critical window of opportunity we have to make an important difference that can affect the lives of literally millions of people, and practice preventive medicine on a global scale.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                   CATALAN  \n",
       "0                                                          Amb tot el respecte per la SIDA i la grip aviar —que avui en parlarà el brillant Dr Brilliant— vull parlar d'una altra pandèmia, les malalties cardiovasculars, la diabetis, la hipertensió... Totes es poden evitar en el 95 % dels casos canviant la dieta i l'estil de vida.  \n",
       "1  Existeix una 'globalització de malalties'. La gent menja, viu i mor com nosaltres, els americans. En una generació, l'Àsia ha pujat d'entre les menors taxes de malalties del cor, obesitat i diabetis, a una de les majors taxes del món. A l'Àfrica, les malalties cardiovasculars, igualen les morts per VIH i SIDA en molts països.  \n",
       "2                                                                                                                                                                       Tenim un marge crític d'oportunitat per fer un canvi prou important, que afecti la vida de milions de gent i de practicar la medicina preventiva a escala mundial.  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#############################################\n",
    "# SOLUCIÓ                                   #\n",
    "#############################################\n",
    "\n",
    "# Ho fem per veure tot el text\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Rutes\n",
    "path_en = \"/kaggle/input/dataset-traduccio-v2/dataset_pr2_traduccio/ca-en.txt/TED2020.ca-en.en\"\n",
    "path_ca = \"/kaggle/input/dataset-traduccio-v2/dataset_pr2_traduccio/ca-en.txt/TED2020.ca-en.ca\"\n",
    "\n",
    "with open(path_en, 'r', encoding='utf-8') as f_en, \\\n",
    "     open(path_ca, 'r', encoding='utf-8') as f_ca:\n",
    "    en_lines = [l.strip() for l in f_en]\n",
    "    ca_lines = [l.strip() for l in f_ca]\n",
    "\n",
    "# Mirem si tenen la mateixa dimensió (hauria de ser així)\n",
    "assert len(en_lines) == len(ca_lines), \"Llistes de diferent dimensió\"\n",
    "print(f\"Longitud del dataset: {len(en_lines)}\")\n",
    "\n",
    "# Llegim les línies\n",
    "with open(path_en, 'r', encoding='utf-8') as f_en, open(path_ca, 'r', encoding='utf-8') as f_ca:\n",
    "    en_lines = [line.strip() for line in f_en]\n",
    "    ca_lines = [line.strip() for line in f_ca]\n",
    "\n",
    "# Creem un dataframe\n",
    "df = pd.DataFrame({\n",
    "    \"ENGLISH\": en_lines,\n",
    "    \"CATALAN\": ca_lines\n",
    "})\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GPKlZ9fPXVFl"
   },
   "source": [
    "**b. Preprocessar les dades, per a eliminar la puntuació i convertir a minúscula.**\n",
    "\n",
    "*Sortida esperada:* Hauràs de mostrar un conjunt de datos normalitzat. Per exemple, la frase en l'idioma origen, \"Hello, world!\" es transformarà en \"hello world\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T08:50:51.644814Z",
     "iopub.status.busy": "2025-05-29T08:50:51.644157Z",
     "iopub.status.idle": "2025-05-29T08:50:53.576870Z",
     "shell.execute_reply": "2025-05-29T08:50:53.575737Z",
     "shell.execute_reply.started": "2025-05-29T08:50:51.644791Z"
    },
    "id": "JgIsoQqS7nbH",
    "outputId": "84b9b38e-99be-476c-c9e7-58815d98cd5a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENGLISH_norm</th>\n",
       "      <th>CATALAN_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>with all the legitimate concerns about aids and avian flu  and well hear about that from the brilliant dr brilliant later today  i want to talk about the other pandemic which is cardiovascular disease diabetes hypertension  all of which are completely preventable for at least 95 percent of people just by changing diet and lifestyle</td>\n",
       "      <td>amb tot el respecte per la sida i la grip aviar que avui en parlarà el brillant dr brilliant vull parlar duna altra pandèmia les malalties cardiovasculars la diabetis la hipertensió totes es poden evitar en el 95  dels casos canviant la dieta i lestil de vida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and whats happening is that theres a globalization of illness occurring that people are starting to eat like us and live like us and die like us and in one generation for example asias gone from having one of the lowest rates of heart disease and obesity and diabetes to one of the highest and in africa cardiovascular disease equals the hiv and aids deaths in most countries</td>\n",
       "      <td>existeix una globalització de malalties la gent menja viu i mor com nosaltres els americans en una generació làsia ha pujat dentre les menors taxes de malalties del cor obesitat i diabetis a una de les majors taxes del món a làfrica les malalties cardiovasculars igualen les morts per vih i sida en molts països</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>so theres a critical window of opportunity we have to make an important difference that can affect the lives of literally millions of people and practice preventive medicine on a global scale</td>\n",
       "      <td>tenim un marge crític doportunitat per fer un canvi prou important que afecti la vida de milions de gent i de practicar la medicina preventiva a escala mundial</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                              ENGLISH_norm  \\\n",
       "0                                            with all the legitimate concerns about aids and avian flu  and well hear about that from the brilliant dr brilliant later today  i want to talk about the other pandemic which is cardiovascular disease diabetes hypertension  all of which are completely preventable for at least 95 percent of people just by changing diet and lifestyle   \n",
       "1  and whats happening is that theres a globalization of illness occurring that people are starting to eat like us and live like us and die like us and in one generation for example asias gone from having one of the lowest rates of heart disease and obesity and diabetes to one of the highest and in africa cardiovascular disease equals the hiv and aids deaths in most countries   \n",
       "2                                                                                                                                                                                          so theres a critical window of opportunity we have to make an important difference that can affect the lives of literally millions of people and practice preventive medicine on a global scale   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                              CATALAN_norm  \n",
       "0                                                      amb tot el respecte per la sida i la grip aviar que avui en parlarà el brillant dr brilliant vull parlar duna altra pandèmia les malalties cardiovasculars la diabetis la hipertensió totes es poden evitar en el 95  dels casos canviant la dieta i lestil de vida  \n",
       "1  existeix una globalització de malalties la gent menja viu i mor com nosaltres els americans en una generació làsia ha pujat dentre les menors taxes de malalties del cor obesitat i diabetis a una de les majors taxes del món a làfrica les malalties cardiovasculars igualen les morts per vih i sida en molts països  \n",
       "2                                                                                                                                                          tenim un marge crític doportunitat per fer un canvi prou important que afecti la vida de milions de gent i de practicar la medicina preventiva a escala mundial  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "#############################################\n",
    "# SOLUCIÓ                                  #\n",
    "#############################################\n",
    "\n",
    "# Preprocessem les dades\n",
    "def normalize(text: str) -> str:\n",
    "    # Conservem només caràcters que no siguin de puntuació\n",
    "    filtered = ''.join(\n",
    "        ch for ch in text\n",
    "        if not unicodedata.category(ch).startswith(\"P\")\n",
    "    )\n",
    "    # Minúscules i eliminem espais\n",
    "    return filtered.lower().strip()\n",
    "\n",
    "df['ENGLISH_norm'] = df['ENGLISH'].apply(normalize)\n",
    "df['CATALAN_norm'] = df['CATALAN'].apply(normalize)\n",
    "\n",
    "df[['ENGLISH_norm', 'CATALAN_norm']].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vNNWw9e1XlnA"
   },
   "source": [
    "**c. Per a tenir una idea de la mida dels textos a analitzar, en funció de la quantitat de paraules, visualitzem les dades resultants amb un histograma.**\n",
    "\n",
    "*Sortida esperada:* Dos histogramas que mostrin la quantitat de tokens dels textos del corpus, un per als vectors de l'idioma origen i l'altre per als de destí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T11:50:08.423019Z",
     "iopub.status.busy": "2025-05-27T11:50:08.422336Z",
     "iopub.status.idle": "2025-05-27T11:50:08.919326Z",
     "shell.execute_reply": "2025-05-27T11:50:08.918662Z",
     "shell.execute_reply.started": "2025-05-27T11:50:08.422995Z"
    },
    "id": "d8LfflHB7nbI",
    "outputId": "06b6f272-b1fd-4730-a3a4-692b899caa08"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#############################################\n",
    "# SOLUCIÓ                                  #\n",
    "#############################################\n",
    "\n",
    "# Visualitzem les dades (idioma origen)\n",
    "df['len_en'] = df['ENGLISH_norm'].str.split().map(len)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(df['len_en'], bins=50)\n",
    "plt.title('Distribució de tokens per frase – Anglès')\n",
    "plt.xlabel('Nombre de tokens')\n",
    "plt.ylabel('Freqüència')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T11:50:11.979763Z",
     "iopub.status.busy": "2025-05-27T11:50:11.979477Z",
     "iopub.status.idle": "2025-05-27T11:50:12.411087Z",
     "shell.execute_reply": "2025-05-27T11:50:12.410430Z",
     "shell.execute_reply.started": "2025-05-27T11:50:11.979720Z"
    },
    "id": "QyM_eI7U7nbI",
    "outputId": "e2d2cca3-b19a-4f61-e99a-219f8d0fb873"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAHHCAYAAACiOWx7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABXYklEQVR4nO3deVhUZf8/8PewzACyubElAuGK4IaFuCsEGppbmTuaa2GpmAuVitoTpuFSbvVUoKWPW2quKIJLCpqguEOKIposbjAiynr//ujL+TkCekR0Bnq/rmuuOPe5z30+Zw40b882CiGEABERERE9lZ62CyAiIiKqChiaiIiIiGRgaCIiIiKSgaGJiIiISAaGJiIiIiIZGJqIiIiIZGBoIiIiIpKBoYmIiIhIBoYmon+RvLw8fPXVV9i7d6+2SyGipzhz5gyCg4Nx8+ZNbZdCj2FoomopODgYCoXilayrS5cu6NKlizR98OBBKBQKbN68+ZWs/3EKhQLBwcHlzg8MDMTatWvh4eFR4XWkpKRAoVAgPDy8wmNUtpL9ffv2bW2XUqX88ssvaNKkCQwNDWFpaantcv61RowYAUdHR402V1dXnDp1CoMHD0ZRUZF2CqNSGJpI54WHh0OhUEgvIyMj2NnZwdfXF99++y3u379fKeu5efMmgoODkZCQUCnj6ZqNGzdi27Zt2LNnj059QObm5iI4OBgHDx7Udin/KomJiRgxYgScnZ3x3//+Fz/88IO2S3olioqKEBYWhi5duqBWrVpQqVRwdHTEyJEjERcX99zjXbhwAcHBwUhJSanUOvX09PC///0PDx8+xOzZsyt1bKo4A20XQCTX3Llz4eTkhIKCAqSnp+PgwYOYNGkSFi1ahO3bt6N58+ZS3y+++AIzZsx4rvFv3ryJOXPmwNHRES1btpS93L59+55rPS/Tw4cPYWBQ+s9aCIEbN25gz549qF+/vhYqK19ubi7mzJkDABpH7OjlOnjwIIqLi7F06VI0aNBA2+W8Eg8fPkS/fv0QERGBTp064bPPPkOtWrWQkpKCjRs3YvXq1UhNTUW9evVkj3nhwgXMmTMHXbp0KXW06EWZmJhgx44d+P777/HgwQPUqFGjUsen58fQRFVGjx490KZNG2k6KCgI0dHR6NmzJ9555x1cvHgRxsbGAAADA4Myw0Nlys3NhYmJCZRK5Utdz/MwMjIqs12hUCAwMPAVV0PaJITAo0ePpL+JJ2VmZgLAM486PmucqmTq1KmIiIjA4sWLMWnSJI15s2fPxuLFi7VT2FNYWVlh5syZ2i6D/g9Pz1GV1q1bN8ycORPXrl3Dr7/+KrWXdU1TZGQkOnToAEtLS5iamqJx48b47LPPAPzzr+433ngDADBy5EjpVGDJdTtdunSBq6sr4uPj0alTJ5iYmEjLPnlNU4mioiJ89tlnsLGxQY0aNfDOO+/g+vXrGn0cHR0xYsSIUsuWNeajR48QHByMRo0awcjICLa2tujXrx+Sk5OlPmVd03Tq1Cn06NED5ubmMDU1hZeXF44dO1bue/q4rKwsjBgxAhYWFrC0tIS/vz+ysrLK7JuYmIh3330XtWrVgpGREdq0aYPt27c/dfyUlBTUrVsXADBnzhzpfX98G6Kjo9GxY0fUqFEDlpaW6N27Ny5evPjM2q9du4YGDRrA1dUVGRkZ0vZMmjQJ9vb2UKlUaNCgAb7++msUFxdr1KRQKPDNN9/ghx9+gLOzM1QqFd544w2cOHFCYx3p6ekYOXIk6tWrB5VKBVtbW/Tu3fuZp2pGjBgBU1NTXLlyBb6+vqhRowbs7Owwd+5cCCE0+hYXF2PJkiVo1qwZjIyMYG1tjXHjxuHevXsa/RwdHdGzZ0/s3bsXbdq0gbGxMb7//vsy1+/o6Cid8qlbt67Ge/60ccLCwtCtWzdYWVlBpVLBxcUFK1euLDV+XFwcfH19UadOHRgbG8PJyQkffPBBhbarsty4cQPff/893nrrrVKBCQD09fXx6aefSkeZrl27ho8++giNGzeGsbExateujffee09j34aHh+O9994DAHTt2lX6/S051fz777/Dz88PdnZ2UKlUcHZ2xrx582Rdo/TNN9+gXbt2qF27NoyNjeHu7q6V6yRJE480UZU3bNgwfPbZZ9i3bx/GjBlTZp/z58+jZ8+eaN68OebOnQuVSoXLly/j6NGjAICmTZti7ty5mDVrFsaOHYuOHTsCANq1ayeNcefOHfTo0QMDBw7E0KFDYW1t/dS6/vOf/0ChUGD69OnIzMzEkiVL4O3tjYSEhOf+V3tRURF69uyJqKgoDBw4EBMnTsT9+/cRGRmJc+fOwdnZudzt7tixI8zNzTFt2jQYGhri+++/R5cuXXDo0KGnXhAuhEDv3r1x5MgRjB8/Hk2bNsXWrVvh7+9f5nrat2+P1157DTNmzECNGjWwceNG9OnTB7/99hv69u1b5jrq1q2LlStX4sMPP0Tfvn3Rr18/AJBOte7fvx89evTA66+/juDgYDx8+BDfffcd2rdvj5MnT5Z7OiQ5ORndunVDrVq1EBkZiTp16iA3NxedO3fG33//jXHjxqF+/fqIiYlBUFAQ0tLSsGTJEo0x1q1bh/v372PcuHFQKBRYsGAB+vXrhytXrsDQ0BAA0L9/f5w/fx4ff/wxHB0dkZmZicjISKSmpj7zVE1RURG6d++Otm3bYsGCBYiIiMDs2bNRWFiIuXPnSv3GjRuH8PBwjBw5Ep988gmuXr2KZcuW4dSpUzh69KhUCwAkJSVh0KBBGDduHMaMGYPGjRuXue4lS5ZgzZo12Lp1K1auXAlTU1ON09vljbNy5Uo0a9YM77zzDgwMDLBjxw589NFHKC4uRkBAAIB/jmD5+Pigbt26mDFjBiwtLZGSkoItW7Zo1PA821UZ9uzZg8LCQgwbNkxW/xMnTiAmJgYDBw5EvXr1kJKSgpUrV6JLly64cOECTExM0KlTJ3zyySf49ttv8dlnn6Fp06YAIP03PDwcpqamCAwMhKmpKaKjozFr1iyo1WosXLjwqetfunQp3nnnHQwZMgT5+flYv3493nvvPezcuRN+fn4v9mZQxQkiHRcWFiYAiBMnTpTbx8LCQrRq1Uqanj17tnj813vx4sUCgLh161a5Y5w4cUIAEGFhYaXmde7cWQAQq1atKnNe586dpekDBw4IAOK1114TarVaat+4caMAIJYuXSq1OTg4CH9//2eO+fPPPwsAYtGiRaX6FhcXSz8DELNnz5am+/TpI5RKpUhOTpbabt68KczMzESnTp1KjfW4bdu2CQBiwYIFUlthYaHo2LFjqffJy8tLuLm5iUePHmnU1a5dO9GwYcOnrufWrVul6i7RsmVLYWVlJe7cuSO1nT59Wujp6Ynhw4dLbSX7+9atW+LixYvCzs5OvPHGG+Lu3btSn3nz5okaNWqIv/76S2MdM2bMEPr6+iI1NVUIIcTVq1cFAFG7dm2N5X///XcBQOzYsUMIIcS9e/cEALFw4cKnbl9Z/P39BQDx8ccfS23FxcXCz89PKJVK6ff0jz/+EADE2rVrNZaPiIgo1e7g4CAAiIiICFk1PP6ePe5p4+Tm5pZq8/X1Fa+//ro0vXXr1mf+vT7PdlWWyZMnCwDi1KlTsvqXta2xsbECgFizZo3UtmnTJgFAHDhwQNYY48aNEyYmJhp/K/7+/sLBweGpy+bn5wtXV1fRrVs3WfXTy8HTc1QtmJqaPvUuupLrNn7//XeNUzHPQ6VSYeTIkbL7Dx8+HGZmZtL0u+++C1tbW+zevfu51/3bb7+hTp06+Pjjj0vNK+/RCkVFRdi3bx/69OmD119/XWq3tbXF4MGDceTIEajV6nLXuXv3bhgYGODDDz+U2vT19UvVcPfuXURHR2PAgAG4f/8+bt++jdu3b+POnTvw9fXFpUuX8Pfffz/vJiMtLQ0JCQkYMWIEatWqJbU3b94cb731Vpnv47lz59C5c2c4Ojpi//79qFmzpjRv06ZN6NixI2rWrCnVePv2bXh7e6OoqAiHDx/WGOv999/XWL7k6OOVK1cAAMbGxlAqlTh48GCFTylNmDBB+lmhUGDChAnIz8/H/v37pZotLCzw1ltvadTs7u4OU1NTHDhwQGM8Jycn+Pr6VqgWOeM8foQ0Ozsbt2/fRufOnXHlyhVkZ2cD+P9/azt37kRBQUGZ4z/vdlWGkt/1x/8mn+bxbS0oKMCdO3fQoEEDWFpa4uTJk889RsnfRseOHZGbm4vExETZy967dw/Z2dno2LGj7HXTy8HTc1Qt5OTkwMrKqtz577//Pn788UeMHj0aM2bMgJeXF/r164d3330Xenry/u3w2muvPddF3w0bNtSYVigUaNCgQYVuTU5OTkbjxo2f6+L2W7duITc3t8xTNE2bNkVxcTGuX7+OZs2albn8tWvXYGtrC1NTU432J8e7fPkyhBCYOXNmuResZmZm4rXXXpNde8n6y1pfSf179+4tdUdRr169YG1tjb1795aq+9KlSzhz5ox0DVVZNT7uybsMSwJUSUBSqVT4+uuvMWXKFFhbW6Nt27bo2bMnhg8fDhsbm2dun56enkaYBYBGjRoBgPQ7cunSJWRnZ5f7u/1kzU5OTs9crxzljXP06FHMnj0bsbGxyM3N1ZiXnZ0NCwsLdO7cGf3798ecOXOwePFidOnSBX369MHgwYOhUqkAPP92Pe7hw4dSQHuShYVFuae+zc3NAUD2I0oePnyIkJAQhIWF4e+//9a41qy89T/p/Pnz+OKLLxAdHV3qHyjPGmPnzp348ssvkZCQgLy8PKn9VT1/jsrG0ERV3o0bN5Cdnf3U26aNjY1x+PBhHDhwALt27UJERAQ2bNiAbt26Yd++fdDX13/mel7G3UNPO0okpyZdUHLk7tNPPy33KMeruqW9f//+WL16NdauXYtx48ZpzCsuLsZbb72FadOmlblsSWApUd77//iH56RJk9CrVy9s27YNe/fuxcyZMxESEoLo6Gi0atXqBbfmn5qtrKywdu3aMuc/GQAr63e0rHGSk5Ph5eWFJk2aYNGiRbC3t4dSqcTu3buxePFi6feg5MGux44dw44dO7B371588MEHCA0NxbFjx2Bqavrc2/W4DRs2lHvENywsrMwbKwCgSZMmAICzZ8/KeqTIxx9/jLCwMEyaNAmenp6wsLCAQqHAwIEDZR2tzsrKQufOnWFubo65c+fC2dkZRkZGOHnyJKZPn/7UMf744w+888476NSpE1asWAFbW1sYGhoiLCwM69ate+a66eVhaKIq75dffgGAZ56W0NPTg5eXF7y8vLBo0SJ89dVX+Pzzz3HgwAF4e3tX+r/gLl26pDEthMDly5c1LritWbNmmXejXbt2TeMohLOzM44fP46CggLZF8jWrVsXJiYmSEpKKjUvMTERenp6sLe3L3d5BwcHREVFIScnR+OozZPjldRpaGgIb29vWbU9rrz33cHBocz1ldRfp06dUs+tWbhwIQwMDPDRRx/BzMwMgwcPluY5OzsjJyenQjU+jbOzM6ZMmYIpU6bg0qVLaNmyJUJDQzXu5ixLcXExrly5ohHW/vrrLwCQLiJ3dnbG/v370b59e63f8r9jxw7k5eVh+/btGkfhyjuV1rZtW7Rt2xb/+c9/sG7dOgwZMgTr16/H6NGjX2i7fH19ERkZWea88o6aAv88skRfXx+//vqrrIvBN2/eDH9/f4SGhkptjx49KvX3Wt7v78GDB3Hnzh1s2bIFnTp1ktqvXr36zHX/9ttvMDIywt69e6Wjc8A/oZC0i9c0UZUWHR2NefPmwcnJCUOGDCm33927d0u1lfxrs+TQd8kHcHm31D+vNWvWaJwK2Lx5M9LS0tCjRw+pzdnZGceOHUN+fr7UtnPnzlKPJujfvz9u376NZcuWlVqPeOIW9RL6+vrw8fHB77//rnFKMCMjA+vWrUOHDh2kUxZlefvtt1FYWKhxS3lRURG+++47jX5WVlbo0qULvv/+e6SlpZUa59atW+WuA/jnAX5A6ffd1tYWLVu2xOrVqzXmnTt3Dvv27cPbb79daiyFQoEffvgB7777Lvz9/TUeeTBgwADExsaW+b17WVlZKCwsfGqdT8rNzcWjR4802pydnWFmZqZxOuVpHt+fQggsW7YMhoaG8PLykmouKirCvHnzSi1bWFhYab+rcpQceXvyNNWTH+T37t0r9Tv55N/ai2yXra0tvL29y3zZ2tqWu5y9vT3GjBmDffv2lfodBv4JsaGhobhx44a0vU9ux3fffVfqcQHl/X+jrPcrPz8fK1asKLfGx5dVKBQa60pJScG2bdueuSy9XDzSRFXGnj17kJiYiMLCQmRkZCA6OhqRkZFwcHDA9u3by32wI/DP08QPHz4MPz8/ODg4IDMzEytWrEC9evXQoUMHAP984FlaWmLVqlUwMzNDjRo14OHhUeHrRGrVqoUOHTpg5MiRyMjIwJIlS9CgQQONxyKMHj0amzdvRvfu3TFgwAAkJyfj119/LfUIgeHDh2PNmjUIDAzEn3/+iY4dO+LBgwfYv38/PvroI/Tu3bvMGr788kvp+VQfffQRDAwM8P333yMvLw8LFix4av29evVC+/btMWPGDKSkpMDFxQVbtmwp81qM5cuXo0OHDnBzc8OYMWPw+uuvIyMjA7Gxsbhx4wZOnz5d7nqMjY3h4uKCDRs2oFGjRqhVqxZcXV3h6uqKhQsXokePHvD09MSoUaOkRw5YWFiU+x17enp6+PXXX9GnTx8MGDAAu3fvRrdu3TB16lRs374dPXv2xIgRI+Du7o4HDx7g7Nmz2Lx5M1JSUlCnTp2nvieP++uvv+Dl5YUBAwbAxcUFBgYG2Lp1KzIyMjBw4MBnLm9kZISIiAj4+/vDw8MDe/bswa5du/DZZ59Jp6c6d+6McePGISQkBAkJCfDx8YGhoSEuXbqETZs2YenSpXj33Xdl1/wifHx8oFQq0atXL4wbNw45OTn473//CysrK42wvHr1aqxYsQJ9+/aFs7Mz7t+/j//+978wNzeXgq62tis0NBTJycn45JNPsGXLFvTs2RM1a9ZEamoqNm3ahMTERGnf9ezZE7/88gssLCzg4uKC2NhY7N+/H7Vr19YYs2XLltDX18fXX3+N7OxsqFQqdOvWDe3atUPNmjXh7++PTz75BAqFAr/88ku5/8h5nJ+fHxYtWoTu3btj8ODByMzMxPLly9GgQQOcOXOm0t8Xeg5aumuPSLaSRw6UvJRKpbCxsRFvvfWWWLp0qcZt/SWefORAVFSU6N27t7CzsxNKpVLY2dmJQYMGlbr9/PfffxcuLi7CwMBA47b6zp07i2bNmpVZX3mPHPjf//4ngoKChJWVlTA2NhZ+fn7i2rVrpZYPDQ0Vr732mlCpVKJ9+/YiLi6u1JhC/HML8ueffy6cnJyEoaGhsLGxEe+++67G4wRQxq37J0+eFL6+vsLU1FSYmJiIrl27ipiYmDK35Ul37twRw4YNE+bm5sLCwkIMGzZMnDp1qsxHMyQnJ4vhw4cLGxsbYWhoKF577TXRs2dPsXnz5meuJyYmRri7uwulUllqG/bv3y/at28vjI2Nhbm5uejVq5e4cOGCxvJl3T6fm5srOnfuLExNTcWxY8eEEELcv39fBAUFiQYNGgilUinq1Kkj2rVrJ7755huRn58vhPj/jxwo61ECj9d2+/ZtERAQIJo0aSJq1KghLCwshIeHh9i4ceMzt9ff31/UqFFDJCcnCx8fH2FiYiKsra3F7NmzRVFRUan+P/zwg3B3dxfGxsbCzMxMuLm5iWnTpombN29KfRwcHISfn98z1/209+xZ42zfvl00b95cGBkZCUdHR/H1119Lj8O4evWqEOKf37dBgwaJ+vXrC5VKJaysrETPnj1FXFxchbarshUWFooff/xRdOzYUVhYWAhDQ0Ph4OAgRo4cqfE4gnv37omRI0eKOnXqCFNTU+Hr6ysSExPLfEzIf//7X/H6668LfX19jccPHD16VLRt21YYGxsLOzs7MW3aNLF3795Sjygo65EDP/30k2jYsKFQqVSiSZMmIiwsrNT/1+jVUwghI/YSEVGlGTFiBDZv3oycnBxtl0JEz4HXNBERERHJwNBEREREJANDExEREZEMvKaJiIiISAYeaSIiIiKSQauhKSQkBG+88QbMzMxgZWWFPn36lHr676NHjxAQEIDatWvD1NQU/fv3R0ZGhkaf1NRU+Pn5wcTEBFZWVpg6dWqpB9UdPHgQrVu3hkqlQoMGDRAeHl6qnuXLl8PR0RFGRkbw8PDAn3/+WenbTERERFWTVh9ueejQIQQEBOCNN95AYWEhPvvsM/j4+ODChQvSU1YnT56MXbt2Sd+KPWHCBPTr1w9Hjx4F8M8Tiv38/GBjY4OYmBikpaVh+PDhMDQ0xFdffQXgn8fW+/n5Yfz48Vi7di2ioqIwevRo2NraSl+9sWHDBgQGBmLVqlXw8PDAkiVL4Ovri6SkpKd+EezjiouLcfPmTZiZmfFLFYmIiKoIIQTu378POzu7p3+Ju1afEvWEzMxMAUAcOnRICCFEVlaWMDQ0FJs2bZL6XLx4UQAQsbGxQgghdu/eLfT09ER6errUZ+XKlcLc3Fzk5eUJIYSYNm1aqQcTvv/++8LX11eafvPNN0VAQIA0XVRUJOzs7ERISIjs+q9fv67xEEa++OKLL7744qvqvK5fv/7Uz3md+hqVkq9nqFWrFgAgPj4eBQUFGl+w2aRJE9SvXx+xsbFo27YtYmNj4ebmBmtra6mPr68vPvzwQ5w/fx6tWrVCbGxsqS/p9PX1xaRJkwD8831A8fHxCAoKkubr6enB29sbsbGx5dabl5en8R1T4v+uqb9+/fpTv9OLiIiIdIdarYa9vT3MzMye2k9nQlNxcTEmTZqE9u3bw9XVFQCQnp4OpVIJS0tLjb7W1tZIT0+X+jwemErml8x7Wh+1Wo2HDx/i3r17KCoqKrNPYmJiuTWHhIRgzpw5pdrNzc0ZmoiIiKqYZ11aozN3zwUEBODcuXNYv369tkuRLSgoCNnZ2dLryW+mJyIioupDJ440TZgwATt37sThw4dRr149qd3Gxgb5+fnIysrSONqUkZEBGxsbqc+Td7mV3F33eJ8n77jLyMiAubk5jI2Noa+vD319/TL7lIxRFpVKBZVK9fwbTERERFWOVo80CSEwYcIEbN26FdHR0XByctKY7+7uDkNDQ0RFRUltSUlJSE1NhaenJwDA09MTZ8+eRWZmptQnMjIS5ubmcHFxkfo8PkZJn5IxlEol3N3dNfoUFxcjKipK6kNERET/crJvDXsJPvzwQ2FhYSEOHjwo0tLSpFdubq7UZ/z48aJ+/foiOjpaxMXFCU9PT+Hp6SnNLywsFK6ursLHx0ckJCSIiIgIUbduXREUFCT1uXLlijAxMRFTp04VFy9eFMuXLxf6+voiIiJC6rN+/XqhUqlEeHi4uHDhghg7dqywtLTUuCvvWbKzswUAkZ2d/YLvDBEREb0qcj+/tRqaUM4tf2FhYVKfhw8fio8++kjUrFlTmJiYiL59+4q0tDSNcVJSUkSPHj2EsbGxqFOnjpgyZYooKCjQ6HPgwAHRsmVLoVQqxeuvv66xjhLfffedqF+/vlAqleLNN98Ux44de67tYWgiIiKqeuR+fvO75yqRWq2GhYUFsrOzefccERFRFSH381tn7p4jIiIi0mUMTUREREQyMDQRERERycDQRERERCQDQxMRERGRDAxNRERERDIwNBERERHJwNBEREREJANDExEREZEMBtougCqP44xdz+yTMt/vFVRCRERU/fBIExEREZEMDE1EREREMjA0EREREcnA0EREREQkA0MTERERkQwMTUREREQyMDQRERERycDQRERERCQDQxMRERGRDAxNRERERDIwNBERERHJwNBEREREJANDExEREZEMDE1EREREMjA0EREREcnA0EREREQkA0MTERERkQwMTUREREQyMDQRERERycDQRERERCQDQxMRERGRDAxNRERERDIwNBERERHJwNBEREREJANDExEREZEMWg9Nhw8fRq9evWBnZweFQoFt27ZpzFcoFGW+Fi5cKPVxdHQsNX/+/Pka45w5cwYdO3aEkZER7O3tsWDBglK1bNq0CU2aNIGRkRHc3Nywe/ful7LNREREVPVoPTQ9ePAALVq0wPLly8ucn5aWpvH6+eefoVAo0L9/f41+c+fO1ej38ccfS/PUajV8fHzg4OCA+Ph4LFy4EMHBwfjhhx+kPjExMRg0aBBGjRqFU6dOoU+fPujTpw/OnTv3cjaciIiIqhQDbRfQo0cP9OjRo9z5NjY2GtO///47unbtitdff12j3czMrFTfEmvXrkV+fj5+/vlnKJVKNGvWDAkJCVi0aBHGjh0LAFi6dCm6d++OqVOnAgDmzZuHyMhILFu2DKtWrXqRTSQiIqJqQOtHmp5HRkYGdu3ahVGjRpWaN3/+fNSuXRutWrXCwoULUVhYKM2LjY1Fp06doFQqpTZfX18kJSXh3r17Uh9vb2+NMX19fREbG1tuPXl5eVCr1RovIiIiqp60fqTpeaxevRpmZmbo16+fRvsnn3yC1q1bo1atWoiJiUFQUBDS0tKwaNEiAEB6ejqcnJw0lrG2tpbm1axZE+np6VLb433S09PLrSckJARz5sypjE0jIiIiHVelQtPPP/+MIUOGwMjISKM9MDBQ+rl58+ZQKpUYN24cQkJCoFKpXlo9QUFBGutWq9Wwt7d/aesjIiIi7akyoemPP/5AUlISNmzY8My+Hh4eKCwsREpKCho3bgwbGxtkZGRo9CmZLrkOqrw+5V0nBQAqleqlhjIiIiLSHVXmmqaffvoJ7u7uaNGixTP7JiQkQE9PD1ZWVgAAT09PHD58GAUFBVKfyMhING7cGDVr1pT6REVFaYwTGRkJT0/PStwKIiIiqqq0HppycnKQkJCAhIQEAMDVq1eRkJCA1NRUqY9arcamTZswevToUsvHxsZiyZIlOH36NK5cuYK1a9di8uTJGDp0qBSIBg8eDKVSiVGjRuH8+fPYsGEDli5dqnFqbeLEiYiIiEBoaCgSExMRHByMuLg4TJgw4eW+AURERFQlaP30XFxcHLp27SpNlwQZf39/hIeHAwDWr18PIQQGDRpUanmVSoX169cjODgYeXl5cHJywuTJkzUCkYWFBfbt24eAgAC4u7ujTp06mDVrlvS4AQBo164d1q1bhy+++AKfffYZGjZsiG3btsHV1fUlbTkRERFVJQohhNB2EdWFWq2GhYUFsrOzYW5u/srX7zhj1zP7pMz3ewWVEBERVR1yP7+1fnqOiIiIqCpgaCIiIiKSgaGJiIiISAaGJiIiIiIZGJqIiIiIZGBoIiIiIpKBoYmIiIhIBoYmIiIiIhkYmoiIiIhkYGgiIiIikoGhiYiIiEgGhiYiIiIiGRiaiIiIiGRgaCIiIiKSgaGJiIiISAaGJiIiIiIZGJqIiIiIZGBoIiIiIpKBoYmIiIhIBoYmIiIiIhkYmoiIiIhkYGgiIiIikoGhiYiIiEgGhiYiIiIiGRiaiIiIiGRgaCIiIiKSgaGJiIiISAaGJiIiIiIZGJqIiIiIZGBoIiIiIpKBoYmIiIhIBoYmIiIiIhkYmoiIiIhkYGgiIiIikoGhiYiIiEgGrYemw4cPo1evXrCzs4NCocC2bds05o8YMQIKhULj1b17d40+d+/exZAhQ2Bubg5LS0uMGjUKOTk5Gn3OnDmDjh07wsjICPb29liwYEGpWjZt2oQmTZrAyMgIbm5u2L17d6VvLxEREVVNBtou4MGDB2jRogU++OAD9OvXr8w+3bt3R1hYmDStUqk05g8ZMgRpaWmIjIxEQUEBRo4cibFjx2LdunUAALVaDR8fH3h7e2PVqlU4e/YsPvjgA1haWmLs2LEAgJiYGAwaNAghISHo2bMn1q1bhz59+uDkyZNwdXV9SVsvn+OMXdougYiI6F9NIYQQ2i6ihEKhwNatW9GnTx+pbcSIEcjKyip1BKrExYsX4eLighMnTqBNmzYAgIiICLz99tu4ceMG7OzssHLlSnz++edIT0+HUqkEAMyYMQPbtm1DYmIiAOD999/HgwcPsHPnTmnstm3bomXLlli1apWs+tVqNSwsLJCdnQ1zc/MKvAPlq6zQlDLfr1LGISIiqi7kfn5r/fScHAcPHoSVlRUaN26MDz/8EHfu3JHmxcbGwtLSUgpMAODt7Q09PT0cP35c6tOpUycpMAGAr68vkpKScO/ePamPt7e3xnp9fX0RGxtbbl15eXlQq9UaLyIiIqqedD40de/eHWvWrEFUVBS+/vprHDp0CD169EBRUREAID09HVZWVhrLGBgYoFatWkhPT5f6WFtba/QpmX5Wn5L5ZQkJCYGFhYX0sre3f7GNJSIiIp2l9WuanmXgwIHSz25ubmjevDmcnZ1x8OBBeHl5abEyICgoCIGBgdK0Wq1mcCIiIqqmdP5I05Nef/111KlTB5cvXwYA2NjYIDMzU6NPYWEh7t69CxsbG6lPRkaGRp+S6Wf1KZlfFpVKBXNzc40XERERVU9VLjTduHEDd+7cga2tLQDA09MTWVlZiI+Pl/pER0ejuLgYHh4eUp/Dhw+joKBA6hMZGYnGjRujZs2aUp+oqCiNdUVGRsLT0/NlbxIRERFVAVoPTTk5OUhISEBCQgIA4OrVq0hISEBqaipycnIwdepUHDt2DCkpKYiKikLv3r3RoEED+Pr6AgCaNm2K7t27Y8yYMfjzzz9x9OhRTJgwAQMHDoSdnR0AYPDgwVAqlRg1ahTOnz+PDRs2YOnSpRqn1iZOnIiIiAiEhoYiMTERwcHBiIuLw4QJE175e0JERES6R+uhKS4uDq1atUKrVq0AAIGBgWjVqhVmzZoFfX19nDlzBu+88w4aNWqEUaNGwd3dHX/88YfGs5rWrl2LJk2awMvLC2+//TY6dOiAH374QZpvYWGBffv24erVq3B3d8eUKVMwa9Ys6RlNANCuXTusW7cOP/zwA1q0aIHNmzdj27ZtOvGMJiIiItI+nXpOU1XH5zQRERFVPdXqOU1ERERE2sbQRERERCQDQxMRERGRDAxNRERERDIwNBERERHJwNBEREREJANDExEREZEMDE1EREREMjA0EREREcnA0EREREQkA0MTERERkQwMTUREREQyMDQRERERycDQRERERCQDQxMRERGRDAxNRERERDIwNBERERHJwNBEREREJANDExEREZEMDE1EREREMjA0EREREcnA0EREREQkA0MTERERkQwMTUREREQyMDQRERERycDQRERERCQDQxMRERGRDAxNRERERDIwNBERERHJwNBEREREJANDExEREZEMDE1EREREMjA0EREREcnA0EREREQkA0MTERERkQxaD02HDx9Gr169YGdnB4VCgW3btknzCgoKMH36dLi5uaFGjRqws7PD8OHDcfPmTY0xHB0doVAoNF7z58/X6HPmzBl07NgRRkZGsLe3x4IFC0rVsmnTJjRp0gRGRkZwc3PD7t27X8o2ExERUdWj9dD04MEDtGjRAsuXLy81Lzc3FydPnsTMmTNx8uRJbNmyBUlJSXjnnXdK9Z07dy7S0tKk18cffyzNU6vV8PHxgYODA+Lj47Fw4UIEBwfjhx9+kPrExMRg0KBBGDVqFE6dOoU+ffqgT58+OHfu3MvZcCIiIqpSDLRdQI8ePdCjR48y51lYWCAyMlKjbdmyZXjzzTeRmpqK+vXrS+1mZmawsbEpc5y1a9ciPz8fP//8M5RKJZo1a4aEhAQsWrQIY8eOBQAsXboU3bt3x9SpUwEA8+bNQ2RkJJYtW4ZVq1ZVxqYSERFRFab1I03PKzs7GwqFApaWlhrt8+fPR+3atdGqVSssXLgQhYWF0rzY2Fh06tQJSqVSavP19UVSUhLu3bsn9fH29tYY09fXF7GxseXWkpeXB7VarfEiIiKi6knrR5qex6NHjzB9+nQMGjQI5ubmUvsnn3yC1q1bo1atWoiJiUFQUBDS0tKwaNEiAEB6ejqcnJw0xrK2tpbm1axZE+np6VLb433S09PLrSckJARz5syprM0jIiIiHVZlQlNBQQEGDBgAIQRWrlypMS8wMFD6uXnz5lAqlRg3bhxCQkKgUqleWk1BQUEa61ar1bC3t39p6yMiIiLtqRKhqSQwXbt2DdHR0RpHmcri4eGBwsJCpKSkoHHjxrCxsUFGRoZGn5LpkuugyutT3nVSAKBSqV5qKCMiIiLdofPXNJUEpkuXLmH//v2oXbv2M5dJSEiAnp4erKysAACenp44fPgwCgoKpD6RkZFo3LgxatasKfWJiorSGCcyMhKenp6VuDVERERUVWn9SFNOTg4uX74sTV+9ehUJCQmoVasWbG1t8e677+LkyZPYuXMnioqKpGuMatWqBaVSidjYWBw/fhxdu3aFmZkZYmNjMXnyZAwdOlQKRIMHD8acOXMwatQoTJ8+HefOncPSpUuxePFiab0TJ05E586dERoaCj8/P6xfvx5xcXEajyUgIiKify+FEEJos4CDBw+ia9eupdr9/f0RHBxc6gLuEgcOHECXLl1w8uRJfPTRR0hMTEReXh6cnJwwbNgwBAYGapw6O3PmDAICAnDixAnUqVMHH3/8MaZPn64x5qZNm/DFF18gJSUFDRs2xIIFC/D222/L3ha1Wg0LCwtkZ2c/8xTi83KcsatSxkmZ71cp4xAREVUXcj+/tR6aqhOGJiIioqpH7ue3zl/TRERERKQLGJqIiIiIZGBoIiIiIpKBoYmIiIhIBoYmIiIiIhle6DlNcXFx2LhxI1JTU5Gfn68xb8uWLS9UGBEREZEuqfCRpvXr16Ndu3a4ePEitm7dioKCApw/fx7R0dGwsLCozBqJiIiItK7Coemrr77C4sWLsWPHDiiVSixduhSJiYkYMGAA6tevX5k1EhEREWldhUNTcnIy/Pz+eVCiUqnEgwcPoFAoMHnyZH71CBEREVU7FQ5NNWvWxP379wEAr732Gs6dOwcAyMrKQm5ubuVUR0RERKQjKnwheKdOnRAZGQk3Nze89957mDhxIqKjoxEZGQkvL6/KrJGIiIhI6yocmpYtW4ZHjx4BAD7//HMYGhoiJiYG/fv3xxdffFFpBRIRERHpggqHplq1akk/6+npYcaMGZVSEBEREZEueq7QpFarpW//VavVT+37tG8JJiIiIqpqnis01axZE2lpabCysoKlpSUUCkWpPkIIKBQKFBUVVVqRRERERNr2XKEpOjpaOi134MCBl1IQERERkS56rtDUuXPnMn8mIiIiqu4q/JymsLAwbNq0qVT7pk2bsHr16hcqioiIiEjXVDg0hYSEoE6dOqXarays8NVXX71QUURERES6psKhKTU1FU5OTqXaHRwckJqa+kJFEREREemaCocmKysrnDlzplT76dOnUbt27RcqioiIiEjXVDg0DRo0CJ988gkOHDiAoqIiFBUVITo6GhMnTsTAgQMrs0YiIiIiravwE8HnzZuHlJQUeHl5wcDgn2GKi4sxfPhwXtNERERE1U6FQ5NSqcSGDRswb948nD59GsbGxnBzc4ODg0Nl1kdERESkEyocmko0atQIjRo1qoxaiIiIiHRWhUNTUVERwsPDERUVhczMTBQXF2vMj46OfuHiiIiIiHRFhUPTxIkTER4eDj8/P7i6upb5PXRERERE1UWFQ9P69euxceNGvP3225VZDxEREZFOqvAjB5RKJRo0aFCZtRARERHprAqHpilTpmDp0qUQQlRmPUREREQ6qcKn544cOYIDBw5gz549aNasGQwNDTXmb9my5YWLIyIiItIVFQ5NlpaW6Nu3b2XWQq+A44xdz+yTMt/vFVRCRERUtVQ4NIWFhVVmHUREREQ6rcLXNAFAfn4+IiIisGLFCqntxo0byMnJeeHCiIiIiHRJhY80JScnw9fXFxkZGcjNzcVHH30EAPjPf/4DIQRWrVpVaUUSERERaVuFjzRNmjQJHTp0wN27dzXuoHv//fcRFRUle5zDhw+jV69esLOzg0KhwLZt2zTmCyEwa9Ys2NrawtjYGN7e3rh06ZJGn7t372LIkCEwNzeHpaUlRo0aVepo15kzZ9CxY0cYGRnB3t4eCxYsKFXLpk2b0KRJExgZGcHNzQ27d++WvR1ERERUvT1XaCouLsaMGTMAADExMQgKCoKhoaHG08AdHR3x999/yx7zwYMHaNGiBZYvX17m/AULFuDbb7/FqlWrcPz4cdSoUQO+vr549OiR1GfIkCE4f/48IiMjsXPnThw+fBhjx46V5qvVavj4+MDBwQHx8fFYuHAhgoOD8cMPP0h9YmJiMGjQIIwaNQqnTp1Cnz590KdPH5w7d072thAREVH1JTs0paWloWvXrigsLATwT4B68vvmACA1NRVmZmayC+jRowe+/PLLMu/EE0JgyZIl+OKLL9C7d280b94ca9aswc2bN6UjUhcvXkRERAR+/PFHeHh4oEOHDvjuu++wfv163Lx5EwCwdu1a5Ofn4+eff0azZs0wcOBAfPLJJ1i0aJG0rqVLl6J79+6YOnUqmjZtinnz5qF169ZYtmyZ7G0hIiKi6kt2aPrxxx/Rt29ffPPNNwAAHx8ffPfddxp9srKyMHPmzEr7apWrV68iPT0d3t7eUpuFhQU8PDwQGxsLAIiNjYWlpSXatGkj9fH29oaenh6OHz8u9enUqROUSqXUx9fXF0lJSbh3757U5/H1lPQpWU9Z8vLyoFarNV5ERERUPcm+EHzixIkwNzeXpkNDQ+Hr6ws3NzcIIdC1a1ckJCTA2toamzZtqpTi0tPTAQDW1tYa7dbW1tK89PR0WFlZacw3MDBArVq1NPo4OTmVGqNkXs2aNZGenv7U9ZQlJCQEc+bMqcCWERERUVUjOzQ9HpgAoF69ejh9+jTWr1+PM2fOICcnB0OGDMGQIUNgbGxc6YXqoqCgIAQGBkrTarUa9vb2WqyIiIiIXpYKP3IA+OeIztChQyurllJsbGwAABkZGbC1tZXaMzIy0LJlS6lPZmamxnKFhYW4e/eutLyNjQ0yMjI0+pRMP6tPyfyyqFQqqFSqCmwZERERVTUVDk1r1qx56vzhw4dXdGiJk5MTbGxsEBUVJYUktVqN48eP48MPPwQAeHp6IisrC/Hx8XB3dwcAREdHo7i4GB4eHlKfzz//HAUFBdJ35EVGRqJx48aoWbOm1CcqKgqTJk2S1h8ZGQlPT88X3g4iIiKq+p4rNKWmpsLe3h4KhQITJ07UmFdQUIDc3FwolUqYmJjIDk05OTm4fPmyNH316lUkJCSgVq1aqF+/PiZNmoQvv/wSDRs2hJOTE2bOnAk7Ozv06dMHANC0aVN0794dY8aMwapVq1BQUIAJEyZg4MCBsLOzAwAMHjwYc+bMwahRozB9+nScO3cOS5cuxeLFi6X1Tpw4EZ07d0ZoaCj8/Pywfv16xMXFaTyWgIiIiP69nis0OTo6Shdel9x19rhLly7hww8/xNSpU2WPGRcXh65du0rTJdcI+fv7Izw8HNOmTcODBw8wduxYZGVloUOHDoiIiICRkZG0zNq1azFhwgR4eXlBT08P/fv3x7fffivNt7CwwL59+xAQEAB3d3fUqVMHs2bN0niWU7t27bBu3Tp88cUX+Oyzz9CwYUNs27YNrq6uz/MWERERUTWlEI8/zvsZTp8+DTc3N+jplf+kgri4OAwdOhSJiYmVUmBVolarYWFhgezs7FIXzr8oxxm7KnW8p0mZ7/fK1kVERKRtcj+/n+uJ4IcOHUJ+fv5T+xgYGEgPlSQiIiKqLp7r9NzixYsxZMgQGBkZYfv27RrzhBBIS0vDsmXL0L59+0otkoiIiEjbnis0Xb16Vfq55ELsEgqFAnXr1kW3bt0QGhpaKcURERER6YoKP3KgrO+dIyIiIqqunuuaJiIiIqJ/qwofaXr860OeZdGiRRVdDREREZFOqHBoOnXqFE6dOoWCggI0btwYAPDXX39BX18frVu3lvopFIoXr5KIiIhIyyocmnr16gUzMzOsXr1a+iqSe/fuYeTIkejYsSOmTJlSaUUSERERaVuFr2kKDQ1FSEiIFJgAoGbNmvjyyy959xwRERFVOxUOTWq1Grdu3SrVfuvWLdy/f/+FiiIiIiLSNRUOTX379sXIkSOxZcsW3LhxAzdu3MBvv/2GUaNGoV+/fpVZIxEREZHWVfiaplWrVuHTTz/F4MGDUVBQ8M9gBgYYNWoUFi5cWGkFEhEREemCCocmExMTrFixAgsXLkRycjIAwNnZGTVq1Ki04oiIiIh0xQs/3DItLQ1paWlo2LAhatSoASFEZdRFREREpFMqHJru3LkDLy8vNGrUCG+//TbS0tIAAKNGjeLjBoiIiKjaqXBomjx5MgwNDZGamgoTExOp/f3330dERESlFEdERESkKyp8TdO+ffuwd+9e1KtXT6O9YcOGuHbt2gsXRkRERKRLKnyk6cGDBxpHmErcvXsXKpXqhYoiIiIi0jUVDk0dO3bEmjVrpGmFQoHi4mIsWLAAXbt2rZTiiIiIiHRFhU/PLViwAF5eXoiLi0N+fj6mTZuG8+fP4+7duzh69Ghl1khERESkdRU+0uTq6oq//voLHTp0QO/evfHgwQP069cPp06dgrOzc2XWSERERKR1FTrSVFBQgO7du2PVqlX4/PPPK7smIiIiIp1ToSNNhoaGOHPmTGXXQkRERKSzKnx6bujQofjpp58qsxYiIiIinVXhC8ELCwvx888/Y//+/XB3dy/1nXOLFi164eKIiIiIdMVzh6YrV67A0dER586dQ+vWrQEAf/31l0YfhUJROdURERER6YjnDk0NGzZEWloaDhw4AOCfr0359ttvYW1tXenFEREREemK576mSQihMb1nzx48ePCg0goiIiIi0kUVvhC8xJMhioiIiKg6eu7QpFAoSl2zxGuYiIiIqLp77muahBAYMWKE9KW8jx49wvjx40vdPbdly5bKqZCIiIhIBzx3aPL399eYHjp0aKUVQ0RERKSrnjs0hYWFvYw6iIiIiHTaC18ITkRERPRvwNBEREREJIPOhyZHR0fpjr3HXwEBAQCALl26lJo3fvx4jTFSU1Ph5+cHExMTWFlZYerUqSgsLNToc/DgQbRu3RoqlQoNGjRAeHj4q9pEIiIiqgIq/N1zr8qJEydQVFQkTZ87dw5vvfUW3nvvPaltzJgxmDt3rjRtYmIi/VxUVAQ/Pz/Y2NggJiYGaWlpGD58OAwNDfHVV18BAK5evQo/Pz+MHz8ea9euRVRUFEaPHg1bW1v4+vq+gq0kIiIiXafzoalu3boa0/Pnz4ezszM6d+4stZmYmMDGxqbM5fft24cLFy5g//79sLa2RsuWLTFv3jxMnz4dwcHBUCqVWLVqFZycnBAaGgoAaNq0KY4cOYLFixczNBERERGAKnB67nH5+fn49ddf8cEHH2g8UHPt2rWoU6cOXF1dERQUhNzcXGlebGws3NzcNL4bz9fXF2q1GufPn5f6eHt7a6zL19cXsbGxT60nLy8ParVa40VERETVk84faXrctm3bkJWVhREjRkhtgwcPhoODA+zs7HDmzBlMnz4dSUlJ0sM109PTS32ZcMl0enr6U/uo1Wo8fPgQxsbGZdYTEhKCOXPmVNbmERERkQ6rUqHpp59+Qo8ePWBnZye1jR07VvrZzc0Ntra28PLyQnJyMpydnV9qPUFBQQgMDJSm1Wo17O3tX+o6iYiISDuqTGi6du0a9u/f/8yvZ/Hw8AAAXL58Gc7OzrCxscGff/6p0ScjIwMApOugbGxspLbH+5ibm5d7lAkAVCqV9HUyREREVL1VmWuawsLCYGVlBT8/v6f2S0hIAADY2toCADw9PXH27FlkZmZKfSIjI2Fubg4XFxepT1RUlMY4kZGR8PT0rMQtICIioqqsSoSm4uJihIWFwd/fHwYG///gWHJyMubNm4f4+HikpKRg+/btGD58ODp16oTmzZsDAHx8fODi4oJhw4bh9OnT2Lt3L7744gsEBARIR4nGjx+PK1euYNq0aUhMTMSKFSuwceNGTJ48WSvbS0RERLqnSoSm/fv3IzU1FR988IFGu1KpxP79++Hj44MmTZpgypQp6N+/P3bs2CH10dfXx86dO6Gvrw9PT08MHToUw4cP13iuk5OTE3bt2oXIyEi0aNECoaGh+PHHH/m4ASIiIpIohBBC20VUF2q1GhYWFsjOzoa5uXmlju04Y1eljvc0KfOffgqUiIioOpH7+V0ljjQRERERaRtDExEREZEMDE1EREREMjA0EREREcnA0EREREQkA0MTERERkQwMTUREREQyMDQRERERycDQRERERCQDQxMRERGRDAxNRERERDIwNBERERHJwNBEREREJANDExEREZEMDE1EREREMjA0EREREcnA0EREREQkA0MTERERkQwMTUREREQyMDQRERERycDQRERERCQDQxMRERGRDAxNRERERDIwNBERERHJwNBEREREJANDExEREZEMDE1EREREMjA0EREREcnA0EREREQkA0MTERERkQwMTUREREQyMDQRERERycDQRERERCQDQxMRERGRDAxNRERERDLofGgKDg6GQqHQeDVp0kSa/+jRIwQEBKB27dowNTVF//79kZGRoTFGamoq/Pz8YGJiAisrK0ydOhWFhYUafQ4ePIjWrVtDpVKhQYMGCA8PfxWbR0RERFWEzocmAGjWrBnS0tKk15EjR6R5kydPxo4dO7Bp0yYcOnQIN2/eRL9+/aT5RUVF8PPzQ35+PmJiYrB69WqEh4dj1qxZUp+rV6/Cz88PXbt2RUJCAiZNmoTRo0dj7969r3Q7iYiISHcZaLsAOQwMDGBjY1OqPTs7Gz/99BPWrVuHbt26AQDCwsLQtGlTHDt2DG3btsW+fftw4cIF7N+/H9bW1mjZsiXmzZuH6dOnIzg4GEqlEqtWrYKTkxNCQ0MBAE2bNsWRI0ewePFi+Pr6vtJtJSIiIt1UJY40Xbp0CXZ2dnj99dcxZMgQpKamAgDi4+NRUFAAb29vqW+TJk1Qv359xMbGAgBiY2Ph5uYGa2trqY+vry/UajXOnz8v9Xl8jJI+JWOUJy8vD2q1WuNFRERE1ZPOhyYPDw+Eh4cjIiICK1euxNWrV9GxY0fcv38f6enpUCqVsLS01FjG2toa6enpAID09HSNwFQyv2Te0/qo1Wo8fPiw3NpCQkJgYWEhvezt7V90c4mIiEhH6fzpuR49ekg/N2/eHB4eHnBwcMDGjRthbGysxcqAoKAgBAYGStNqtZrBiYiIqJrS+SNNT7K0tESjRo1w+fJl2NjYID8/H1lZWRp9MjIypGugbGxsSt1NVzL9rD7m5uZPDWYqlQrm5uYaLyIiIqqeqlxoysnJQXJyMmxtbeHu7g5DQ0NERUVJ85OSkpCamgpPT08AgKenJ86ePYvMzEypT2RkJMzNzeHi4iL1eXyMkj4lYxARERHpfGj69NNPcejQIaSkpCAmJgZ9+/aFvr4+Bg0aBAsLC4waNQqBgYE4cOAA4uPjMXLkSHh6eqJt27YAAB8fH7i4uGDYsGE4ffo09u7diy+++AIBAQFQqVQAgPHjx+PKlSuYNm0aEhMTsWLFCmzcuBGTJ0/W5qYTERGRDtH5a5pu3LiBQYMG4c6dO6hbty46dOiAY8eOoW7dugCAxYsXQ09PD/3790deXh58fX2xYsUKaXl9fX3s3LkTH374ITw9PVGjRg34+/tj7ty5Uh8nJyfs2rULkydPxtKlS1GvXj38+OOPfNwAERERSRRCCKHtIqoLtVoNCwsLZGdnV/r1TY4zdlXqeE+TMt/vla2LiIhI2+R+fuv86TkiIiIiXcDQRERERCQDQxMRERGRDAxNRERERDIwNBERERHJwNBEREREJIPOP6eJXj05jzfgYwmIiOjfhkeaiIiIiGRgaCIiIiKSgaGJiIiISAaGJiIiIiIZGJqIiIiIZGBoIiIiIpKBoYmIiIhIBoYmIiIiIhkYmoiIiIhkYGgiIiIikoGhiYiIiEgGhiYiIiIiGRiaiIiIiGRgaCIiIiKSgaGJiIiISAaGJiIiIiIZGJqIiIiIZGBoIiIiIpKBoYmIiIhIBoYmIiIiIhkYmoiIiIhkYGgiIiIikoGhiYiIiEgGhiYiIiIiGRiaiIiIiGRgaCIiIiKSgaGJiIiISAaGJiIiIiIZdD40hYSE4I033oCZmRmsrKzQp08fJCUlafTp0qULFAqFxmv8+PEafVJTU+Hn5wcTExNYWVlh6tSpKCws1Ohz8OBBtG7dGiqVCg0aNEB4ePjL3jwiIiKqInQ+NB06dAgBAQE4duwYIiMjUVBQAB8fHzx48ECj35gxY5CWlia9FixYIM0rKiqCn58f8vPzERMTg9WrVyM8PByzZs2S+ly9ehV+fn7o2rUrEhISMGnSJIwePRp79+59ZdtKREREustA2wU8S0REhMZ0eHg4rKysEB8fj06dOkntJiYmsLGxKXOMffv24cKFC9i/fz+sra3RsmVLzJs3D9OnT0dwcDCUSiVWrVoFJycnhIaGAgCaNm2KI0eOYPHixfD19X15G0hERERVgs4faXpSdnY2AKBWrVoa7WvXrkWdOnXg6uqKoKAg5ObmSvNiY2Ph5uYGa2trqc3X1xdqtRrnz5+X+nh7e2uM6evri9jY2HJrycvLg1qt1ngRERFR9aTzR5oeV1xcjEmTJqF9+/ZwdXWV2gcPHgwHBwfY2dnhzJkzmD59OpKSkrBlyxYAQHp6ukZgAiBNp6enP7WPWq3Gw4cPYWxsXKqekJAQzJkzp1K3kYiIiHRTlQpNAQEBOHfuHI4cOaLRPnbsWOlnNzc32NrawsvLC8nJyXB2dn5p9QQFBSEwMFCaVqvVsLe3f2nrIyIiIu2pMqfnJkyYgJ07d+LAgQOoV6/eU/t6eHgAAC5fvgwAsLGxQUZGhkafkumS66DK62Nubl7mUSYAUKlUMDc313gRERFR9aTzoUkIgQkTJmDr1q2Ijo6Gk5PTM5dJSEgAANja2gIAPD09cfbsWWRmZkp9IiMjYW5uDhcXF6lPVFSUxjiRkZHw9PSspC0hIiKiqkznQ1NAQAB+/fVXrFu3DmZmZkhPT0d6ejoePnwIAEhOTsa8efMQHx+PlJQUbN++HcOHD0enTp3QvHlzAICPjw9cXFwwbNgwnD59Gnv37sUXX3yBgIAAqFQqAMD48eNx5coVTJs2DYmJiVixYgU2btyIyZMna23biYiISHfofGhauXIlsrOz0aVLF9ja2kqvDRs2AACUSiX2798PHx8fNGnSBFOmTEH//v2xY8cOaQx9fX3s3LkT+vr68PT0xNChQzF8+HDMnTtX6uPk5IRdu3YhMjISLVq0QGhoKH788Uc+boCIiIgAAAohhNB2EdWFWq2GhYUFsrOzK/36JscZuyp1vFchZb6ftksgIiJ6Jrmf3zp/pImIiIhIFzA0EREREcnA0EREREQkA0MTERERkQwMTUREREQyMDQRERERycDQRERERCQDQxMRERGRDAxNRERERDIwNBERERHJwNBEREREJANDExEREZEMDE1EREREMjA0EREREcnA0EREREQkA0MTERERkQwMTUREREQyMDQRERERycDQRERERCQDQxMRERGRDAxNRERERDIwNBERERHJwNBEREREJANDExEREZEMBtougKovxxm7ntknZb7fK6iEiIjoxfFIExEREZEMDE1EREREMjA0EREREcnA0EREREQkA0MTERERkQwMTUREREQyMDQRERERycDQRERERCQDH25JWsUHYBIRUVXBI01EREREMjA0PWH58uVwdHSEkZERPDw88Oeff2q7JCIiItIBPD33mA0bNiAwMBCrVq2Ch4cHlixZAl9fXyQlJcHKykrb5f1r8RQeERHpAoUQQmi7CF3h4eGBN954A8uWLQMAFBcXw97eHh9//DFmzJjxzOXVajUsLCyQnZ0Nc3PzSq1NTnCgp2OwIiKissj9/OaRpv+Tn5+P+Ph4BAUFSW16enrw9vZGbGxsmcvk5eUhLy9Pms7Ozgbwz5tf2Yrzcit9zH+b+pM3Vco45+b4Vso4RESkG0o+t591HImh6f/cvn0bRUVFsLa21mi3trZGYmJimcuEhIRgzpw5pdrt7e1fSo2kGyyWaLsCIiJ6Ge7fvw8LC4ty5zM0vYCgoCAEBgZK08XFxbh79y5q164NhUJRaetRq9Wwt7fH9evXK/20H7047h/dxX2ju7hvdNu/bf8IIXD//n3Y2dk9tR9D0/+pU6cO9PX1kZGRodGekZEBGxubMpdRqVRQqVQabZaWli+rRJibm/8rfnmrKu4f3cV9o7u4b3Tbv2n/PO0IUwk+cuD/KJVKuLu7IyoqSmorLi5GVFQUPD09tVgZERER6QIeaXpMYGAg/P390aZNG7z55ptYsmQJHjx4gJEjR2q7NCIiItIyhqbHvP/++7h16xZmzZqF9PR0tGzZEhEREaUuDn/VVCoVZs+eXepUIOkG7h/dxX2ju7hvdBv3T9n4nCYiIiIiGXhNExEREZEMDE1EREREMjA0EREREcnA0EREREQkA0NTFbB8+XI4OjrCyMgIHh4e+PPPP7VdUrV3+PBh9OrVC3Z2dlAoFNi2bZvGfCEEZs2aBVtbWxgbG8Pb2xuXLl3S6HP37l0MGTIE5ubmsLS0xKhRo5CTk/MKt6J6CgkJwRtvvAEzMzNYWVmhT58+SEpK0ujz6NEjBAQEoHbt2jA1NUX//v1LPbg2NTUVfn5+MDExgZWVFaZOnYrCwsJXuSnVzsqVK9G8eXPpgYienp7Ys2ePNJ/7RXfMnz8fCoUCkyZNktq4f56NoUnHbdiwAYGBgZg9ezZOnjyJFi1awNfXF5mZmdourVp78OABWrRogeXLl5c5f8GCBfj222+xatUqHD9+HDVq1ICvry8ePXok9RkyZAjOnz+PyMhI7Ny5E4cPH8bYsWNf1SZUW4cOHUJAQACOHTuGyMhIFBQUwMfHBw8ePJD6TJ48GTt27MCmTZtw6NAh3Lx5E/369ZPmFxUVwc/PD/n5+YiJicHq1asRHh6OWbNmaWOTqo169eph/vz5iI+PR1xcHLp164bevXvj/PnzALhfdMWJEyfw/fffo3nz5hrt3D8yCNJpb775pggICJCmi4qKhJ2dnQgJCdFiVf8uAMTWrVul6eLiYmFjYyMWLlwotWVlZQmVSiX+97//CSGEuHDhggAgTpw4IfXZs2ePUCgU4u+//35ltf8bZGZmCgDi0KFDQoh/9oWhoaHYtGmT1OfixYsCgIiNjRVCCLF7926hp6cn0tPTpT4rV64U5ubmIi8v79VuQDVXs2ZN8eOPP3K/6Ij79++Lhg0bisjISNG5c2cxceJEIQT/buTikSYdlp+fj/j4eHh7e0ttenp68Pb2RmxsrBYr+3e7evUq0tPTNfaLhYUFPDw8pP0SGxsLS0tLtGnTRurj7e0NPT09HD9+/JXXXJ1lZ2cDAGrVqgUAiI+PR0FBgcb+adKkCerXr6+xf9zc3DQeXOvr6wu1Wi0dFaEXU1RUhPXr1+PBgwfw9PTkftERAQEB8PPz09gPAP9u5OITwXXY7du3UVRUVOqJ5NbW1khMTNRSVZSeng4AZe6Xknnp6emwsrLSmG9gYIBatWpJfejFFRcXY9KkSWjfvj1cXV0B/PPeK5XKUl+e/eT+KWv/lcyjijt79iw8PT3x6NEjmJqaYuvWrXBxcUFCQgL3i5atX78eJ0+exIkTJ0rN49+NPAxNRFRlBQQE4Ny5czhy5Ii2S6H/07hxYyQkJCA7OxubN2+Gv78/Dh06pO2y/vWuX7+OiRMnIjIyEkZGRtoup8ri6TkdVqdOHejr65e6eyEjIwM2NjZaqopK3vun7RcbG5tSF+sXFhbi7t273HeVZMKECdi5cycOHDiAevXqSe02NjbIz89HVlaWRv8n909Z+69kHlWcUqlEgwYN4O7ujpCQELRo0QJLly7lftGy+Ph4ZGZmonXr1jAwMICBgQEOHTqEb7/9FgYGBrC2tub+kYGhSYcplUq4u7sjKipKaisuLkZUVBQ8PT21WNm/m5OTE2xsbDT2i1qtxvHjx6X94unpiaysLMTHx0t9oqOjUVxcDA8Pj1dec3UihMCECROwdetWREdHw8nJSWO+u7s7DA0NNfZPUlISUlNTNfbP2bNnNYJtZGQkzM3N4eLi8mo25F+iuLgYeXl53C9a5uXlhbNnzyIhIUF6tWnTBkOGDJF+5v6RQdtXotPTrV+/XqhUKhEeHi4uXLggxo4dKywtLTXuXqDKd//+fXHq1Clx6tQpAUAsWrRInDp1Sly7dk0IIcT8+fOFpaWl+P3338WZM2dE7969hZOTk3j48KE0Rvfu3UWrVq3E8ePHxZEjR0TDhg3FoEGDtLVJ1caHH34oLCwsxMGDB0VaWpr0ys3NlfqMHz9e1K9fX0RHR4u4uDjh6ekpPD09pfmFhYXC1dVV+Pj4iISEBBERESHq1q0rgoKCtLFJ1caMGTPEoUOHxNWrV8WZM2fEjBkzhEKhEPv27RNCcL/omsfvnhOC+0cOhqYq4LvvvhP169cXSqVSvPnmm+LYsWPaLqnaO3DggABQ6uXv7y+E+OexAzNnzhTW1tZCpVIJLy8vkZSUpDHGnTt3xKBBg4SpqakwNzcXI0eOFPfv39fC1lQvZe0XACIsLEzq8/DhQ/HRRx+JmjVrChMTE9G3b1+RlpamMU5KSoro0aOHMDY2FnXq1BFTpkwRBQUFr3hrqpcPPvhAODg4CKVSKerWrSu8vLykwCQE94uueTI0cf88m0IIIbRzjIuIiIio6uA1TUREREQyMDQRERERycDQRERERCQDQxMRERGRDAxNRERERDIwNBERERHJwNBEREREJANDExEREZEMDE1EVKWEh4fD0tJSa+tPSUmBQqFAQkLCK1+3tred6N+OoYmInsuIESOgUCgwf/58jfZt27ZBoVBoqaqqheGHqGpiaCKi52ZkZISvv/4a9+7d03YpsuTn52u7BCKqBhiaiOi5eXt7w8bGBiEhIU/t99tvv6FZs2ZQqVRwdHREaGioxnxHR0d8+eWXGD58OExNTeHg4IDt27fj1q1b6N27N0xNTdG8eXPExcWVGnvbtm1o2LAhjIyM4Ovri+vXr0vzgoOD0bJlS/z4449wcnKCkZERACArKwujR49G3bp1YW5ujm7duuH06dNP3YY///wTrVq1gpGREdq0aYNTp06V6nPu3Dn06NEDpqamsLa2xrBhw3D79u0yxzt48CBGjhyJ7OxsKBQKKBQKBAcHAwDu3buH4cOHo2bNmjAxMUGPHj1w6dKlcmu7desW2rRpg759+yIvLw/FxcUICQmBk5MTjI2N0aJFC2zevFlj3QqFAlFRUWjTpg1MTEzQrl07JCUlSX1Onz6Nrl27wszMDObm5nB3dy/z/Sf6N2JoIqLnpq+vj6+++grfffcdbty4UWaf+Ph4DBgwAAMHDsTZs2cRHByMmTNnIjw8XKPf4sWL0b59e5w6dQp+fn4YNmwYhg8fjqFDh+LkyZNwdnbG8OHD8fh3i+fm5uI///kP1qxZg6NHjyIrKwsDBw7UGPfy5cv47bffsGXLFun6o/feew+ZmZnYs2cP4uPj0bp1a3h5eeHu3btlbkNOTg569uwJFxcXxMfHIzg4GJ9++qlGn6ysLHTr1g2tWrVCXFwcIiIikJGRgQEDBpQ5Zrt27bBkyRKYm5sjLS0NaWlp0pgjRoxAXFwctm/fjtjYWAgh8Pbbb6OgoKDUONevX0fHjh3h6uqKzZs3Q6VSISQkBGvWrMGqVatw/vx5TJ48GUOHDsWhQ4c0lv38888RGhqKuLg4GBgY4IMPPpDmDRkyBPXq1cOJEycQHx+PGTNmwNDQsMxtIfrXEUREz8Hf31/07t1bCCFE27ZtxQcffCCEEGLr1q3i8f+lDB48WLz11lsay06dOlW4uLhI0w4ODmLo0KHSdFpamgAgZs6cKbXFxsYKACItLU0IIURYWJgAII4dOyb1uXjxogAgjh8/LoQQYvbs2cLQ0FBkZmZKff744w9hbm4uHj16pFGTs7Oz+P7778vc1u+//17Url1bPHz4UGpbuXKlACBOnTolhBBi3rx5wsfHR2O569evCwAiKSmpzHHDwsKEhYWFRttff/0lAIijR49Kbbdv3xbGxsZi48aNGsslJiYKe3t78cknn4ji4mIhhBCPHj0SJiYmIiYmRmPcUaNGiUGDBgkhhDhw4IAAIPbv3y/N37VrlwAgbaOZmZkIDw8vs26ifzseaSKiCvv666+xevVqXLx4sdS8ixcvon379hpt7du3x6VLl1BUVCS1NW/eXPrZ2toaAODm5laqLTMzU2ozMDDAG2+8IU03adIElpaWGnU4ODigbt260vTp06eRk5OD2rVrw9TUVHpdvXoVycnJZW7fxYsX0bx5c+n0HgB4enpq9Dl9+jQOHDigMWaTJk0AoNxxy1uXgYEBPDw8pLbatWujcePGGtv18OFDdOzYEf369cPSpUuli+8vX76M3NxcvPXWWxq1rFmzplQdj7/ntra2AP7/+xsYGIjRo0fD29sb8+fPf65tIKruDLRdABFVXZ06dYKvry+CgoIwYsSICo3x+KmfkgBQVltxcfFzjVujRg2N6ZycHNja2uLgwYOl+r7InWw5OTno1asXvv7661LzSgJJZVKpVPD29sbOnTsxdepUvPbaa1IdALBr1y6p7fFlHve09zc4OBiDBw/Grl27sGfPHsyePRvr169H3759K31biKoahiYieiHz589Hy5Yt0bhxY432pk2b4ujRoxptR48eRaNGjaCvr/9C6ywsLERcXBzefPNNAEBSUhKysrLQtGnTcpdp3bo10tPTYWBgAEdHR1nradq0KX755Rc8evRIOtp07NixUuP+9ttvcHR0hIGBvP+lKpVKjaNtJesqLCzE8ePH0a5dOwDAnTt3kJSUBBcXF6mfnp4efvnlFwwePBhdu3bFwYMHYWdnBxcXF6hUKqSmpqJz586y6ihPo0aN0KhRI0yePBmDBg1CWFgYQxMReCE4Eb0gNzc3DBkyBN9++61G+5QpUxAVFYV58+bhr7/+wurVq7Fs2bJSF1JXhKGhIT7++GMcP34c8fHxGDFiBNq2bSuFqLJ4e3vD09MTffr0wb59+5CSkoKYmBh8/vnn5d4dNnjwYCgUCowZMwYXLlzA7t278c0332j0CQgIwN27dzFo0CCcOHECycnJ2Lt3L0aOHFkqGJVwdHRETk4OoqKicPv2beTm5qJhw4bo3bs3xowZgyNHjuD06dMYOnQoXnvtNfTu3VtjeX19faxduxYtWrRAt27dkJ6eDjMzM3z66aeYPHkyVq9ejeTkZJw8eRLfffcdVq9eLet9ffjwISZMmICDBw/i2rVrOHr0KE6cOPHUMEr0b8LQREQvbO7cuaVOn7Vu3RobN27E+vXr4erqilmzZmHu3LkVPo33OBMTE0yfPh2DBw9G+/btYWpqig0bNjx1GYVCgd27d6NTp04YOXIkGjVqhIEDB+LatWvSdVNPMjU1xY4dO3D27Fm0atUKn3/+eanTcHZ2djh69CiKiorg4+MDNzc3TJo0CZaWltDTK/t/se3atcP48ePx/vvvo27duliwYAEAICwsDO7u7ujZsyc8PT0hhMDu3bvLvHvNwMAA//vf/9CsWTN069YNmZmZmDdvHmbOnImQkBA0bdoU3bt3x65du+Dk5CTnbYW+vj7u3LmD4cOHo1GjRhgwYAB69OiBOXPmyFqeqLpTCPHYfbxEREREVCYeaSIiIiKSgaGJiIiISAaGJiIiIiIZGJqIiIiIZGBoIiIiIpKBoYmIiIhIBoYmIiIiIhkYmoiIiIhkYGgiIiIikoGhiYiIiEgGhiYiIiIiGf4f564/J1+jA6IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#############################################\n",
    "# SOLUCIÓ                                   #\n",
    "#############################################\n",
    "\n",
    "# Visualitzem les dades (idioma destí)\n",
    "df['len_ca'] = df['CATALAN_norm'].str.split().map(len)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(df['len_ca'], bins=50)\n",
    "plt.title('Distribució de tokens per frase – Català')\n",
    "plt.xlabel('Nombre de tokens')\n",
    "plt.ylabel('Freqüència')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wvz2u3zktH5s"
   },
   "source": [
    "Per a la definició dels models, necessitem instal·lar *keras* i *tensorflow*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WPv_880u7nbJ",
    "outputId": "d30cf1e0-70ff-47c6-b1bd-0c07d99f2dd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras) (1.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras) (2.0.2)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras) (3.13.0)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.15.0)\n",
      "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras) (0.4.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras) (4.13.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "isjIX82C7nbK",
    "outputId": "7962929a-ca05-43d4-9d30-047be0817a28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4xUTSitYTZr"
   },
   "source": [
    "**d. Calculem el vocabulari tant el de l'idioma origen, com el de l'idioma destí, i imprimim el nombre de paraules**.\n",
    "\n",
    "*Resultat esperat:* Es visualitzaran dos nombres, el de paraules del vocabulari de l'idioma origen i el de destí, després d'haver aplicat el preprocessament i la tokenització."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T08:50:58.364452Z",
     "iopub.status.busy": "2025-05-29T08:50:58.363640Z",
     "iopub.status.idle": "2025-05-29T08:50:58.993978Z",
     "shell.execute_reply": "2025-05-29T08:50:58.993243Z",
     "shell.execute_reply.started": "2025-05-29T08:50:58.364428Z"
    },
    "id": "TTCjxsZMgj9E",
    "outputId": "2d3d4b4c-9048-4c5a-c830-63ce296555be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eng_vocab_size: 29845\n",
      "cat_vocab_size: 45215\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# SOLUCIÓ                                  #\n",
    "#############################################\n",
    "\n",
    "eng_tokens = df['ENGLISH_norm'].str.split().explode()\n",
    "cat_tokens = df['CATALAN_norm'].str.split().explode()\n",
    "\n",
    "eng_vocab = set(eng_tokens.dropna())\n",
    "cat_vocab = set(cat_tokens.dropna())\n",
    "\n",
    "eng_vocab_size = len(eng_vocab)\n",
    "cat_vocab_size = len(cat_vocab)\n",
    "\n",
    "print(f\"eng_vocab_size: {eng_vocab_size}\")\n",
    "print(f\"cat_vocab_size: {cat_vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1K5WlBKEYcGZ"
   },
   "source": [
    "**e. Separem els conjunts d'entrenament per idioma i els codifiquem.**\n",
    "\n",
    "En aquest pas, se separen les dades en dos conjunts: un per a entrenament (*train*) i l'altre per a prova (*test*), utilitzant una divisió del 80% per a entrenament i 20% per a prova.\n",
    "\n",
    "*Sortida esperada:* tres primeres files del dataset d'entrenament *train*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T08:51:02.210913Z",
     "iopub.status.busy": "2025-05-29T08:51:02.210084Z",
     "iopub.status.idle": "2025-05-29T08:51:02.288696Z",
     "shell.execute_reply": "2025-05-29T08:51:02.287986Z",
     "shell.execute_reply.started": "2025-05-29T08:51:02.210891Z"
    },
    "id": "mX7rtG4Q7nbM",
    "outputId": "c3cf5050-8929-48e9-c510-980f8a9095fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['and i discovered that telomeres consisted of special segments of noncoding dna right at the very ends of chromosomes'\n",
      "  'vaig descobrir que aquests telòmers estan formats per segments especials dadn no codificat just al final dels cromosomes']\n",
      " ['volunteer 0 7 9 0 4 4' 'home 079044']\n",
      " ['we are just not doing enough' 'simplement no hi estem fent prou']]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "#############################################\n",
    "# SOLUCIÓ                                  #\n",
    "#############################################\n",
    "\n",
    "eng_strs = df['ENGLISH_norm'].tolist()\n",
    "cat_strs = df['CATALAN_norm'].tolist()\n",
    "\n",
    "eng_train, eng_test, cat_train, cat_test = train_test_split(\n",
    "    eng_strs,\n",
    "    cat_strs,\n",
    "    test_size=0.2,\n",
    "    random_state=12\n",
    ")\n",
    "\n",
    "train_pairs = np.array(list(zip(eng_train, cat_train)), dtype=object)\n",
    "test_pairs  = np.array(list(zip(eng_test, cat_test)), dtype=object)\n",
    "\n",
    "print(train_pairs[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJbNLhqUc2ER"
   },
   "source": [
    "**f. Definir i aplicar una funció per a codificar les seqüències**\n",
    "\n",
    "En aquest pas, els dos conjunts de dades creats en el punt anterior,  seran codificats usant **tokenització** i un procés de **padding** per a assegurar que totes les seqüències d'un mateix idioma tinguin la mateixa longitud.\n",
    "\n",
    "**Important:** Per a dur a terme un primer experiment, *depenent de la capacitat de processament disponible de cadascú*, se suggereix ajustar el valor del paràmetre **longitud de seqüència*, *fins a trobar el valor més alt possible que permeti entrenar el model encoder-decoder en un temps acceptable.*\n",
    "\n",
    "El paràmetre **longitud de seqüència** té un impacte important en l'entrenament del model. Un valor alt permet al model capturar més context de les frases, la qual cosa és crucial per a traduir correctament oracions complexes; no obstant això, si la longitud és massa curta, el model pot truncar frases importants, perdent informació clau.\n",
    "\n",
    "Uso de memoria y eficiencia computacional:\n",
    "\n",
    "Majors longituds requereixen més memòria, ja que el model defineix matrius més grans per a representar les seqüències. Mentre que longituds curtes són més eficients en termes de recursos, però poden sacrificar precisió si les oracions reals excedeixen aquest límit amb freqüència.\n",
    "\n",
    "Finalment, en traducció automàtica, les longituds de les seqüències en l'idioma origen i destí no sempre han de ser iguals (per exemple, una oració en anglès pot ser més curta que la seva equivalent en alemany).\n",
    "\n",
    "Considerant tot l'anterior, si es disposa d'infraestructura amb GPU, se suggereix iniciar amb un valor máximo de 12 (o proper) i mínim de 4. A la cel·la de codi que segueix, es proposa iniciar amb un valor intermedi de 8, però aquest valor pot ser ajustat.\n",
    "\n",
    "Si durant l'entrenament, es produeixen problemes (per limitació d'infraestructura), es podrà tornar a aquest pas per a fixar el valor mínim de 4 per a la longitud de seqüència de tots dos idiomes (tot i que els resultats de la traducció no seran de qualitat)\n",
    "\n",
    "**Sortida esperada:** Mida de cada arxiu i mostra de les tres primeres seqüències codificades de l'arxiu d'entrenament."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T08:51:06.427567Z",
     "iopub.status.busy": "2025-05-29T08:51:06.426760Z",
     "iopub.status.idle": "2025-05-29T08:51:10.079106Z",
     "shell.execute_reply": "2025-05-29T08:51:10.078307Z",
     "shell.execute_reply.started": "2025-05-29T08:51:06.427542Z"
    },
    "id": "kNjdWyEdc2r4",
    "outputId": "d177addf-1027-4700-a696-31bf697cfbf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX.shape, testX.shape: (42156, 12) (10540, 12)\n",
      "Primeres 3 seqüències codificades (trainX):\n",
      " [[  909  9458     4 15688   828    98    34     1    60   998     4  3526]\n",
      " [ 2029  7061  8103  6335  7061  2373  2373     0     0     0     0     0]\n",
      " [   11    16    47    30   146   248     0     0     0     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "# ----------------------\n",
    "# Depenent de la infraestructura del sistema,\n",
    "# la longitud de seqüència es pot iniciar amb un valor de 8.\n",
    "max_text_length = 12\n",
    "# ----------------------\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################\n",
    "\n",
    "eng_tokenizer = Tokenizer()\n",
    "cat_tokenizer = Tokenizer()\n",
    "\n",
    "eng_tokenizer.fit_on_texts(eng_train)\n",
    "cat_tokenizer.fit_on_texts(cat_train)\n",
    "\n",
    "train_eng_seq = eng_tokenizer.texts_to_sequences(eng_train)\n",
    "test_eng_seq  = eng_tokenizer.texts_to_sequences(eng_test)\n",
    "train_cat_seq = cat_tokenizer.texts_to_sequences(cat_train)\n",
    "test_cat_seq  = cat_tokenizer.texts_to_sequences(cat_test)\n",
    "\n",
    "trainX = pad_sequences(train_eng_seq, maxlen=max_text_length, padding='post')\n",
    "testX  = pad_sequences(test_eng_seq,  maxlen=max_text_length, padding='post')\n",
    "trainY = pad_sequences(train_cat_seq, maxlen=max_text_length, padding='post')\n",
    "testY  = pad_sequences(test_cat_seq,  maxlen=max_text_length, padding='post')\n",
    "\n",
    "print(\"trainX.shape, testX.shape:\", trainX.shape, testX.shape)\n",
    "print(\"Primeres 3 seqüències codificades (trainX):\\n\", trainX[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6M9ZQnwKqcAt"
   },
   "source": [
    "### 1.1.2 Definició del model encoder-decoder i entrenament (2 punts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fbXuj15hK_Ck"
   },
   "source": [
    "**a. Definim el model *encoder-decoder* basant-nos en el notebook vist a l'assignatura**, i l'instanciem amb una capa d'embedding per a les frases de la **llengua origen** i la dimensió de la última capa com la del vocabulario de la **llengua destí**.\n",
    "\n",
    "**Important:** Per a la definició del model, considerar els següents paràmetres i valors referencials:\n",
    "\n",
    "* Com a quantitat de **units** treballar, inicialment, amb el valor de 100. El nombre d'unitats o cel·les de memòria de cada capa LSTM defineix la dimensionalitat de l'espai intern en el que la LSTM processa i representa la informació al llarg del temps; és a dir, és la mida del vector de l'estat ocult *hidden state* i de l'estat de cel·la *cell state* que la LSTN manté per a capturar patrons i dependències de les seqüències d'entrada.\n",
    "\n",
    " A major nombre de *units*, augmenta la capacitat del model per a modelar relacions complexes i dependè cies a llarg termini en el text, la qual cosa és clau per a la traducció automàtica, on el context pot comprendre vàries paraules o frases. No obstant això, un valor alt incrementa el nombre de paràmetres i, per tant, requerirà més memòria i temps de càlcul; a més, creix el risc de sobreajustament si les dades d'entrenament no són suficients.\n",
    "\n",
    " Per tant, treballarem amb un valor inicial de 100 tot i que l'ideal seria usar un valor superior.\n",
    "\n",
    "* Longitud dels vectors d'embeddings *embedding_vec_length*: establir-lo en 200; aquest és un valor referencial que podría ser ajustat segons la mida del vocabulario, la complexitat de l'idioma i els recursos disponibles. Més endavant, *exercici 1.1.3* es demanar variar aquest valor.\n",
    "\n",
    "**Resultat esperat:** s'haurà instanciat un modelo encoder-decoder. Aquest model està dissenyat per a processar i traduir textos de l'**idioma origen** a l'**idioma destí** utilitzant capes d'embedding i LSTM.\n",
    "\n",
    "*Sortida esperada*: Utilitzar el mètode *mt_model.summary()* per a visualitzar l'estructura i configuració del model, incloent el nombre de paràmetres i la disposició de les capes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T07:25:55.946426Z",
     "iopub.status.busy": "2025-05-29T07:25:55.946137Z",
     "iopub.status.idle": "2025-05-29T07:25:57.231035Z",
     "shell.execute_reply": "2025-05-29T07:25:57.230380Z",
     "shell.execute_reply.started": "2025-05-29T07:25:55.946404Z"
    },
    "id": "bGLbPLtE7nbN",
    "outputId": "2d40e5cd-297d-42c0-a213-0b1136a19288"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "I0000 00:00:1748503557.172342      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1748503557.173107      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"mt_seq_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"mt_seq_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ repeat_vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)         │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ repeat_vector (\u001b[38;5;33mRepeatVector\u001b[0m)         │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, RepeatVector, Dense\n",
    "\n",
    "#############################################\n",
    "# SOLUCIÓ                                   #\n",
    "#############################################\n",
    "\n",
    "# Definim el model encoder-decoder\n",
    "\n",
    "embedding_vec_length = 200 # Valor referencial\n",
    "units = 100 # Valor referencial\n",
    "\n",
    "# Tamany del vocabulari anglès i català\n",
    "vocab_size_eng = len(eng_tokenizer.word_index) + 1\n",
    "vocab_size_cat = len(cat_tokenizer.word_index) + 1\n",
    "\n",
    "seq_model = Sequential(name=\"mt_seq_model\")\n",
    "\n",
    "# Embedding de l'idioma origen\n",
    "seq_model.add(Embedding(input_dim=vocab_size_eng,\n",
    "                        output_dim=embedding_vec_length,\n",
    "                        input_length=max_text_length,\n",
    "                        name=\"embedding\"))\n",
    "\n",
    "# Encoder LSTM\n",
    "seq_model.add(LSTM(units, name=\"lstm\"))\n",
    "\n",
    "# Repetim l'estat ocult tantes vegades com longitud de seqüència\n",
    "seq_model.add(RepeatVector(max_text_length, name=\"repeat_vector\"))\n",
    "\n",
    "# Decoder LSTM\n",
    "seq_model.add(LSTM(units,\n",
    "                   return_sequences=True,\n",
    "                   name=\"lstm_1\"))\n",
    "\n",
    "# Dense\n",
    "seq_model.add(Dense(vocab_size_cat,\n",
    "                    activation=\"softmax\",\n",
    "                    name=\"dense\"))\n",
    "\n",
    "seq_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dkFBEaXjlcu9"
   },
   "source": [
    "**b. Compilem el model**\n",
    "\n",
    "**Resultat esperat:** el model compilat i llest per a ser entrenat. S'utilitzarà l'optimitzador *RMSprop* amb una tasa d'aprenentatge de *0.001* i la funció de pèrdua *sparse_categorical_crossentropy*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T07:26:00.402998Z",
     "iopub.status.busy": "2025-05-29T07:26:00.402737Z",
     "iopub.status.idle": "2025-05-29T07:26:00.439442Z",
     "shell.execute_reply": "2025-05-29T07:26:00.438859Z",
     "shell.execute_reply.started": "2025-05-29T07:26:00.402981Z"
    },
    "id": "wNwpJh4D7nbO",
    "outputId": "798ae27d-3f06-42f1-eeee-cf99abd1fc22"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"mt_seq_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"mt_seq_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ repeat_vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)         │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ repeat_vector (\u001b[38;5;33mRepeatVector\u001b[0m)         │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "#############################################\n",
    "# SOLUCIÓ                                   #\n",
    "#############################################\n",
    "\n",
    "# Compilem el model\n",
    "seq_model.compile(\n",
    "    optimizer=RMSprop(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "seq_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IuVDwSApo0VT"
   },
   "source": [
    "**c. Entrenem i guardem el model.**\n",
    "\n",
    "**Important:** El model pot trigar hores si es disposa de CPU, molt menys amb GPU. Colab permet l'ús de GPU en general, si no se'n fa un ús intensiu i continuat. Per tant, habilitar només la GPU quan es necessiti per a entrenar i predir. Deshabilitar-la (i per tant reiniciar l'entorn) per a executar les cel·les no necessàries per a entrenar.\n",
    "\n",
    "* Per tant, per a provar el funcionament, recomanem llençar l'entrenament **només amb una època** i comprovar-ne el funcionament. Un cop tenim clar que el sistema funciona, incrementar el valor (per exemple a 50 o 100, depenent de com evoluciona el model amb cada *epoch*)\n",
    "\n",
    "* Si durant l'entrenament, Colab no pot carregar el model en memòria, recomanem disminuir el valor de **longitud de paraula** a 4 i el nombre de **units** a 128, d'aquesta manera es podrà completar el procés, tot i que, probablement, els resultats no seran bons.\n",
    "\n",
    "* Revisar el `Notebook d'Exemple`, en el que es proporcionen pautes i guies per a dur un millor control de les execucions quan s'han de realitzar reinicis de sessió o s'exhaureix la memòria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T11:51:52.165446Z",
     "iopub.status.busy": "2025-05-27T11:51:52.164784Z",
     "iopub.status.idle": "2025-05-27T13:34:01.145839Z",
     "shell.execute_reply": "2025-05-27T13:34:01.145063Z",
     "shell.execute_reply.started": "2025-05-27T11:51:52.165421Z"
    },
    "id": "_1muJyWc7nbO",
    "outputId": "480480aa-af9c-488c-d5d7-9273f42e2b25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1748346717.214721     102 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 91ms/step - accuracy: 0.1822 - loss: 7.3088 - val_accuracy: 0.1952 - val_loss: 6.2247\n",
      "Epoch 2/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.1812 - loss: 6.4246 - val_accuracy: 0.1952 - val_loss: 6.2143\n",
      "Epoch 3/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.1857 - loss: 6.3816 - val_accuracy: 0.1952 - val_loss: 6.1634\n",
      "Epoch 4/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.1809 - loss: 6.3120 - val_accuracy: 0.2033 - val_loss: 5.9344\n",
      "Epoch 5/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.1957 - loss: 6.1153 - val_accuracy: 0.2119 - val_loss: 5.9169\n",
      "Epoch 6/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2039 - loss: 6.0477 - val_accuracy: 0.2182 - val_loss: 5.8386\n",
      "Epoch 7/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2072 - loss: 6.0187 - val_accuracy: 0.2157 - val_loss: 5.8402\n",
      "Epoch 8/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2079 - loss: 6.0176 - val_accuracy: 0.2204 - val_loss: 5.8052\n",
      "Epoch 9/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2121 - loss: 5.9769 - val_accuracy: 0.2226 - val_loss: 5.8089\n",
      "Epoch 10/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2140 - loss: 5.9564 - val_accuracy: 0.2252 - val_loss: 5.7677\n",
      "Epoch 11/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2174 - loss: 5.9341 - val_accuracy: 0.2314 - val_loss: 5.7511\n",
      "Epoch 12/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2242 - loss: 5.8918 - val_accuracy: 0.2325 - val_loss: 5.7311\n",
      "Epoch 13/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2261 - loss: 5.8812 - val_accuracy: 0.2290 - val_loss: 5.7477\n",
      "Epoch 14/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2279 - loss: 5.8641 - val_accuracy: 0.2328 - val_loss: 5.7226\n",
      "Epoch 15/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2291 - loss: 5.8423 - val_accuracy: 0.2337 - val_loss: 5.7121\n",
      "Epoch 16/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2312 - loss: 5.8263 - val_accuracy: 0.2348 - val_loss: 5.6878\n",
      "Epoch 17/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2323 - loss: 5.8001 - val_accuracy: 0.2337 - val_loss: 5.6913\n",
      "Epoch 18/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2341 - loss: 5.7803 - val_accuracy: 0.2373 - val_loss: 5.6628\n",
      "Epoch 19/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2387 - loss: 5.7361 - val_accuracy: 0.2410 - val_loss: 5.6778\n",
      "Epoch 20/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2408 - loss: 5.7183 - val_accuracy: 0.2432 - val_loss: 5.6628\n",
      "Epoch 21/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2397 - loss: 5.7094 - val_accuracy: 0.2364 - val_loss: 5.6410\n",
      "Epoch 22/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2450 - loss: 5.6545 - val_accuracy: 0.2407 - val_loss: 5.6092\n",
      "Epoch 23/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2456 - loss: 5.6365 - val_accuracy: 0.2437 - val_loss: 5.5917\n",
      "Epoch 24/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2458 - loss: 5.6190 - val_accuracy: 0.2399 - val_loss: 5.5942\n",
      "Epoch 25/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2495 - loss: 5.5706 - val_accuracy: 0.2461 - val_loss: 5.5848\n",
      "Epoch 26/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2525 - loss: 5.5387 - val_accuracy: 0.2428 - val_loss: 5.5751\n",
      "Epoch 27/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2510 - loss: 5.5442 - val_accuracy: 0.2447 - val_loss: 5.5703\n",
      "Epoch 28/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2547 - loss: 5.4956 - val_accuracy: 0.2429 - val_loss: 5.5555\n",
      "Epoch 29/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2573 - loss: 5.4541 - val_accuracy: 0.2402 - val_loss: 5.5502\n",
      "Epoch 30/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2597 - loss: 5.4245 - val_accuracy: 0.2448 - val_loss: 5.5607\n",
      "Epoch 31/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2615 - loss: 5.3990 - val_accuracy: 0.2411 - val_loss: 5.5449\n",
      "Epoch 32/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2656 - loss: 5.3600 - val_accuracy: 0.2425 - val_loss: 5.5418\n",
      "Epoch 33/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2680 - loss: 5.3246 - val_accuracy: 0.2461 - val_loss: 5.5437\n",
      "Epoch 34/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2673 - loss: 5.3130 - val_accuracy: 0.2361 - val_loss: 5.5540\n",
      "Epoch 35/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2706 - loss: 5.2766 - val_accuracy: 0.2440 - val_loss: 5.5486\n",
      "Epoch 36/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2717 - loss: 5.2568 - val_accuracy: 0.2340 - val_loss: 5.5535\n",
      "Epoch 37/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2729 - loss: 5.2311 - val_accuracy: 0.2413 - val_loss: 5.5311\n",
      "Epoch 38/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2768 - loss: 5.1829 - val_accuracy: 0.2406 - val_loss: 5.5375\n",
      "Epoch 39/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2780 - loss: 5.1687 - val_accuracy: 0.2314 - val_loss: 5.5740\n",
      "Epoch 40/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2803 - loss: 5.1310 - val_accuracy: 0.2412 - val_loss: 5.5374\n",
      "Epoch 41/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2799 - loss: 5.1178 - val_accuracy: 0.2352 - val_loss: 5.5572\n",
      "Epoch 42/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2873 - loss: 5.0518 - val_accuracy: 0.2379 - val_loss: 5.5507\n",
      "Epoch 43/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2888 - loss: 5.0365 - val_accuracy: 0.2412 - val_loss: 5.5797\n",
      "Epoch 44/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2884 - loss: 5.0242 - val_accuracy: 0.2341 - val_loss: 5.5681\n",
      "Epoch 45/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2928 - loss: 4.9706 - val_accuracy: 0.2373 - val_loss: 5.5793\n",
      "Epoch 46/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2936 - loss: 4.9579 - val_accuracy: 0.2318 - val_loss: 5.5897\n",
      "Epoch 47/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2961 - loss: 4.9297 - val_accuracy: 0.2381 - val_loss: 5.5829\n",
      "Epoch 48/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.2985 - loss: 4.9023 - val_accuracy: 0.2402 - val_loss: 5.5918\n",
      "Epoch 49/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3027 - loss: 4.8549 - val_accuracy: 0.2366 - val_loss: 5.6021\n",
      "Epoch 50/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3021 - loss: 4.8422 - val_accuracy: 0.2367 - val_loss: 5.6117\n",
      "Epoch 51/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3032 - loss: 4.8286 - val_accuracy: 0.2382 - val_loss: 5.6282\n",
      "Epoch 52/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3059 - loss: 4.7920 - val_accuracy: 0.2372 - val_loss: 5.6285\n",
      "Epoch 53/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3079 - loss: 4.7687 - val_accuracy: 0.2382 - val_loss: 5.6382\n",
      "Epoch 54/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3116 - loss: 4.7315 - val_accuracy: 0.2361 - val_loss: 5.6463\n",
      "Epoch 55/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3146 - loss: 4.6984 - val_accuracy: 0.2361 - val_loss: 5.6696\n",
      "Epoch 56/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3169 - loss: 4.6711 - val_accuracy: 0.2330 - val_loss: 5.6712\n",
      "Epoch 57/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3180 - loss: 4.6542 - val_accuracy: 0.2363 - val_loss: 5.6935\n",
      "Epoch 58/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3187 - loss: 4.6336 - val_accuracy: 0.2329 - val_loss: 5.6961\n",
      "Epoch 59/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3224 - loss: 4.5942 - val_accuracy: 0.2405 - val_loss: 5.7419\n",
      "Epoch 60/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3223 - loss: 4.5792 - val_accuracy: 0.2358 - val_loss: 5.7256\n",
      "Epoch 61/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3241 - loss: 4.5554 - val_accuracy: 0.2293 - val_loss: 5.7389\n",
      "Epoch 62/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3283 - loss: 4.5197 - val_accuracy: 0.2304 - val_loss: 5.7461\n",
      "Epoch 63/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3295 - loss: 4.5024 - val_accuracy: 0.2313 - val_loss: 5.7532\n",
      "Epoch 64/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3302 - loss: 4.4890 - val_accuracy: 0.2310 - val_loss: 5.7813\n",
      "Epoch 65/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3320 - loss: 4.4654 - val_accuracy: 0.2319 - val_loss: 5.7928\n",
      "Epoch 66/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3355 - loss: 4.4325 - val_accuracy: 0.2326 - val_loss: 5.8030\n",
      "Epoch 67/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3368 - loss: 4.4110 - val_accuracy: 0.2301 - val_loss: 5.8138\n",
      "Epoch 68/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3415 - loss: 4.3696 - val_accuracy: 0.2283 - val_loss: 5.8333\n",
      "Epoch 69/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3394 - loss: 4.3749 - val_accuracy: 0.2318 - val_loss: 5.8463\n",
      "Epoch 70/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3416 - loss: 4.3419 - val_accuracy: 0.2317 - val_loss: 5.8587\n",
      "Epoch 71/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3433 - loss: 4.3278 - val_accuracy: 0.2313 - val_loss: 5.8724\n",
      "Epoch 72/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3461 - loss: 4.3014 - val_accuracy: 0.2255 - val_loss: 5.9015\n",
      "Epoch 73/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3498 - loss: 4.2632 - val_accuracy: 0.2280 - val_loss: 5.9067\n",
      "Epoch 74/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3522 - loss: 4.2367 - val_accuracy: 0.2278 - val_loss: 5.9210\n",
      "Epoch 75/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3515 - loss: 4.2358 - val_accuracy: 0.2250 - val_loss: 5.9463\n",
      "Epoch 76/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3536 - loss: 4.2135 - val_accuracy: 0.2242 - val_loss: 5.9633\n",
      "Epoch 77/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3562 - loss: 4.1869 - val_accuracy: 0.2230 - val_loss: 5.9826\n",
      "Epoch 78/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3559 - loss: 4.1730 - val_accuracy: 0.2263 - val_loss: 5.9818\n",
      "Epoch 79/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3564 - loss: 4.1594 - val_accuracy: 0.2219 - val_loss: 6.0198\n",
      "Epoch 80/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3606 - loss: 4.1291 - val_accuracy: 0.2271 - val_loss: 6.0167\n",
      "Epoch 81/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3604 - loss: 4.1188 - val_accuracy: 0.2248 - val_loss: 6.0237\n",
      "Epoch 82/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3642 - loss: 4.0847 - val_accuracy: 0.2220 - val_loss: 6.0550\n",
      "Epoch 83/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3680 - loss: 4.0571 - val_accuracy: 0.2216 - val_loss: 6.0725\n",
      "Epoch 84/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3686 - loss: 4.0391 - val_accuracy: 0.2253 - val_loss: 6.0779\n",
      "Epoch 85/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3663 - loss: 4.0453 - val_accuracy: 0.2248 - val_loss: 6.0853\n",
      "Epoch 86/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3680 - loss: 4.0219 - val_accuracy: 0.2234 - val_loss: 6.1085\n",
      "Epoch 87/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3719 - loss: 3.9956 - val_accuracy: 0.2193 - val_loss: 6.1433\n",
      "Epoch 88/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3721 - loss: 3.9874 - val_accuracy: 0.2201 - val_loss: 6.1587\n",
      "Epoch 89/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3748 - loss: 3.9558 - val_accuracy: 0.2217 - val_loss: 6.1499\n",
      "Epoch 90/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3777 - loss: 3.9317 - val_accuracy: 0.2202 - val_loss: 6.1868\n",
      "Epoch 91/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3768 - loss: 3.9269 - val_accuracy: 0.2257 - val_loss: 6.1850\n",
      "Epoch 92/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3802 - loss: 3.8955 - val_accuracy: 0.2211 - val_loss: 6.2008\n",
      "Epoch 93/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3813 - loss: 3.8836 - val_accuracy: 0.2229 - val_loss: 6.2258\n",
      "Epoch 94/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3834 - loss: 3.8654 - val_accuracy: 0.2257 - val_loss: 6.2380\n",
      "Epoch 95/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3823 - loss: 3.8667 - val_accuracy: 0.2147 - val_loss: 6.2795\n",
      "Epoch 96/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3859 - loss: 3.8340 - val_accuracy: 0.2218 - val_loss: 6.2685\n",
      "Epoch 97/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3865 - loss: 3.8228 - val_accuracy: 0.2229 - val_loss: 6.2868\n",
      "Epoch 98/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3866 - loss: 3.8062 - val_accuracy: 0.2124 - val_loss: 6.3447\n",
      "Epoch 99/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3906 - loss: 3.7786 - val_accuracy: 0.2183 - val_loss: 6.3215\n",
      "Epoch 100/100\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 93ms/step - accuracy: 0.3909 - loss: 3.7643 - val_accuracy: 0.2164 - val_loss: 6.3421\n",
      "Model guardat a: mt_seq_model.keras\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# SOLUCIÓ                                   #\n",
    "#############################################\n",
    "\n",
    "# Entrenem i guardem el model\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "\n",
    "history = seq_model.fit(\n",
    "    trainX,\n",
    "    trainY,\n",
    "    validation_data=(testX, testY),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "\n",
    "model_path = \"mt_seq_model.keras\"\n",
    "seq_model.save(model_path, save_format=\"keras\")\n",
    "print(f\"Model guardat a: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ivjPTmUsBv_a"
   },
   "source": [
    "**d. Generar prediccions.**\n",
    "\n",
    "Un cop entrenat el model, aplicar el mètode *predict()* a l'arxiu de test per a obtenir les prediccions.\n",
    "\n",
    "**Suggeriment:** Revisar el `Notebook d'exemple` en el que es proporciona una pauta per a treballar amb un subconjunt de l'arxiu de tex en cas de tenir limitacions durante el procés de predicció."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T09:56:59.586486Z",
     "iopub.status.busy": "2025-05-28T09:56:59.585760Z",
     "iopub.status.idle": "2025-05-28T09:56:59.591230Z",
     "shell.execute_reply": "2025-05-28T09:56:59.590352Z",
     "shell.execute_reply.started": "2025-05-28T09:56:59.586461Z"
    },
    "id": "z3UEm_VgjJuc"
   },
   "outputs": [],
   "source": [
    "def load_ta_model (model_path):\n",
    "    \"\"\"Loads a pre-trained model from a specified file path.\n",
    "\n",
    "    This function attempts to load a saved model, including its architecture,\n",
    "    weights, and optimizer state, from the given file path.\n",
    "\n",
    "    Args:\n",
    "        model_path (str): The file path where the saved model file is located.\n",
    "\n",
    "    Returns:\n",
    "        object: The loaded 'Keras model' object if the file exists and the underlying\n",
    "                `load_model` function executes successfully.\n",
    "        None: If the file specified by `model_path` does not exist or if the\n",
    "              `load_model` function raises an exception during loading.\n",
    "    \"\"\"\n",
    "    print(f\"Loading model from: {model_path}\")\n",
    "    mt_model = None\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"ERROR: Model file not found at {model_path}.\")\n",
    "    else:\n",
    "        try:\n",
    "            # Load the model, includes architecture, weigths and optimizer state\n",
    "            mt_model = load_model(model_path)\n",
    "            print(\"Model loaded successfully!\")\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR: Unable to load model from {model_path}. Error: {e}\")\n",
    "    return mt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T09:57:02.520584Z",
     "iopub.status.busy": "2025-05-28T09:57:02.520021Z",
     "iopub.status.idle": "2025-05-28T09:57:04.835914Z",
     "shell.execute_reply": "2025-05-28T09:57:04.835172Z",
     "shell.execute_reply.started": "2025-05-28T09:57:02.520564Z"
    },
    "id": "ep65eoStjJuc",
    "outputId": "72bac85b-dce9-4121-9865-0c6e52934c52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /kaggle/input/mt_seq_model/keras/pr2-textos-model-1/1/mt_seq_model.keras\n",
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Secció Load model\n",
    "#\n",
    "# PER A CARREGAR UN MODEL JA ENTRENAT:\n",
    "#\n",
    "# 1. Canviar only_load_model a True\n",
    "# 2. Revisar, i en el seu cas modificar, el 'model_path' del model a recuperar\n",
    "# 2. Executar aquesta cel·la\n",
    "#\n",
    "# Per seguretat, restaurar only_load_model a False\n",
    "#\n",
    "\n",
    "only_load_model = True     # Change when necessary\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "if only_load_model:\n",
    "    model_path = '/kaggle/input/mt_seq_model/keras/pr2-textos-model-1/1/mt_seq_model.keras'\n",
    "    mt_model = load_ta_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T09:57:06.696163Z",
     "iopub.status.busy": "2025-05-28T09:57:06.695913Z",
     "iopub.status.idle": "2025-05-28T09:57:08.071817Z",
     "shell.execute_reply": "2025-05-28T09:57:08.071070Z",
     "shell.execute_reply.started": "2025-05-28T09:57:06.696146Z"
    },
    "id": "QX74wIEu7nbP",
    "outputId": "c9096f8c-b799-4ff6-ef2f-1621398bca82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/10\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 1s/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1748426227.781812      98 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# SOLUCIÓ                                   #\n",
    "#############################################\n",
    "\n",
    "# Apliquem el modelo\n",
    "# Error de memòria, nomes 10 primeres entrades\n",
    "n_samples = 10\n",
    "\n",
    "X_sample       = testX[:n_samples]\n",
    "expected_small = cat_test[:n_samples]\n",
    "\n",
    "pred_probs = mt_model.predict(X_sample, batch_size=1)\n",
    "pred_ids   = np.argmax(pred_probs, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ArVXrJKCn471"
   },
   "source": [
    "**e. Visualització de resultats.**\n",
    "\n",
    "Visualitzem els resultats de les prediccions amb els valors esperats.\n",
    "\n",
    "**Resultat esperat:** prediccions traduïdes de les primeres 10 entrades del conjunt de prova. Aquestes prediccions es mostraran amb els textos esperats a efectes de comprovar la bondat de la predicció."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T09:57:35.402001Z",
     "iopub.status.busy": "2025-05-28T09:57:35.401698Z",
     "iopub.status.idle": "2025-05-28T09:57:35.411522Z",
     "shell.execute_reply": "2025-05-28T09:57:35.410866Z",
     "shell.execute_reply.started": "2025-05-28T09:57:35.401981Z"
    },
    "id": "5BNLHUKaLe9P",
    "outputId": "966b9df8-5694-43d3-a511-e669a951dc7c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>és la cosa més poderosa que posseeixes</td>\n",
       "      <td>aquesta és la més que que</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>realment són tan diferents</td>\n",
       "      <td>així són són</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aquest no és un exercici secundari</td>\n",
       "      <td>aquí és és la diferència diferència</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en la meva segona químio la meva mare es va posar molt malalta i vaig anar a visitarla</td>\n",
       "      <td>amb amb de de i i em em li li la la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>o potser és una persona normal i corrent com ara tu o jo</td>\n",
       "      <td>o una o o o no sóc una una</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ell no va utilitzar mai més el meu sobrenom</td>\n",
       "      <td>el mai mai més més</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rialles igual que el bisolvon no és una cura universal per totes les malalties leducació tampoc ho és per tots els pecats racials dels eua</td>\n",
       "      <td>una una una a per les de de de de de de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>que quan éreu un embrió</td>\n",
       "      <td>el del cervell cos cos cos mateix un que un un un</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>i mantenen estrets vincles socials</td>\n",
       "      <td>els els estan estan un</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>explosions</td>\n",
       "      <td>el del nit i i 4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                       actual  \\\n",
       "0                                                                                                      és la cosa més poderosa que posseeixes   \n",
       "1                                                                                                                  realment són tan diferents   \n",
       "2                                                                                                          aquest no és un exercici secundari   \n",
       "3                                                      en la meva segona químio la meva mare es va posar molt malalta i vaig anar a visitarla   \n",
       "4                                                                                    o potser és una persona normal i corrent com ara tu o jo   \n",
       "5                                                                                                 ell no va utilitzar mai més el meu sobrenom   \n",
       "6  rialles igual que el bisolvon no és una cura universal per totes les malalties leducació tampoc ho és per tots els pecats racials dels eua   \n",
       "7                                                                                                                     que quan éreu un embrió   \n",
       "8                                                                                                          i mantenen estrets vincles socials   \n",
       "9                                                                                                                                  explosions   \n",
       "\n",
       "                                           predicted  \n",
       "0                          aquesta és la més que que  \n",
       "1                                       així són són  \n",
       "2                aquí és és la diferència diferència  \n",
       "3                amb amb de de i i em em li li la la  \n",
       "4                         o una o o o no sóc una una  \n",
       "5                                 el mai mai més més  \n",
       "6            una una una a per les de de de de de de  \n",
       "7  el del cervell cos cos cos mateix un que un un un  \n",
       "8                             els els estan estan un  \n",
       "9                                   el del nit i i 4  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################################\n",
    "# SOLUCIÓ                                   #\n",
    "#############################################\n",
    "\n",
    "def decode_sequence(seq):\n",
    "    return ' '.join(\n",
    "        cat_tokenizer.index_word.get(idx, '')\n",
    "        for idx in seq\n",
    "        if idx != 0\n",
    "    ).strip()\n",
    "\n",
    "decoded_preds = [decode_sequence(seq) for seq in pred_ids]\n",
    "\n",
    "df_results = pd.DataFrame({\n",
    "    'actual':    expected_small,\n",
    "    'predicted': decoded_preds\n",
    "})\n",
    "\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UlScdExYLdqb"
   },
   "source": [
    "f. **Pregunta d'anàlisi:** Depenent dels resultats obtinguts en la predicció (valors reals vs. valors generats), per què creus que no són bons i com creus que poden obtenir-se millors resultats?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQGw9X9Rqsag"
   },
   "source": [
    "**Resposta a la pregunta:**\n",
    "\n",
    "Els resultats són dolents perquè el model s'ha entrenat completament de zero amb encoders personalitzats, embeddings de dimensió 200, o un número d'unitats de 100. D'aquesta manera la capacitat i el coneixement inicial eren molt limitats tot i entrenar 100 èpoques. Per obtenir millors traduccions, caldria utilitzar transfer learning amb embeddings o encoders preentrenats, augmentar la capacitat o fer servir un altre arquitectura de model. A la feina m'han donat molt bons resultats els transformers.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mqE2RI7dqcAw"
   },
   "source": [
    "### 1.1.3 Experimentació amb diferentss resultats (1,5 punts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-S3kdvvGq6N"
   },
   "source": [
    "En aquest apartat podríem analitzar com afecta a la qualitat de la traducció la variació de diferents paràmetres del model com ara:\n",
    "* longitud d'embeddings (*embedding_vec_length*),\n",
    "* longitud de seqüència (*max_text_length*),\n",
    "* número de units (*units*),\n",
    "* batch size,\n",
    "* epochs,\n",
    "* ...\n",
    "\n",
    "No obstant això, degut a que no sempre ens trobarem amb GPUs lliures, aquí ens limitarem a experimentar amb els paràmetres:\n",
    "* *embedding_vec_length* i\n",
    "* *max_text_length*.\n",
    "\n",
    "**Important:** durant les execucions, depenent del model i del consum de memòria actual, la predicció pot cancel·lar si s'exhaureix la memòria disponible. En cas de cancel·lació, recarregar el model des de local (veue apartat 1.1.2.2 del `Notebook d'exemple`) i predir només un subconjunt de l'arxiu de test (tot i que en aquest cas no seran vàlides les magnituds de medició de qualitat del sistema)  \n",
    "\n",
    "A més, suggerim que després de cada entrenament es realitzi una còpia del model entrenat i s'emmagatzemi en local (*'model/...'*) per a, en cas de cancel·lació, no haver de realitzar de nou l'entrenament, associant al nom de la còpia els paràmetres amb els que ha estat entrenat.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AxtBK6h7SQXc"
   },
   "source": [
    "**a. Experimentar amb el valor de longitud de embedding** (*embedding_vec_length*)\n",
    "\n",
    "Analitzar com un increment en la mida dels vectors de embedding afecta al rendiment d'un model de traducció automàtica de **l'idioma origen** a **l'idioma destí**.\n",
    "\n",
    "**Resultat esperat:** S'imprimirà el resultat que mostri el rendiment del model creat per a diferents mides d'embeddings (inicialment s'ha treballat amb 200, també es podria experimentar amb valors com ara 50 i 300). Cada resultat constarà de la mida de l'embedding seguit d'un **score** que n'indiqui l'efectivitat del model calculat amb *model.evaluate()*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T10:20:20.053652Z",
     "iopub.status.busy": "2025-05-28T10:20:20.053373Z",
     "iopub.status.idle": "2025-05-28T10:43:04.964971Z",
     "shell.execute_reply": "2025-05-28T10:43:04.964154Z",
     "shell.execute_reply.started": "2025-05-28T10:20:20.053634Z"
    },
    "id": "V_OIoFheEKfu",
    "outputId": "492b6210-3d09-45ac-c2bf-616be3f3b046"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 168ms/step - accuracy: 0.1815 - loss: 7.8000 - val_accuracy: 0.1952 - val_loss: 6.2309\n",
      "Epoch 2/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 163ms/step - accuracy: 0.1830 - loss: 6.4203 - val_accuracy: 0.1952 - val_loss: 6.1931\n",
      "Epoch 3/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 165ms/step - accuracy: 0.1849 - loss: 6.3710 - val_accuracy: 0.1952 - val_loss: 6.1776\n",
      "Epoch 4/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 164ms/step - accuracy: 0.1845 - loss: 6.3492 - val_accuracy: 0.1952 - val_loss: 6.0842\n",
      "Epoch 5/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 164ms/step - accuracy: 0.1839 - loss: 6.2455 - val_accuracy: 0.2020 - val_loss: 5.9263\n",
      "Epoch 6/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 164ms/step - accuracy: 0.1998 - loss: 6.0863 - val_accuracy: 0.2098 - val_loss: 5.8684\n",
      "Epoch 7/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 164ms/step - accuracy: 0.2041 - loss: 6.0364 - val_accuracy: 0.2129 - val_loss: 5.8589\n",
      "Epoch 8/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 164ms/step - accuracy: 0.2054 - loss: 6.0176 - val_accuracy: 0.2168 - val_loss: 5.8165\n",
      "Epoch 9/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 164ms/step - accuracy: 0.2076 - loss: 5.9950 - val_accuracy: 0.2143 - val_loss: 5.9185\n",
      "Epoch 10/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 164ms/step - accuracy: 0.2093 - loss: 5.9741 - val_accuracy: 0.2195 - val_loss: 5.7896\n",
      "Epoch 11/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 164ms/step - accuracy: 0.2078 - loss: 5.9788 - val_accuracy: 0.2219 - val_loss: 5.7783\n",
      "Epoch 12/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 164ms/step - accuracy: 0.2107 - loss: 5.9557 - val_accuracy: 0.2188 - val_loss: 5.7874\n",
      "Epoch 13/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 164ms/step - accuracy: 0.2098 - loss: 5.9625 - val_accuracy: 0.2189 - val_loss: 5.8229\n",
      "Epoch 14/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 164ms/step - accuracy: 0.2129 - loss: 5.9300 - val_accuracy: 0.2239 - val_loss: 5.7522\n",
      "Epoch 15/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 164ms/step - accuracy: 0.2163 - loss: 5.8988 - val_accuracy: 0.2248 - val_loss: 5.7330\n",
      "Epoch 16/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 164ms/step - accuracy: 0.2168 - loss: 5.8952 - val_accuracy: 0.2248 - val_loss: 5.7343\n",
      "Epoch 17/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 164ms/step - accuracy: 0.2173 - loss: 5.8883 - val_accuracy: 0.2233 - val_loss: 5.7277\n",
      "Epoch 18/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 164ms/step - accuracy: 0.2174 - loss: 5.8765 - val_accuracy: 0.2264 - val_loss: 5.7143\n",
      "Epoch 19/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 164ms/step - accuracy: 0.2169 - loss: 5.8714 - val_accuracy: 0.2240 - val_loss: 5.7200\n",
      "Epoch 20/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 164ms/step - accuracy: 0.2216 - loss: 5.8457 - val_accuracy: 0.2273 - val_loss: 5.7063\n",
      "Epoch 21/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 164ms/step - accuracy: 0.2238 - loss: 5.8362 - val_accuracy: 0.2307 - val_loss: 5.6986\n",
      "Epoch 22/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 164ms/step - accuracy: 0.2284 - loss: 5.8059 - val_accuracy: 0.2338 - val_loss: 5.7001\n",
      "Epoch 23/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 164ms/step - accuracy: 0.2274 - loss: 5.8102 - val_accuracy: 0.2353 - val_loss: 5.6726\n",
      "Epoch 24/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 164ms/step - accuracy: 0.2284 - loss: 5.7908 - val_accuracy: 0.2337 - val_loss: 5.6713\n",
      "Epoch 25/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 164ms/step - accuracy: 0.2312 - loss: 5.7777 - val_accuracy: 0.2366 - val_loss: 5.6529\n",
      "Results (embedding=50):  loss=5.6529, accuracy=0.2366\n",
      "Model guardat a: mt_seq_model_emb50.keras\n"
     ]
    }
   ],
   "source": [
    "# Possibles longituds de vectors a provar:\n",
    "embedding_size = 50\n",
    "epochs = 25  # incrementar aquest valor si existeix disponibilitat de GPUs.\n",
    "batch_size=128\n",
    "\n",
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################\n",
    "\n",
    "seq_model = Sequential(name=\"mt_seq_emb50\")\n",
    "seq_model.add(Embedding(input_dim=vocab_size_eng,\n",
    "                        output_dim=embedding_size,\n",
    "                        input_length=max_text_length,\n",
    "                        name=\"embedding_50\"))\n",
    "seq_model.add(LSTM(units, name=\"lstm_50\"))\n",
    "seq_model.add(RepeatVector(max_text_length, name=\"repeat_vector_50\"))\n",
    "seq_model.add(LSTM(units,\n",
    "                   return_sequences=True,\n",
    "                   name=\"lstm_1_50\"))\n",
    "seq_model.add(Dense(vocab_size_cat,\n",
    "                    activation=\"softmax\",\n",
    "                    name=\"dense_50\"))\n",
    "\n",
    "seq_model.compile(\n",
    "    optimizer=RMSprop(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = seq_model.fit(\n",
    "    trainX,\n",
    "    trainY,\n",
    "    validation_data=(testX, testY),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "loss, acc = seq_model.evaluate(testX, testY, batch_size=batch_size, verbose=0)\n",
    "print(f\"Results (embedding=50):  loss={loss:.4f}, accuracy={acc:.4f}\")\n",
    "\n",
    "model_path = \"mt_seq_model_emb50.keras\"\n",
    "seq_model.save(model_path, save_format=\"keras\")\n",
    "print(f\"Model guardat a: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T10:44:13.646240Z",
     "iopub.status.busy": "2025-05-28T10:44:13.645949Z",
     "iopub.status.idle": "2025-05-28T11:07:15.692651Z",
     "shell.execute_reply": "2025-05-28T11:07:15.691964Z",
     "shell.execute_reply.started": "2025-05-28T10:44:13.646219Z"
    },
    "id": "afnBJga0jJue",
    "outputId": "2424aa5c-4ff0-4166-bc3a-5b64405dc80a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 168ms/step - accuracy: 0.1825 - loss: 7.7596 - val_accuracy: 0.1952 - val_loss: 6.2280\n",
      "Epoch 2/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 166ms/step - accuracy: 0.1854 - loss: 6.3969 - val_accuracy: 0.1952 - val_loss: 6.2050\n",
      "Epoch 3/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 167ms/step - accuracy: 0.1833 - loss: 6.3884 - val_accuracy: 0.1952 - val_loss: 6.1811\n",
      "Epoch 4/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 166ms/step - accuracy: 0.1860 - loss: 6.3549 - val_accuracy: 0.1952 - val_loss: 6.1607\n",
      "Epoch 5/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 166ms/step - accuracy: 0.1836 - loss: 6.3325 - val_accuracy: 0.1952 - val_loss: 6.0419\n",
      "Epoch 6/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 166ms/step - accuracy: 0.1864 - loss: 6.1816 - val_accuracy: 0.2090 - val_loss: 5.9085\n",
      "Epoch 7/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 166ms/step - accuracy: 0.2016 - loss: 6.0698 - val_accuracy: 0.2175 - val_loss: 5.8619\n",
      "Epoch 8/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 166ms/step - accuracy: 0.2044 - loss: 6.0378 - val_accuracy: 0.2160 - val_loss: 5.8329\n",
      "Epoch 9/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 166ms/step - accuracy: 0.2058 - loss: 6.0147 - val_accuracy: 0.2174 - val_loss: 5.8183\n",
      "Epoch 10/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 167ms/step - accuracy: 0.2058 - loss: 6.0047 - val_accuracy: 0.2188 - val_loss: 5.8122\n",
      "Epoch 11/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 166ms/step - accuracy: 0.2085 - loss: 5.9836 - val_accuracy: 0.2138 - val_loss: 5.8196\n",
      "Epoch 12/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 167ms/step - accuracy: 0.2084 - loss: 5.9815 - val_accuracy: 0.2178 - val_loss: 5.7979\n",
      "Epoch 13/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 166ms/step - accuracy: 0.2087 - loss: 5.9709 - val_accuracy: 0.2206 - val_loss: 5.7814\n",
      "Epoch 14/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 166ms/step - accuracy: 0.2109 - loss: 5.9494 - val_accuracy: 0.2041 - val_loss: 5.8957\n",
      "Epoch 15/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 166ms/step - accuracy: 0.2134 - loss: 5.9380 - val_accuracy: 0.2246 - val_loss: 5.7623\n",
      "Epoch 16/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 166ms/step - accuracy: 0.2199 - loss: 5.8965 - val_accuracy: 0.2253 - val_loss: 5.7414\n",
      "Epoch 17/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 166ms/step - accuracy: 0.2166 - loss: 5.8956 - val_accuracy: 0.2244 - val_loss: 5.7507\n",
      "Epoch 18/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 167ms/step - accuracy: 0.2191 - loss: 5.8705 - val_accuracy: 0.2251 - val_loss: 5.7305\n",
      "Epoch 19/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 166ms/step - accuracy: 0.2183 - loss: 5.8738 - val_accuracy: 0.2271 - val_loss: 5.7279\n",
      "Epoch 20/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 166ms/step - accuracy: 0.2182 - loss: 5.8711 - val_accuracy: 0.2251 - val_loss: 5.7570\n",
      "Epoch 21/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 166ms/step - accuracy: 0.2203 - loss: 5.8488 - val_accuracy: 0.2269 - val_loss: 5.7092\n",
      "Epoch 22/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 166ms/step - accuracy: 0.2210 - loss: 5.8451 - val_accuracy: 0.2305 - val_loss: 5.7226\n",
      "Epoch 23/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 166ms/step - accuracy: 0.2276 - loss: 5.8053 - val_accuracy: 0.2328 - val_loss: 5.7123\n",
      "Epoch 24/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 166ms/step - accuracy: 0.2275 - loss: 5.8033 - val_accuracy: 0.2317 - val_loss: 5.6884\n",
      "Epoch 25/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 166ms/step - accuracy: 0.2288 - loss: 5.7840 - val_accuracy: 0.2288 - val_loss: 5.6905\n",
      "Results (embedding=300):  loss=5.6905, accuracy=0.2288\n",
      "Model guardat a: mt_seq_model_emb300.keras\n"
     ]
    }
   ],
   "source": [
    "# Possibles longituds de vectors a provar:\n",
    "embedding_size = 300\n",
    "epochs = 25  # incrementar aquest valor si existeix disponibilitat de GPUs.\n",
    "batch_size=128\n",
    "\n",
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################\n",
    "\n",
    "seq_model = Sequential(name=\"mt_seq_emb300\")\n",
    "seq_model.add(Embedding(input_dim=vocab_size_eng,\n",
    "                        output_dim=embedding_size,\n",
    "                        input_length=max_text_length,\n",
    "                        name=\"embedding_300\"))\n",
    "seq_model.add(LSTM(units, name=\"lstm_300\"))\n",
    "seq_model.add(RepeatVector(max_text_length, name=\"repeat_vector_300\"))\n",
    "seq_model.add(LSTM(units,\n",
    "                   return_sequences=True,\n",
    "                   name=\"lstm_1_300\"))\n",
    "seq_model.add(Dense(vocab_size_cat,\n",
    "                    activation=\"softmax\",\n",
    "                    name=\"dense_300\"))\n",
    "\n",
    "seq_model.compile(\n",
    "    optimizer=RMSprop(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = seq_model.fit(\n",
    "    trainX,\n",
    "    trainY,\n",
    "    validation_data=(testX, testY),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "loss, acc = seq_model.evaluate(testX, testY, batch_size=batch_size, verbose=0)\n",
    "print(f\"Results (embedding=300):  loss={loss:.4f}, accuracy={acc:.4f}\")\n",
    "\n",
    "model_path = \"mt_seq_model_emb300.keras\"\n",
    "seq_model.save(model_path, save_format=\"keras\")\n",
    "print(f\"Model guardat a: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-6qAi33ReoD"
   },
   "source": [
    "**b. Exercici opcional: Experimentar amb el valor de longitud de seqüència** (*max_text_length*)\n",
    "\n",
    "Analitzar com un increment/reducció de la longitud de seqüència impacta en la qualitat del model de traducció.\n",
    "\n",
    "**Resultat esperat:** S'imprimirà el resultat que mostri el rendiment del model per a una longitud de seqüència superior o inferior a l'establert (per exemple, si es va inicialitzar el model preliminar amb el valor de 8, aquí es podria provar amb 4 i 12). El resultat constarà del valor de la longitud, i del score que indica l'efectivitat del model calculat amb *model.evaluate()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T07:39:55.390263Z",
     "iopub.status.busy": "2025-05-29T07:39:55.389535Z",
     "iopub.status.idle": "2025-05-29T07:51:46.894601Z",
     "shell.execute_reply": "2025-05-29T07:51:46.893893Z",
     "shell.execute_reply.started": "2025-05-29T07:39:55.390239Z"
    },
    "id": "qPgcB87FT-61",
    "outputId": "b3f84bbb-f94e-4603-be83-87035a11b6bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1748504401.055483     103 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 87ms/step - accuracy: 0.0338 - loss: 9.4038 - val_accuracy: 0.0388 - val_loss: 7.4571\n",
      "Epoch 2/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 86ms/step - accuracy: 0.0371 - loss: 7.5892 - val_accuracy: 0.0450 - val_loss: 7.4087\n",
      "Epoch 3/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 85ms/step - accuracy: 0.0371 - loss: 7.5483 - val_accuracy: 0.0388 - val_loss: 7.3930\n",
      "Epoch 4/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 85ms/step - accuracy: 0.0399 - loss: 7.5216 - val_accuracy: 0.0388 - val_loss: 7.3664\n",
      "Epoch 5/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 85ms/step - accuracy: 0.0415 - loss: 7.5123 - val_accuracy: 0.0302 - val_loss: 7.3556\n",
      "Epoch 6/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 85ms/step - accuracy: 0.0445 - loss: 7.4991 - val_accuracy: 0.0495 - val_loss: 7.3443\n",
      "Epoch 7/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 85ms/step - accuracy: 0.0454 - loss: 7.4695 - val_accuracy: 0.0517 - val_loss: 7.3373\n",
      "Epoch 8/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 85ms/step - accuracy: 0.0455 - loss: 7.4809 - val_accuracy: 0.0495 - val_loss: 7.3256\n",
      "Epoch 9/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 85ms/step - accuracy: 0.0496 - loss: 7.4598 - val_accuracy: 0.0590 - val_loss: 7.3145\n",
      "Epoch 10/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 85ms/step - accuracy: 0.0564 - loss: 7.4482 - val_accuracy: 0.0551 - val_loss: 7.3098\n",
      "Epoch 11/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 85ms/step - accuracy: 0.0571 - loss: 7.4239 - val_accuracy: 0.0675 - val_loss: 7.2991\n",
      "Epoch 12/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 85ms/step - accuracy: 0.0589 - loss: 7.4381 - val_accuracy: 0.0565 - val_loss: 7.2949\n",
      "Epoch 13/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 85ms/step - accuracy: 0.0600 - loss: 7.4210 - val_accuracy: 0.0666 - val_loss: 7.2790\n",
      "Epoch 14/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 85ms/step - accuracy: 0.0626 - loss: 7.4086 - val_accuracy: 0.0687 - val_loss: 7.2627\n",
      "Epoch 15/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 85ms/step - accuracy: 0.0622 - loss: 7.3965 - val_accuracy: 0.0616 - val_loss: 7.2348\n",
      "Epoch 16/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 85ms/step - accuracy: 0.0654 - loss: 7.3691 - val_accuracy: 0.0723 - val_loss: 7.2063\n",
      "Epoch 17/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 85ms/step - accuracy: 0.0672 - loss: 7.3356 - val_accuracy: 0.0683 - val_loss: 7.1912\n",
      "Epoch 18/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 85ms/step - accuracy: 0.0649 - loss: 7.3265 - val_accuracy: 0.0673 - val_loss: 7.1752\n",
      "Epoch 19/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 85ms/step - accuracy: 0.0675 - loss: 7.3051 - val_accuracy: 0.0716 - val_loss: 7.1647\n",
      "Epoch 20/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 85ms/step - accuracy: 0.0682 - loss: 7.2860 - val_accuracy: 0.0704 - val_loss: 7.1489\n",
      "Epoch 21/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 85ms/step - accuracy: 0.0684 - loss: 7.2809 - val_accuracy: 0.0707 - val_loss: 7.1460\n",
      "Epoch 22/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 85ms/step - accuracy: 0.0687 - loss: 7.2661 - val_accuracy: 0.0713 - val_loss: 7.1365\n",
      "Epoch 23/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 85ms/step - accuracy: 0.0669 - loss: 7.2602 - val_accuracy: 0.0694 - val_loss: 7.1274\n",
      "Epoch 24/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 85ms/step - accuracy: 0.0671 - loss: 7.2451 - val_accuracy: 0.0715 - val_loss: 7.1232\n",
      "Epoch 25/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 85ms/step - accuracy: 0.0682 - loss: 7.2473 - val_accuracy: 0.0713 - val_loss: 7.1128\n",
      "Results (embedding=200, maxlen=4): loss=7.1128, accuracy=0.0713\n",
      "Model desat a: models/mt_seq_emb200_len4.keras\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, RepeatVector, Dense\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import os\n",
    "\n",
    "#############################################\n",
    "# SOLUCIÓ                                   #\n",
    "#############################################\n",
    "# Possibles valors a provar:\n",
    "embedding_size   = 200\n",
    "max_text_length  = 4\n",
    "units            = 100\n",
    "epochs           = 25\n",
    "batch_size       = 128\n",
    "model_dir        = \"models\"\n",
    "\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "trainX = pad_sequences(train_eng_seq, maxlen=max_text_length, padding='post')\n",
    "testX  = pad_sequences(test_eng_seq,  maxlen=max_text_length, padding='post')\n",
    "trainY = pad_sequences(train_cat_seq, maxlen=max_text_length, padding='post')\n",
    "testY  = pad_sequences(test_cat_seq,  maxlen=max_text_length, padding='post')\n",
    "\n",
    "seq_model = Sequential(name=\"mt_seq_emb200_len4\")\n",
    "seq_model.add(Embedding(input_dim=vocab_size_eng,\n",
    "                        output_dim=embedding_size,\n",
    "                        input_length=max_text_length,\n",
    "                        name=\"embedding_200\"))\n",
    "seq_model.add(LSTM(units, name=\"lstm_200\"))\n",
    "seq_model.add(RepeatVector(max_text_length, name=\"repeat_vector_200\"))\n",
    "seq_model.add(LSTM(units, return_sequences=True, name=\"lstm_1_200\"))\n",
    "seq_model.add(Dense(vocab_size_cat,\n",
    "                    activation=\"softmax\",\n",
    "                    name=\"dense_200\"))\n",
    "\n",
    "seq_model.compile(\n",
    "    optimizer=RMSprop(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = seq_model.fit(\n",
    "    trainX, trainY,\n",
    "    validation_data=(testX, testY),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "loss, acc = seq_model.evaluate(testX, testY,\n",
    "                               batch_size=batch_size,\n",
    "                               verbose=0)\n",
    "print(f\"Results (embedding=200, maxlen=4): loss={loss:.4f}, accuracy={acc:.4f}\")\n",
    "\n",
    "save_path = os.path.join(model_dir, \"mt_seq_emb200_len4.keras\")\n",
    "seq_model.save(save_path, save_format=\"keras\")\n",
    "print(f\"Model desat a: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T07:52:10.566331Z",
     "iopub.status.busy": "2025-05-29T07:52:10.566049Z",
     "iopub.status.idle": "2025-05-29T08:15:17.631159Z",
     "shell.execute_reply": "2025-05-29T08:15:17.630481Z",
     "shell.execute_reply.started": "2025-05-29T07:52:10.566309Z"
    },
    "id": "vykqa4aVjJuf",
    "outputId": "8801d452-c5f4-4024-bb7c-5c496d88e865"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 171ms/step - accuracy: 0.1777 - loss: 7.7813 - val_accuracy: 0.1952 - val_loss: 6.2253\n",
      "Epoch 2/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 166ms/step - accuracy: 0.1824 - loss: 6.4183 - val_accuracy: 0.1952 - val_loss: 6.1980\n",
      "Epoch 3/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 167ms/step - accuracy: 0.1835 - loss: 6.3830 - val_accuracy: 0.1952 - val_loss: 6.1804\n",
      "Epoch 4/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 166ms/step - accuracy: 0.1866 - loss: 6.3487 - val_accuracy: 0.1952 - val_loss: 6.1755\n",
      "Epoch 5/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 166ms/step - accuracy: 0.1825 - loss: 6.3545 - val_accuracy: 0.1952 - val_loss: 6.1053\n",
      "Epoch 6/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 166ms/step - accuracy: 0.1840 - loss: 6.2506 - val_accuracy: 0.1952 - val_loss: 5.9480\n",
      "Epoch 7/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 167ms/step - accuracy: 0.1987 - loss: 6.0918 - val_accuracy: 0.2165 - val_loss: 5.8797\n",
      "Epoch 8/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 167ms/step - accuracy: 0.2044 - loss: 6.0513 - val_accuracy: 0.2116 - val_loss: 5.8603\n",
      "Epoch 9/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 167ms/step - accuracy: 0.2043 - loss: 6.0294 - val_accuracy: 0.2162 - val_loss: 5.8200\n",
      "Epoch 10/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 167ms/step - accuracy: 0.2050 - loss: 6.0114 - val_accuracy: 0.2101 - val_loss: 5.8694\n",
      "Epoch 11/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 167ms/step - accuracy: 0.2099 - loss: 5.9687 - val_accuracy: 0.2196 - val_loss: 5.7902\n",
      "Epoch 12/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 167ms/step - accuracy: 0.2094 - loss: 5.9639 - val_accuracy: 0.2149 - val_loss: 5.8158\n",
      "Epoch 13/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 167ms/step - accuracy: 0.2091 - loss: 5.9602 - val_accuracy: 0.2201 - val_loss: 5.7887\n",
      "Epoch 14/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 167ms/step - accuracy: 0.2104 - loss: 5.9494 - val_accuracy: 0.2208 - val_loss: 5.7659\n",
      "Epoch 15/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 167ms/step - accuracy: 0.2123 - loss: 5.9354 - val_accuracy: 0.2220 - val_loss: 5.7564\n",
      "Epoch 16/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 167ms/step - accuracy: 0.2143 - loss: 5.9220 - val_accuracy: 0.2251 - val_loss: 5.7355\n",
      "Epoch 17/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 166ms/step - accuracy: 0.2184 - loss: 5.8852 - val_accuracy: 0.2242 - val_loss: 5.7430\n",
      "Epoch 18/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 167ms/step - accuracy: 0.2180 - loss: 5.8844 - val_accuracy: 0.2247 - val_loss: 5.7249\n",
      "Epoch 19/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 167ms/step - accuracy: 0.2181 - loss: 5.8726 - val_accuracy: 0.2279 - val_loss: 5.7164\n",
      "Epoch 20/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 167ms/step - accuracy: 0.2215 - loss: 5.8485 - val_accuracy: 0.2286 - val_loss: 5.7325\n",
      "Epoch 21/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 167ms/step - accuracy: 0.2257 - loss: 5.8395 - val_accuracy: 0.2317 - val_loss: 5.6965\n",
      "Epoch 22/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 167ms/step - accuracy: 0.2256 - loss: 5.8347 - val_accuracy: 0.2239 - val_loss: 5.7353\n",
      "Epoch 23/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 167ms/step - accuracy: 0.2261 - loss: 5.8264 - val_accuracy: 0.2275 - val_loss: 5.7097\n",
      "Epoch 24/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 167ms/step - accuracy: 0.2299 - loss: 5.7797 - val_accuracy: 0.2347 - val_loss: 5.6849\n",
      "Epoch 25/25\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 167ms/step - accuracy: 0.2307 - loss: 5.7760 - val_accuracy: 0.2354 - val_loss: 5.7054\n",
      "Results (embedding=200, maxlen=4): loss=5.7054, accuracy=0.2354\n",
      "Model desat a: models/mt_seq_emb200_len12.keras\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, RepeatVector, Dense\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import os\n",
    "\n",
    "#############################################\n",
    "# SOLUCIÓ                                   #\n",
    "#############################################\n",
    "# Possibles valors a provar:\n",
    "embedding_size   = 200\n",
    "max_text_length  = 12\n",
    "units            = 100\n",
    "epochs           = 25\n",
    "batch_size       = 128\n",
    "model_dir        = \"models\"\n",
    "\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "trainX = pad_sequences(train_eng_seq, maxlen=max_text_length, padding='post')\n",
    "testX  = pad_sequences(test_eng_seq,  maxlen=max_text_length, padding='post')\n",
    "trainY = pad_sequences(train_cat_seq, maxlen=max_text_length, padding='post')\n",
    "testY  = pad_sequences(test_cat_seq,  maxlen=max_text_length, padding='post')\n",
    "\n",
    "seq_model = Sequential(name=\"mt_seq_emb200_len12\")\n",
    "seq_model.add(Embedding(input_dim=vocab_size_eng,\n",
    "                        output_dim=embedding_size,\n",
    "                        input_length=max_text_length,\n",
    "                        name=\"embedding_200\"))\n",
    "seq_model.add(LSTM(units, name=\"lstm_200\"))\n",
    "seq_model.add(RepeatVector(max_text_length, name=\"repeat_vector_200\"))\n",
    "seq_model.add(LSTM(units, return_sequences=True, name=\"lstm_1_200\"))\n",
    "seq_model.add(Dense(vocab_size_cat,\n",
    "                    activation=\"softmax\",\n",
    "                    name=\"dense_200\"))\n",
    "\n",
    "seq_model.compile(\n",
    "    optimizer=RMSprop(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = seq_model.fit(\n",
    "    trainX, trainY,\n",
    "    validation_data=(testX, testY),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "loss, acc = seq_model.evaluate(testX, testY,\n",
    "                               batch_size=batch_size,\n",
    "                               verbose=0)\n",
    "print(f\"Results (embedding=200, maxlen=4): loss={loss:.4f}, accuracy={acc:.4f}\")\n",
    "\n",
    "save_path = os.path.join(model_dir, \"mt_seq_emb200_len12.keras\")\n",
    "seq_model.save(save_path, save_format=\"keras\")\n",
    "print(f\"Model desat a: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cyb8LvH0rqrq"
   },
   "source": [
    "Segons els resultats obtinguts en aquest exercici 1.1.3, discutir en el *document d'Anàlisi* les diferències trobades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Re2z6jLm7nbP"
   },
   "source": [
    "## 1.2 TA amb Embeddings preentrenats (2,5 punts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nlktD0P3qK5w"
   },
   "source": [
    "\n",
    "En aquest apartat repetirem l'exercici anterior carregant a la capa d'embedding els pesos d'un model `GloVe` entrenat per a l'anglès.\n",
    "\n",
    "Aquest apartat 1.2 pot executar-se en diferents sessions de treball; no depèn de les seccions anteriors a excepció de:\n",
    "* Executar l'apartat *0. Connexió amb Drive* (o les cel·les que s'hagin definit per a altres entorns no Colab).\n",
    "* Executar la cel·la de preparació de dades (secció 1.1.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3MS7zPlqcAy"
   },
   "source": [
    "### 1.2.1 Càrrega de `GloVe`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxeXqLearl3b"
   },
   "source": [
    "**a. Començarem carregant el model `Glove`per a l'anglès.**\n",
    "\n",
    "Podeu utilitzar [`'glove.42B.300d.txt'`](https://www.kaggle.com/datasets/yutanakamura/glove42b300dtxt).\n",
    "\n",
    "**Sortida esperada:** mida de l'objecte carregat, utilitzar *len()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T08:35:35.110946Z",
     "iopub.status.busy": "2025-05-29T08:35:35.110122Z",
     "iopub.status.idle": "2025-05-29T08:37:52.901498Z",
     "shell.execute_reply": "2025-05-29T08:37:52.900685Z",
     "shell.execute_reply.started": "2025-05-29T08:35:35.110922Z"
    },
    "id": "CKCaeep9B29Z",
    "outputId": "c5dfd62c-c762-47f7-fb0f-c61945b92404"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to open glove file: /kaggle/input/glove-42b-300d-pr2/glove.42B.300d.txt\n",
      "Successfully opened glove file: glove.42B.300d.txt\n",
      "1917494\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "embeddings_index = {}\n",
    "\n",
    "glove=\"glove.42B.300d.txt\"\n",
    "my_path_pra2 = \"/kaggle/input/glove-42b-300d-pr2\"\n",
    "glove_path = os.path.join(my_path_pra2, glove)    #'my_path_pra2' definida en sección 0\n",
    "\n",
    "\n",
    "print(f\"Attempting to open glove file: {glove_path}\")\n",
    "try:\n",
    "    with open(glove_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "        print(f\"Successfully opened glove file: {glove}\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: File not found at opening file: {e}\")\n",
    "\n",
    "print(len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCu6o3oubiAI"
   },
   "source": [
    "### 1.2.2 Definició del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rcFO-1y_wjoh"
   },
   "source": [
    "**a. Construir la matriu d'embeddings.**\n",
    "\n",
    "A continuació, hem de construir la matriu d'embeddings.\n",
    "\n",
    "Per a no carregar tot el vocabulari del model, filtrarem només aquelles entrades presents en el vocabulari del tokenitzador que utilitzarem.\n",
    "\n",
    "A més, inclourem a la matriu de vectors els índexs de les entrades, paraules, que no constin en el model `glove` carregat. Aquests vectors se solen inicialitzar amb zeros o amb el resultat d'una distribució N (0, 1).\n",
    "\n",
    "**Sortida esperada:** Imprimir els 3 primers elements de la matriu d'embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T08:38:13.957447Z",
     "iopub.status.busy": "2025-05-29T08:38:13.957133Z",
     "iopub.status.idle": "2025-05-29T08:38:14.087883Z",
     "shell.execute_reply": "2025-05-29T08:38:14.087196Z",
     "shell.execute_reply.started": "2025-05-29T08:38:13.957425Z"
    },
    "id": "T0-OCm4XqcA4",
    "outputId": "9814ef86-d0ec-4c18-932d-a96fcffdf887"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeres 3 files de la matriu d'embeddings:\n",
      "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-2.08379999e-01 -1.49320006e-01 -1.75279994e-02 -2.84320004e-02\n",
      "  -6.01040013e-02 -2.64600009e-01 -4.14449978e+00  6.29320025e-01\n",
      "   3.36719990e-01 -4.33950007e-01  3.98990005e-01 -1.95730001e-01\n",
      "   1.39770001e-01 -2.15189997e-02  3.78230006e-01 -5.52500010e-01\n",
      "  -1.12300001e-01 -8.14430043e-03  2.90589988e-01  6.68170005e-02\n",
      "   1.04649998e-01 -8.69430006e-02 -4.89830002e-02 -2.67569989e-01\n",
      "  -4.70380008e-01  2.74690002e-01  6.92450032e-02 -2.79670004e-02\n",
      "  -1.97190002e-01  1.67490002e-02 -2.96810001e-01  1.78379998e-01\n",
      "   5.83739989e-02 -2.48060003e-01  8.58459994e-02  3.50430012e-01\n",
      "   4.91570011e-02 -1.64309993e-01  5.00119984e-01 -1.80529997e-01\n",
      "   3.14220011e-01  1.06710002e-01  3.18519995e-02  7.42779970e-02\n",
      "   2.79560000e-01  8.03169981e-02  5.47799990e-02 -3.03490013e-01\n",
      "  -4.32150006e-01  3.24169993e-01  4.08560008e-01  3.61919999e-01\n",
      "   1.34450004e-01 -1.29329994e-01  1.13310002e-01 -1.57550007e-01\n",
      "   3.57549995e-01  3.04630011e-01 -9.84880030e-02  1.20320003e-02\n",
      "   4.55810010e-01  3.71010005e-01  1.42700002e-01 -4.33290005e-01\n",
      "  -1.08690001e-01  4.98490006e-01  5.44550002e-01  4.43520010e-01\n",
      "   3.18040013e-01  2.21710000e-02 -4.11859989e-01 -2.54280008e-02\n",
      "   2.10620001e-01 -3.58300000e-01  2.20280007e-01 -5.53910017e-01\n",
      "  -3.53639983e-02 -5.39980009e-02  3.21720004e-01 -5.19280016e-01\n",
      "  -2.74269998e-01 -4.52140003e-01 -3.28999996e-01 -4.85190004e-01\n",
      "   5.29659986e-01  4.14340012e-03 -1.71800002e-01 -1.87480003e-01\n",
      "  -2.43650004e-01 -6.07860014e-02  5.07330000e-02 -2.13349998e-01\n",
      "   2.76270002e-01  4.27450001e-01  1.14610000e-02 -2.97939986e-01\n",
      "  -3.28810000e+00 -3.98420006e-01  1.67960003e-01 -1.28940001e-01\n",
      "   2.00049998e-03  4.56129998e-01  1.52150005e-01  1.53640002e-01\n",
      "  -2.12809995e-01 -2.53390014e-01  2.89550006e-01 -5.78170002e-01\n",
      "  -6.07400000e-01  1.03009999e-01  2.83239990e-01  2.15059996e-01\n",
      "  -4.23250012e-02  4.04790014e-01 -2.05789998e-01 -1.16740000e-02\n",
      "   2.60919988e-01 -1.54019997e-01  5.79609983e-02 -5.85759990e-02\n",
      "  -4.19739991e-01  5.20150006e-01  1.50739998e-01 -8.80390033e-02\n",
      "  -1.44459993e-01 -1.70739993e-01  8.37519988e-02 -2.57079989e-01\n",
      "   1.63619995e-01  1.47949994e-01 -5.98209985e-02  3.44729982e-02\n",
      "  -1.45339996e-01 -1.79649994e-01  7.63029978e-02  3.33539993e-01\n",
      "  -1.44339994e-01  1.76180005e-01  4.53449994e-01  1.52620003e-01\n",
      "  -7.50999972e-02  2.75920004e-01  8.14559981e-02  3.07379991e-01\n",
      "  -7.23270029e-02  1.07060000e-01 -3.55809987e-01 -2.66900007e-02\n",
      "   6.12360001e-01  7.08289981e-01 -2.89449990e-01 -2.46370006e-02\n",
      "   1.18899997e-02 -9.18990001e-02 -2.72720009e-01 -1.01570003e-01\n",
      "   4.47129995e-01  9.24180001e-02 -1.07110001e-01 -1.55520001e-02\n",
      "   1.28220007e-01  2.22560003e-01 -6.90589994e-02  2.99270004e-01\n",
      "  -1.09130003e-01  1.61799997e-01  1.47960007e-01  1.13600001e-01\n",
      "   2.66339988e-01  1.08319996e-02  7.19460025e-02  1.69729993e-01\n",
      "  -2.27689996e-01  3.21999997e-01 -8.37479979e-02  6.52689993e-01\n",
      "   6.82440028e-02 -3.26869994e-01  3.17820013e-01  1.70350000e-01\n",
      "   7.98030019e-01 -1.91939995e-01 -1.64849997e-01 -3.24369997e-01\n",
      "   7.91049972e-02 -3.56720001e-01 -2.67859995e-01 -2.47860000e-01\n",
      "   7.05120027e-01 -1.19089998e-01  1.62560001e-01 -4.32590008e-01\n",
      "  -5.00780009e-02  5.02320006e-02 -1.14500001e-01 -4.18849997e-02\n",
      "   4.78659987e-01  1.27670001e-02  1.96419999e-01  2.61960000e-01\n",
      "  -2.94250011e-01  8.96150023e-02 -1.77359998e-01 -2.24480003e-01\n",
      "   2.26239994e-01  1.67490005e-01  5.57699986e-02  1.43989995e-01\n",
      "   2.15800002e-01  3.38189989e-01  2.34589994e-01  1.58260003e-01\n",
      "  -2.85600007e-01  2.41990000e-01  1.10179998e-01  3.81639987e-01\n",
      "  -2.98400015e-01 -2.01690003e-01  2.69499987e-01  1.11860000e-01\n",
      "  -2.10060000e-01 -4.20700014e-02  1.65069997e-02 -2.28660002e-01\n",
      "  -3.38820004e+00  2.92039990e-01 -8.83579999e-02 -1.49659999e-02\n",
      "  -2.52249986e-01 -1.15029998e-01  3.63369994e-02 -1.48169994e-01\n",
      "   4.62200008e-02 -7.34660029e-02 -1.38659999e-01  2.36120000e-01\n",
      "   3.38819996e-02  2.94950008e-01 -6.12339973e-01  2.02889994e-01\n",
      "  -4.20910001e-01  3.77669990e-01  3.62600014e-02  2.17079997e-01\n",
      "   1.25609994e-01 -2.16820002e-01 -3.79969995e-03 -1.77910000e-01\n",
      "  -2.64310002e-01  3.16780001e-01 -5.12290001e-02  4.92689982e-02\n",
      "  -1.26220003e-01 -1.01170003e-01  1.72460005e-02 -2.19500009e-02\n",
      "  -1.98200002e-01  3.72500010e-02 -1.67909995e-01 -5.54590002e-02\n",
      "   5.76699972e-01  5.91229983e-02  2.29310006e-01  6.42009974e-02\n",
      "   2.74239987e-01 -3.71289998e-01 -9.13750008e-02 -7.13419989e-02\n",
      "  -3.72180007e-02 -1.26679996e-02 -1.79760009e-02 -4.26220000e-01\n",
      "  -1.00950003e-01  4.49919999e-02 -9.02250037e-02  2.29149997e-01\n",
      "   1.86100006e-01  3.63660008e-01 -2.06760004e-01 -3.30370009e-01\n",
      "   4.73019987e-01  2.33799994e-01  7.93059990e-02  2.10830003e-01\n",
      "   2.10130006e-01  1.52750000e-01  8.08729976e-02 -3.30130011e-01\n",
      "  -1.71810001e-01 -7.01700002e-02 -4.12440002e-02 -4.61820006e-01\n",
      "   2.79029999e-02  5.46570003e-01 -2.58940011e-01  3.95150006e-01\n",
      "   2.61440009e-01 -5.40660024e-01  2.11989999e-01 -9.43570025e-03]\n",
      " [-9.61100012e-02 -2.57880002e-01 -3.58599991e-01 -3.28869998e-01\n",
      "   5.79500020e-01 -5.17740011e-01 -4.15819979e+00 -1.13710001e-01\n",
      "  -1.08479999e-01 -4.88849998e-01  1.99310005e-01 -1.05400003e-01\n",
      "  -4.38250005e-01 -3.44830006e-01 -4.50520009e-01 -3.48639995e-01\n",
      "  -4.58000004e-01 -8.15540016e-01  2.20060006e-01  2.02539995e-01\n",
      "  -1.09540001e-01  1.25200003e-01 -5.41170001e-01  3.47310007e-01\n",
      "  -9.99979973e-02 -1.89980008e-02 -1.42770007e-01 -4.24809992e-01\n",
      "  -9.40909982e-03 -4.31549996e-01 -3.87689993e-02  1.21469997e-01\n",
      "   5.19879997e-01 -4.98400003e-01 -2.46250004e-01 -5.20669997e-01\n",
      "  -5.82100004e-02 -3.07119995e-01  2.55120009e-01  4.80329990e-02\n",
      "  -2.23130003e-01 -6.91819983e-03  3.98240015e-02 -5.00880003e-01\n",
      "  -1.19719997e-01 -7.90449977e-02  1.68800000e-02 -3.40519994e-01\n",
      "  -2.06599995e-01  8.12650025e-02  1.23520002e-01 -4.90069985e-01\n",
      "   3.49460006e-01 -2.92409986e-01  1.48929998e-01  1.36600003e-01\n",
      "  -9.78299975e-02 -6.84719980e-02 -1.09130004e-02  2.84540001e-03\n",
      "  -1.26560003e-01  3.42700005e-01  1.05800003e-01 -4.61510003e-01\n",
      "   7.01330006e-02 -6.13429993e-02 -1.50210001e-02  1.76589996e-01\n",
      "   1.79409996e-01 -5.13769984e-01 -3.13809991e-01 -1.37199998e-01\n",
      "   4.51860018e-02 -8.22589993e-02  2.15149999e-01 -2.19549999e-01\n",
      "   1.03129998e-01 -2.07039997e-01  1.40410006e-01 -3.51509988e-01\n",
      "   6.23160005e-01 -5.79900026e-01 -5.61150014e-02 -2.17460003e-03\n",
      "   1.89579993e-01  2.23979995e-01  1.22460000e-01 -2.61779994e-01\n",
      "   1.07789999e-02 -3.12680006e-01 -2.14469999e-01  3.53439987e-01\n",
      "  -2.60409992e-02  1.82319991e-02  3.57510000e-01 -7.01880008e-02\n",
      "  -3.08719993e+00 -1.31310001e-01  1.73870008e-02  2.32439995e-01\n",
      "  -6.05849996e-02  2.06790000e-01  5.75789988e-01  3.63380015e-01\n",
      "  -4.15740013e-01  3.06070000e-02  2.36190006e-01 -1.12839997e-01\n",
      "  -3.60430002e-01  2.16350004e-01 -2.75199991e-02  1.75019994e-01\n",
      "   4.34909999e-01 -8.82470012e-02  4.07539994e-01 -4.85509992e-01\n",
      "   1.35389999e-01 -9.07590017e-02  1.44229993e-01  3.41179997e-01\n",
      "  -3.79400015e-01 -2.73440003e-01  2.59300005e-02  7.32169971e-02\n",
      "  -1.01760000e-01  1.65509999e-01 -2.32779995e-01 -1.85629994e-01\n",
      "   2.13719998e-02 -9.31110010e-02  1.51789993e-01  1.50570005e-01\n",
      "   5.51479995e-01 -2.00880006e-01 -7.94949979e-02  2.25989997e-01\n",
      "   2.62430012e-01  2.51230001e-01  6.02660000e-01 -2.04229996e-01\n",
      "   3.69720012e-01 -1.06940001e-01  7.28869997e-03  1.83589999e-02\n",
      "   2.23680004e-01 -1.40650004e-01  1.11199997e-01  8.76670033e-02\n",
      "   8.46599996e-01  3.15450013e-01 -1.53479993e-01  2.03109998e-02\n",
      "   2.08780002e-02  3.86510015e-01  4.74219993e-02 -2.48539999e-01\n",
      "  -1.90530002e-01  4.91730005e-01  3.81609984e-02 -2.10379995e-02\n",
      "   1.44960001e-01  1.15910001e-01 -1.51050001e-01 -1.89420000e-01\n",
      "   1.87030002e-01  2.67520007e-02  4.65229992e-03  3.98140013e-01\n",
      "  -1.86170004e-02 -7.31769979e-01  7.28320032e-02  4.15349990e-01\n",
      "  -4.88180012e-01  3.04000010e-03 -2.27290004e-01  8.82480025e-01\n",
      "  -6.16119981e-01 -1.89009994e-01 -3.34910005e-01 -2.86720008e-01\n",
      "  -1.31430002e-02 -3.75449985e-01 -1.84430003e-01 -5.52179992e-01\n",
      "   7.01860011e-01 -7.31069967e-02  6.39299989e-01  1.30980000e-01\n",
      "   7.15859979e-02  5.36409998e-03  2.46360004e-01 -7.07440019e-01\n",
      "  -4.50360000e-01  6.01870008e-04 -3.90929997e-01 -2.71600001e-02\n",
      "   2.55890012e-01 -1.73130006e-01  2.98830003e-01 -9.09470022e-04\n",
      "   8.31400007e-02 -4.09900010e-01 -1.30240005e-02 -4.95329984e-02\n",
      "   3.04100007e-01  6.43019974e-01  2.30450004e-01 -1.87570006e-01\n",
      "   3.75839993e-02 -2.60820001e-01  1.75300002e-01 -6.28150031e-02\n",
      "  -2.25690007e-01 -1.21299997e-01  1.55239999e-01 -1.44069999e-01\n",
      "   8.87319967e-02  3.46740007e-01 -4.34940010e-01  3.86880010e-01\n",
      "  -1.57330006e-01 -1.27210006e-01  3.01939994e-01  3.20340008e-01\n",
      "  -3.32640004e+00  6.94269985e-02  1.38479993e-01 -5.82160018e-02\n",
      "  -2.70879995e-02  1.10280000e-01  3.40400010e-01  1.86539993e-01\n",
      "   1.15220003e-01 -4.03809994e-01  4.47760001e-02  1.55350000e-01\n",
      "   1.62469998e-01 -2.40510002e-01  4.72900011e-02  3.49799991e-02\n",
      "  -7.59420022e-02  1.55980006e-01 -5.98729998e-02  4.67430009e-03\n",
      "   1.55949995e-01 -2.76129991e-01  1.35619998e-01  1.34849995e-01\n",
      "  -7.37240016e-02  3.14209998e-01  3.12339999e-02 -2.35159993e-01\n",
      "   3.10050011e-01 -1.03749998e-01 -3.07830006e-01 -5.53269982e-01\n",
      "   2.83039987e-01  8.14289972e-02  3.77779990e-01  1.57250002e-01\n",
      "   1.17570003e-02  4.30059992e-02 -4.34230000e-01 -2.27180004e-01\n",
      "  -4.32920009e-02 -6.36170030e-01 -8.93899977e-01 -1.74060002e-01\n",
      "   4.11110014e-01 -1.44040003e-01 -1.67799994e-01 -4.44379985e-01\n",
      "  -7.30509996e-01  1.09569997e-01  1.31219998e-01  8.56230035e-02\n",
      "   1.25039995e-01 -4.03369993e-01  4.17650007e-02 -2.75739998e-01\n",
      "   6.25130013e-02  5.10930009e-02  3.99260014e-01  1.11489996e-01\n",
      "  -5.64620011e-02  2.68090010e-01 -3.95689994e-01  3.10330003e-01\n",
      "  -4.97500002e-02 -3.31389993e-01  4.77809995e-01 -2.12130006e-02\n",
      "  -2.12359995e-01  4.23740000e-01  1.40829995e-01  6.74979985e-02\n",
      "  -1.26750007e-01 -3.70299995e-01 -9.27739963e-02  3.90579998e-01]]\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# SOLUCIÓ                                   #\n",
    "#############################################\n",
    "\n",
    "embedding_dim   = 300\n",
    "vocab_size_eng  = len(eng_tokenizer.word_index) + 1\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size_eng, embedding_dim))\n",
    "\n",
    "for word, idx in eng_tokenizer.word_index.items():\n",
    "    if idx < vocab_size_eng:\n",
    "        vector = embeddings_index.get(word)\n",
    "        if vector is not None:\n",
    "            embedding_matrix[idx] = vector\n",
    "        else:\n",
    "            embedding_matrix[idx] = np.random.normal(loc=0.0, scale=1.0, size=embedding_dim)\n",
    "\n",
    "print(\"Primeres 3 files de la matriu d'embeddings:\")\n",
    "print(embedding_matrix[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKfscNIFsAPq"
   },
   "source": [
    "**b. Inicialitzar la capa d'embeddings.**\n",
    "\n",
    "Per a inicialitzar una capa d'embeddings amb pesos predefinits s'utilitza l'argument `weights`. A més, como no volem que es modifiquin els pesos, marquem l'argument `trainable` com a `False`.\n",
    "\n",
    "Seguint amb el nostre exemple, faríem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T08:55:31.803234Z",
     "iopub.status.busy": "2025-05-29T08:55:31.802531Z",
     "iopub.status.idle": "2025-05-29T08:55:35.511269Z",
     "shell.execute_reply": "2025-05-29T08:55:35.510525Z",
     "shell.execute_reply.started": "2025-05-29T08:55:31.803210Z"
    },
    "id": "UkvFG3HyjJuh",
    "outputId": "53b0ce65-382a-44c3-9f81-94ae1fc21a3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX.shape, testX.shape: (42156, 8) (10540, 8)\n",
      "Primeres 3 seqüències codificades (trainX):\n",
      " [[ 828   98   34    1   60  998    4 3526]\n",
      " [2029 7061 8103 6335 7061 2373 2373    0]\n",
      " [  11   16   47   30  146  248    0    0]]\n"
     ]
    }
   ],
   "source": [
    "# ----------------------\n",
    "# Depenent de la infraestructura del sistema,\n",
    "# la longitud de seqüència es pot iniciar amb un valor de 8.\n",
    "max_text_length = 8\n",
    "# ----------------------\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################\n",
    "\n",
    "eng_tokenizer = Tokenizer()\n",
    "cat_tokenizer = Tokenizer()\n",
    "\n",
    "eng_tokenizer.fit_on_texts(eng_train)\n",
    "cat_tokenizer.fit_on_texts(cat_train)\n",
    "\n",
    "train_eng_seq = eng_tokenizer.texts_to_sequences(eng_train)\n",
    "test_eng_seq  = eng_tokenizer.texts_to_sequences(eng_test)\n",
    "train_cat_seq = cat_tokenizer.texts_to_sequences(cat_train)\n",
    "test_cat_seq  = cat_tokenizer.texts_to_sequences(cat_test)\n",
    "\n",
    "trainX = pad_sequences(train_eng_seq, maxlen=max_text_length, padding='post')\n",
    "testX  = pad_sequences(test_eng_seq,  maxlen=max_text_length, padding='post')\n",
    "trainY = pad_sequences(train_cat_seq, maxlen=max_text_length, padding='post')\n",
    "testY  = pad_sequences(test_cat_seq,  maxlen=max_text_length, padding='post')\n",
    "\n",
    "print(\"trainX.shape, testX.shape:\", trainX.shape, testX.shape)\n",
    "print(\"Primeres 3 seqüències codificades (trainX):\\n\", trainX[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T08:55:45.516106Z",
     "iopub.status.busy": "2025-05-29T08:55:45.515296Z",
     "iopub.status.idle": "2025-05-29T08:55:45.603231Z",
     "shell.execute_reply": "2025-05-29T08:55:45.602632Z",
     "shell.execute_reply.started": "2025-05-29T08:55:45.516081Z"
    },
    "id": "QLjfzHAq7nbR"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "# Es podria experimentar amb diferents models, variant paràmetres com ara 'embedding_vec_length' i 'max_text_length'\n",
    "# A l'entrenar nous models, recordar:\n",
    "# - O bé modificar el nom del model en el paràmetre callback (variable 'model_path') de la classe 'fit'\n",
    "# - O bé (opció recomanada), un cop finalitza l'entrenament, reanomenar el model emmagatzemat segons 'model_path'.\n",
    "#\n",
    "\n",
    "embedding_vec_length = 200 # Ajustar si fa falta\n",
    "max_text_length = 8 # Ajustar si fa falta\n",
    "\n",
    "#############################################\n",
    "# SOLUCIÓ                                   #\n",
    "#############################################\n",
    "\n",
    "seq_model = Sequential(name=\"mt_seq_glove_emb300\")\n",
    "seq_model.add(Embedding(\n",
    "    input_dim=vocab_size_eng,\n",
    "    output_dim=embedding_dim,\n",
    "    input_length=max_text_length,\n",
    "    weights=[embedding_matrix],\n",
    "    trainable=False,\n",
    "    name=\"embedding_glove\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6lijj-QRsnO8"
   },
   "source": [
    "**c. Definició del nou model considerant els pesos del model preentrenat.**\n",
    "\n",
    " Implementa i entrena de nou un model de traducció automàtica de **l'idioma origen** a  **l'idioma destí**; aquest cop carregant els pesos de la capa embedding a partir del model `Glove` preentrenat en anglès i disponible a `glove.42B.300d.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T08:55:49.853758Z",
     "iopub.status.busy": "2025-05-29T08:55:49.852913Z",
     "iopub.status.idle": "2025-05-29T08:55:49.886178Z",
     "shell.execute_reply": "2025-05-29T08:55:49.885642Z",
     "shell.execute_reply.started": "2025-05-29T08:55:49.853724Z"
    },
    "id": "9hKTQCdp7nbS",
    "outputId": "bbfd0f91-da38-4a5b-8548-efe0999b629e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"mt_seq_glove_emb300\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"mt_seq_glove_emb300\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_glove (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)          │ ?                           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">8,115,300</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_enc (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ repeat_vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)         │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_dec (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_glove (\u001b[38;5;33mEmbedding\u001b[0m)          │ ?                           │       \u001b[38;5;34m8,115,300\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_enc (\u001b[38;5;33mLSTM\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ repeat_vector (\u001b[38;5;33mRepeatVector\u001b[0m)         │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_dec (\u001b[38;5;33mLSTM\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_out (\u001b[38;5;33mDense\u001b[0m)                    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,115,300</span> (30.96 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,115,300\u001b[0m (30.96 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,115,300</span> (30.96 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m8,115,300\u001b[0m (30.96 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#############################################\n",
    "# SOLUCIÓ                                  #\n",
    "#############################################\n",
    "\n",
    "# ... una cop definit embedding_layer, definim el model\n",
    "\n",
    "seq_model.add(LSTM(units, name=\"lstm_enc\"))\n",
    "seq_model.add(RepeatVector(max_text_length, name=\"repeat_vector\"))\n",
    "seq_model.add(LSTM(units, return_sequences=True, name=\"lstm_dec\"))\n",
    "seq_model.add(Dense(vocab_size_cat, activation=\"softmax\", name=\"dense_out\"))\n",
    "\n",
    "seq_model.compile(\n",
    "    optimizer=RMSprop(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "seq_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vi7XA1rQfcqT"
   },
   "source": [
    "### 1.2.3 Entrenament del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wFa-V2gnszdl"
   },
   "source": [
    "**Entrenar i guardar el model.**\n",
    "\n",
    "Tot i que aquest entrenament és més 'lleuger' que l'anterior, recomanem l'ús de GPU si és viable.\n",
    "\n",
    "**Suggeriments:**\n",
    "\n",
    "- Provar amb diferents valors *batch_size*. En el notebook d'exemple es va treballar bé amb el valor de 128.\n",
    "\n",
    "- Observar com evoluciona el model després de cada *epoch*; en caso de no observar millores, es pot disminuir el seu valor. En el notebook d'exemple es va baixar el valor a 50 perquè a partir de l'epoch 32 no es va observar millora.\n",
    "\n",
    "- Revisar el `Notebook d'Exemple`, secció 1.2.3.2, en el que proporcionem pautes i guies per a dur un millor control de les execucions quan s'ha de reiniciar la sessió o s'exhaureix la memòria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T08:55:52.820761Z",
     "iopub.status.busy": "2025-05-29T08:55:52.820483Z",
     "iopub.status.idle": "2025-05-29T09:26:59.455567Z",
     "shell.execute_reply": "2025-05-29T09:26:59.454890Z",
     "shell.execute_reply.started": "2025-05-29T08:55:52.820743Z"
    },
    "id": "l58sRZaY7nbS",
    "outputId": "f870b294-93b9-4529-a324-34552a4ae684",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 144ms/step - accuracy: 0.0903 - loss: 8.1076 - val_accuracy: 0.1055 - val_loss: 6.8093\n",
      "Epoch 2/40\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 140ms/step - accuracy: 0.0954 - loss: 6.9830 - val_accuracy: 0.1055 - val_loss: 6.7850\n",
      "Epoch 3/40\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 141ms/step - accuracy: 0.0972 - loss: 6.9588 - val_accuracy: 0.1055 - val_loss: 6.7731\n",
      "Epoch 4/40\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 141ms/step - accuracy: 0.0958 - loss: 6.9483 - val_accuracy: 0.1055 - val_loss: 6.7731\n",
      "Epoch 5/40\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 141ms/step - accuracy: 0.0972 - loss: 6.9401 - val_accuracy: 0.1055 - val_loss: 6.7608\n",
      "Epoch 6/40\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 141ms/step - accuracy: 0.0971 - loss: 6.9282 - val_accuracy: 0.1055 - val_loss: 6.7539\n",
      "Epoch 7/40\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 141ms/step - accuracy: 0.0970 - loss: 6.9182 - val_accuracy: 0.1055 - val_loss: 6.7424\n",
      "Epoch 8/40\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 141ms/step - accuracy: 0.0977 - loss: 6.9018 - val_accuracy: 0.1055 - val_loss: 6.7407\n",
      "Epoch 9/40\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 140ms/step - accuracy: 0.0977 - loss: 6.8991 - val_accuracy: 0.1055 - val_loss: 6.6918\n",
      "Epoch 10/40\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 141ms/step - accuracy: 0.0960 - loss: 6.8402 - val_accuracy: 0.1055 - val_loss: 6.6218\n",
      "Epoch 11/40\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 141ms/step - accuracy: 0.1080 - loss: 6.7742 - val_accuracy: 0.1281 - val_loss: 6.5472\n",
      "Epoch 12/40\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 141ms/step - accuracy: 0.1192 - loss: 6.7079 - val_accuracy: 0.1285 - val_loss: 6.5146\n",
      "Epoch 13/40\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 141ms/step - accuracy: 0.1238 - loss: 6.6577 - val_accuracy: 0.1355 - val_loss: 6.4639\n",
      "Epoch 14/40\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 141ms/step - accuracy: 0.1283 - loss: 6.6319 - val_accuracy: 0.1369 - val_loss: 6.4423\n",
      "Epoch 15/40\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 141ms/step - accuracy: 0.1309 - loss: 6.5944 - val_accuracy: 0.1406 - val_loss: 6.4212\n",
      "Epoch 16/40\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 141ms/step - accuracy: 0.1329 - loss: 6.5705 - val_accuracy: 0.1409 - val_loss: 6.4008\n",
      "Epoch 17/40\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 141ms/step - accuracy: 0.1352 - loss: 6.5450 - val_accuracy: 0.1376 - val_loss: 6.4011\n",
      "Epoch 18/40\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 141ms/step - accuracy: 0.1364 - loss: 6.5282 - val_accuracy: 0.1456 - val_loss: 6.3705\n",
      "Epoch 19/40\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 141ms/step - accuracy: 0.1390 - loss: 6.5031 - val_accuracy: 0.1463 - val_loss: 6.3592\n",
      "Epoch 20/40\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 141ms/step - accuracy: 0.1386 - loss: 6.5029 - val_accuracy: 0.1482 - val_loss: 6.3444\n",
      "Epoch 21/40\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 141ms/step - accuracy: 0.1422 - loss: 6.4747 - val_accuracy: 0.1519 - val_loss: 6.3204\n",
      "Epoch 22/40\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 141ms/step - accuracy: 0.1443 - loss: 6.4623 - val_accuracy: 0.1552 - val_loss: 6.3138\n",
      "Epoch 23/40\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 140ms/step - accuracy: 0.1487 - loss: 6.4367 - val_accuracy: 0.1591 - val_loss: 6.2759\n",
      "Epoch 24/40\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 141ms/step - accuracy: 0.1519 - loss: 6.4057 - val_accuracy: 0.1574 - val_loss: 6.2684\n",
      "Epoch 25/40\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 140ms/step - accuracy: 0.1529 - loss: 6.3766 - val_accuracy: 0.1617 - val_loss: 6.2273\n",
      "Epoch 26/40\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 140ms/step - accuracy: 0.1558 - loss: 6.3428 - val_accuracy: 0.1546 - val_loss: 6.2422\n",
      "Epoch 27/40\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 141ms/step - accuracy: 0.1549 - loss: 6.3261 - val_accuracy: 0.1626 - val_loss: 6.2084\n",
      "Epoch 28/40\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 141ms/step - accuracy: 0.1588 - loss: 6.2815 - val_accuracy: 0.1632 - val_loss: 6.1671\n",
      "Epoch 29/40\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 140ms/step - accuracy: 0.1581 - loss: 6.2592 - val_accuracy: 0.1653 - val_loss: 6.1608\n",
      "Epoch 30/40\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 141ms/step - accuracy: 0.1628 - loss: 6.2175 - val_accuracy: 0.1653 - val_loss: 6.1447\n",
      "Epoch 31/40\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 141ms/step - accuracy: 0.1628 - loss: 6.1892 - val_accuracy: 0.1677 - val_loss: 6.1115\n",
      "Epoch 32/40\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 140ms/step - accuracy: 0.1668 - loss: 6.1349 - val_accuracy: 0.1633 - val_loss: 6.0998\n",
      "Epoch 33/40\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 141ms/step - accuracy: 0.1675 - loss: 6.1188 - val_accuracy: 0.1693 - val_loss: 6.0789\n",
      "Epoch 34/40\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 140ms/step - accuracy: 0.1670 - loss: 6.0998 - val_accuracy: 0.1717 - val_loss: 6.0403\n",
      "Epoch 35/40\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 141ms/step - accuracy: 0.1705 - loss: 6.0539 - val_accuracy: 0.1724 - val_loss: 6.0161\n",
      "Epoch 36/40\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 140ms/step - accuracy: 0.1724 - loss: 6.0176 - val_accuracy: 0.1671 - val_loss: 6.0267\n",
      "Epoch 37/40\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 141ms/step - accuracy: 0.1748 - loss: 5.9873 - val_accuracy: 0.1740 - val_loss: 5.9833\n",
      "Epoch 38/40\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 140ms/step - accuracy: 0.1741 - loss: 5.9686 - val_accuracy: 0.1745 - val_loss: 5.9857\n",
      "Epoch 39/40\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 140ms/step - accuracy: 0.1745 - loss: 5.9500 - val_accuracy: 0.1718 - val_loss: 5.9563\n",
      "Epoch 40/40\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 141ms/step - accuracy: 0.1751 - loss: 5.9240 - val_accuracy: 0.1696 - val_loss: 5.9617\n",
      "Results (Glove emb=300):  loss=5.9617, accuracy=0.1696\n",
      "Model guardat a: mt_seq_glove_emb300.keras\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# SOLUCIÓ                                   #\n",
    "#############################################\n",
    "\n",
    "# entrenem i guardem el model\n",
    "\n",
    "epochs = 40\n",
    "batch_size = 128\n",
    "\n",
    "history = seq_model.fit(\n",
    "    trainX,\n",
    "    trainY,\n",
    "    validation_data=(testX, testY),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "loss, acc = seq_model.evaluate(testX, testY, batch_size=batch_size, verbose=0)\n",
    "print(f\"Results (Glove emb={embedding_dim}):  loss={loss:.4f}, accuracy={acc:.4f}\")\n",
    "\n",
    "model_path = f\"mt_seq_glove_emb{embedding_dim}.keras\"\n",
    "seq_model.save(model_path, save_format=\"keras\")\n",
    "print(f\"Model guardat a: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YLgsT8ebQn03"
   },
   "source": [
    "### 1.2.4 Generar prediccions\n",
    "\n",
    "En aquest pas, aplicar el model per a generar les prediccions utilitzant l'arxiu de test.\n",
    "\n",
    "**Resultat esperat:**\n",
    "\n",
    "- Visualitzar la taula de resultats: frase en l'idioma origen, text traduït real vs. text traduït generat.\n",
    "\n",
    "**Suggeriment:** Si durant l'execució, cancel·la la predicció per exhaurir-se la memòria disponible, recarregar el model des de local (veure apartat 1.2.3.2 del `Notebook d'Exemple`) i predir només per a un subconjunt de l'arxiu de test (tot i que en aquest cas no seran vàlides les magnituds de medició de qualitat del sistema).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T09:42:01.013965Z",
     "iopub.status.busy": "2025-05-29T09:42:01.013645Z",
     "iopub.status.idle": "2025-05-29T09:42:02.007338Z",
     "shell.execute_reply": "2025-05-29T09:42:02.006514Z",
     "shell.execute_reply.started": "2025-05-29T09:42:01.013943Z"
    },
    "id": "efztL7bg7nbT",
    "outputId": "a3349f47-e30c-4b8c-9572-2ca3867507bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English (ORIG)</th>\n",
       "      <th>Catalan (REAL)</th>\n",
       "      <th>Catalan (PREDICTED)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>its the most powerful thing you own</td>\n",
       "      <td>és la cosa més poderosa que posseeixes</td>\n",
       "      <td>és és és és la la la la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>are they so different</td>\n",
       "      <td>realment són tan diferents</td>\n",
       "      <td>i són són són</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this isnt a second class exercise</td>\n",
       "      <td>aquest no és un exercici secundari</td>\n",
       "      <td>és és és en a de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in my second chemo my mother got very sick and i went to see her</td>\n",
       "      <td>en la meva segona químio la meva mare es va posar molt malalta i vaig anar a visitarla</td>\n",
       "      <td>i i i i i a a meva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>or perhaps an ordinary person like you or me</td>\n",
       "      <td>o potser és una persona normal i corrent com ara tu o jo</td>\n",
       "      <td>un una que o o o o cosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>despite the presence of plaques and tangles and brain shrinkage  what appeared to be unquestionable alzheimers  the nuns who had belonged to these brains showed no signs of having the disease while they were alive</td>\n",
       "      <td>tot i la presència de plaques cabdells i reducció del cervell que semblava indubtablement alzheimer les monges no havien mostrat senyals dalzheimer en vida</td>\n",
       "      <td>la la les les que que que que</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>i dont know if id try that but its available</td>\n",
       "      <td>no sé si la provaria però és disponible</td>\n",
       "      <td>que que que que que que no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>they look upon their body as a form of transport for their heads</td>\n",
       "      <td>veuen el seu cos com una forma de transport pels seus caps no</td>\n",
       "      <td>un a a a a la la la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>so anyone walking by can pick up a piece of chalk reflect on their life and share their personal aspirations in public space</td>\n",
       "      <td>així qualsevol que hi passi pot agafar un tros de guix reflexionar sobre la seva vida i compartir les aspiracions personals en un espai públic</td>\n",
       "      <td>i i la la la la la vida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>now these large numbers are just one part of the story</td>\n",
       "      <td>però aquests grans números només són una part de la història</td>\n",
       "      <td>i és és un de la de del</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                           English (ORIG)  \\\n",
       "0                                                                                                                                                                                     its the most powerful thing you own   \n",
       "1                                                                                                                                                                                                   are they so different   \n",
       "2                                                                                                                                                                                       this isnt a second class exercise   \n",
       "3                                                                                                                                                        in my second chemo my mother got very sick and i went to see her   \n",
       "4                                                                                                                                                                            or perhaps an ordinary person like you or me   \n",
       "..                                                                                                                                                                                                                    ...   \n",
       "95  despite the presence of plaques and tangles and brain shrinkage  what appeared to be unquestionable alzheimers  the nuns who had belonged to these brains showed no signs of having the disease while they were alive   \n",
       "96                                                                                                                                                                           i dont know if id try that but its available   \n",
       "97                                                                                                                                                       they look upon their body as a form of transport for their heads   \n",
       "98                                                                                           so anyone walking by can pick up a piece of chalk reflect on their life and share their personal aspirations in public space   \n",
       "99                                                                                                                                                                 now these large numbers are just one part of the story   \n",
       "\n",
       "                                                                                                                                                 Catalan (REAL)  \\\n",
       "0                                                                                                                        és la cosa més poderosa que posseeixes   \n",
       "1                                                                                                                                    realment són tan diferents   \n",
       "2                                                                                                                            aquest no és un exercici secundari   \n",
       "3                                                                        en la meva segona químio la meva mare es va posar molt malalta i vaig anar a visitarla   \n",
       "4                                                                                                      o potser és una persona normal i corrent com ara tu o jo   \n",
       "..                                                                                                                                                          ...   \n",
       "95  tot i la presència de plaques cabdells i reducció del cervell que semblava indubtablement alzheimer les monges no havien mostrat senyals dalzheimer en vida   \n",
       "96                                                                                                                      no sé si la provaria però és disponible   \n",
       "97                                                                                                veuen el seu cos com una forma de transport pels seus caps no   \n",
       "98               així qualsevol que hi passi pot agafar un tros de guix reflexionar sobre la seva vida i compartir les aspiracions personals en un espai públic   \n",
       "99                                                                                                 però aquests grans números només són una part de la història   \n",
       "\n",
       "              Catalan (PREDICTED)  \n",
       "0         és és és és la la la la  \n",
       "1                   i són són són  \n",
       "2                és és és en a de  \n",
       "3              i i i i i a a meva  \n",
       "4         un una que o o o o cosa  \n",
       "..                            ...  \n",
       "95  la la les les que que que que  \n",
       "96     que que que que que que no  \n",
       "97            un a a a a la la la  \n",
       "98        i i la la la la la vida  \n",
       "99        i és és un de la de del  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apliquem el model i visualitzem resultats\n",
    "\n",
    "# Si degut a la configuració escollida no es pot realitzar la predicció per problemes de memòria\n",
    "# amb l'arxiu sencer de testX, utilitzar-ne un subconjunt.\n",
    "\n",
    "reducir_test = True    # Canvia a True per a només les primeres 100 frases\n",
    "if reducir_test:\n",
    "    testX_to_pred = testX[:100]\n",
    "    eng_to_pred   = eng_test[:100]\n",
    "    cat_to_pred   = cat_test[:100]\n",
    "else:\n",
    "    testX_to_pred = testX\n",
    "    eng_to_pred   = eng_test\n",
    "    cat_to_pred   = cat_test\n",
    "\n",
    "\n",
    "#############################################\n",
    "# SOLUCIÓ                                   #\n",
    "#############################################\n",
    "\n",
    "pred_probs = seq_model.predict(testX_to_pred, batch_size=1)\n",
    "pred_ids   = np.argmax(pred_probs, axis=-1)\n",
    "\n",
    "index_to_word = {idx: word for word, idx in cat_tokenizer.word_index.items()}\n",
    "index_to_word[0] = \"\"\n",
    "\n",
    "def decode_sequence(seq):\n",
    "    return \" \".join(\n",
    "        index_to_word.get(idx, \"\") for idx in seq if idx != 0\n",
    "    ).strip()\n",
    "\n",
    "decoded_preds = [decode_sequence(seq) for seq in pred_ids]\n",
    "\n",
    "df_results = pd.DataFrame({\n",
    "    'English (ORIG)':        eng_to_pred,\n",
    "    'Catalan (REAL)':        cat_to_pred,\n",
    "    'Catalan (PREDICTED)':   decoded_preds\n",
    "})\n",
    "\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpRSYwVIwqZ1"
   },
   "source": [
    "# 2 Detecció de NER i NEL (3 punts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2QdsM57uxFa"
   },
   "source": [
    "En aquesta segona part, ens enfocarem en la detección de entidades anomenades (`NER`).\n",
    "\n",
    "A més, experimentarem amb 'Named Entity Linking' (`NEL`) per a buscar entitats enllaçades a una base de coneixement (KB), en aquest cas *Wikidata*. Identificarem els enllaços a Wikidata de certes entitats d'un text utilitzant la API de Wikidata.\n",
    "\n",
    "**Aquest apartat pot executar-se aïlladament**, no depèn de l'apartat anterior, a excepció d'executar l'apartat *0. Connexió amb Drive* (o les cel·les que s'hagin definit per a altres entorns no Colab)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OoSNLW2HjNNY",
    "outputId": "752d19ca-ee14-437e-fad2-484bf1941ebb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Accedir a Colab myDrive\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\", force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l_JRpFeqjdAN",
    "outputId": "5064741e-a1c5-4eea-cddf-02dbd4d98b6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorio arrel canviat a: '/content/drive/MyDrive/UOC/20242_ADT/PRA2'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Establir el directori arrel\n",
    "\n",
    "# Canviar aquest directori arell si és necessari però seguint l'estructura de directoris descrita\n",
    "my_path_pra2 = \"/content/drive/MyDrive/UOC/20242_ADT/PRA2\"\n",
    "\n",
    "if os.path.exists(my_path_pra2):\n",
    "    try:\n",
    "        os.chdir(my_path_pra2)\n",
    "        print(f\"Directorio arrel canviat a: '{os.getcwd()}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error canviant al directori: '{my_path_pra2}'. Error: {e}\")\n",
    "else:\n",
    "    print(f\"Directori '{my_path_pra2}' no existeix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aMfY2OzVqcA6"
   },
   "source": [
    "## 2.1 Detecció de NER (2 punts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GE_kPjM-vGXc"
   },
   "source": [
    "En aquesta primera subsecció, detectarem entitats anomenades (`NER`), utilitzant tant spaCy com transformers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7HBlBfKQzXTv"
   },
   "source": [
    "\n",
    "### 2.1.1 Detecció d'entitats anomenades (NER) utilitzant spaCy.\n",
    "\n",
    "Per a detectar NER utilitzarem el model `en_core_web_sm` de spaCy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qn9KhNzWlgjx"
   },
   "source": [
    "**a. Instal·lar llibreries i model de llenguatge a utilitzar.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-06-04T14:04:12.660582Z",
     "iopub.status.busy": "2025-06-04T14:04:12.660262Z",
     "iopub.status.idle": "2025-06-04T14:04:15.721386Z",
     "shell.execute_reply": "2025-06-04T14:04:15.720734Z",
     "shell.execute_reply.started": "2025-06-04T14:04:12.660555Z"
    },
    "id": "6j5WkL16iH5Q",
    "outputId": "5104f5b1-84d8-47fe-e1e5-476befed70b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.7)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.16.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.4.26)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T14:04:19.994521Z",
     "iopub.status.busy": "2025-06-04T14:04:19.994248Z",
     "iopub.status.idle": "2025-06-04T14:04:27.217895Z",
     "shell.execute_reply": "2025-06-04T14:04:27.217036Z",
     "shell.execute_reply.started": "2025-06-04T14:04:19.994495Z"
    },
    "id": "ND86mIOO1Q-R",
    "outputId": "5895415f-be27-4af7-8716-ddbba71c3d6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3GGja_0a8_YP"
   },
   "source": [
    "**`Important:`**\n",
    "\n",
    "Si la descàrrega de *'en_core_web_sm'* es realitza des de Google Colab y, després de la descàrrega, es mostra el missatge 'Restart to reload dependencies', executar l'opció de menú 'Runtime>>>Restart session'. A continuació tornar a executar la secció 0 d'aquest notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nuw5kYMWvh1M"
   },
   "source": [
    "**b. Definir funcions per a imprimir els resultats de la detecció.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T14:04:34.108189Z",
     "iopub.status.busy": "2025-06-04T14:04:34.107937Z",
     "iopub.status.idle": "2025-06-04T14:04:34.116257Z",
     "shell.execute_reply": "2025-06-04T14:04:34.115698Z",
     "shell.execute_reply.started": "2025-06-04T14:04:34.108165Z"
    },
    "id": "O8Ot3tH3lO48"
   },
   "outputs": [],
   "source": [
    "def get_tokens_to_print(model, text):\n",
    "  \"\"\"Print tokens of the text and its relevant attributes.\n",
    "\n",
    "    Parameters:\n",
    "      model (spaCy model): spaCy model used for tokenization\n",
    "      text (str):  text to transform in a spaCy doc class.\n",
    "\n",
    "    Returns: ---\n",
    "  \"\"\"\n",
    "  doc = model(text)\n",
    "  print (f\"The text:\\n\\n{get_text_to_print(text)}\\n\\nwas converted in a spaCy object: {type(doc)}\\n\")\n",
    "  print (f\"Token-based analysis. Each token is a spaCy object: {type(doc[0])}\\n\")\n",
    "\n",
    "  # We obtain rows to print: headers and content\n",
    "  rows  = []\n",
    "  # head_align: List of tuples. Each tuple: heather and its alignment when printing\n",
    "  head_align  = [('Token', '<'), ('Lemma', '<'), ('Syntactic parent', '<'), ('#Tok', '>'), ('Chr_Start', '>'), ('Chr_End', '>'), ('POS', '<'),\n",
    "                 ('TAG', '<'), ('TAG meaning:', '<'), ('ENT', '<'), ('DEP', '<'), ('DEP meaning:', '<')]\n",
    "  head, align = list(zip(*head_align))\n",
    "  rows.append(head)                           # Header\n",
    "  rows.append(['='*len(i) for i in head])     # Underline headers\n",
    "  for tok in doc:\n",
    "    rows.append([tok.text, tok.lemma_, tok.head.text, str(tok.i), str(tok.idx), str(tok.idx+len(tok)-1), tok.pos_,\n",
    "                 tok.tag_, str(spacy.explain(tok.tag_))[:20], tok.ent_type_, tok.dep_, str(spacy.explain(tok.dep_))[:20]])\n",
    "\n",
    "  # Width of each column: the witdh of the longest element\n",
    "  columns       = zip(*rows)\n",
    "  column_widths = [max(len(i) for i in col) for col in columns]\n",
    "\n",
    "  # Print the files with alignment\n",
    "  for row in rows:\n",
    "    print(*[f\"{row[i]:{align[i]}{column_widths[i]}}  \" for i in range(0, len(row))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T14:04:37.513295Z",
     "iopub.status.busy": "2025-06-04T14:04:37.513066Z",
     "iopub.status.idle": "2025-06-04T14:04:37.517689Z",
     "shell.execute_reply": "2025-06-04T14:04:37.517082Z",
     "shell.execute_reply.started": "2025-06-04T14:04:37.513267Z"
    },
    "id": "u9N8mQA3s56Z"
   },
   "outputs": [],
   "source": [
    "def get_text_to_print(text):\n",
    "  \"\"\"Format given text.\n",
    "\n",
    "    Parameters:\n",
    "      text (str): text to print\n",
    "\n",
    "    Returns:\n",
    "      str: text formatted in 100 character lines with an initial line numbering the characters\n",
    "  \"\"\"\n",
    "  line_length = 100\n",
    "  line_poss   = \"     1-------10--------20--------30--------40--------50--------60--------70--------80--------90-------100\"\n",
    "  text        = text.replace(\"\\n\", \" \")     # In order to avoid that the \\n character produces a line change.\n",
    "  text        = text.replace(\"\\r\", \" \")     # In wikipedia texts we have detected the character '\\r' that, if interpreted, may induce some printing problems.\n",
    "  text_format = \"\\n\".join([ f\"{i//line_length:<5}{text[i:i+line_length]}\"  for i in range(0, len(text), line_length) ])\n",
    "  return line_poss + \"\\n\" + text_format + \"\\n\" + line_poss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2xbabYm4uIe"
   },
   "source": [
    "**c. Carregar el model `en_core_web_sm`**\n",
    "\n",
    "**Resultat esperat**: Codi per a la càrrega del model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T14:04:41.790408Z",
     "iopub.status.busy": "2025-06-04T14:04:41.790185Z",
     "iopub.status.idle": "2025-06-04T14:04:45.825953Z",
     "shell.execute_reply": "2025-06-04T14:04:45.825348Z",
     "shell.execute_reply.started": "2025-06-04T14:04:41.790391Z"
    },
    "id": "bLtWJNWHqcA9"
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓ                                   #\n",
    "#############################################\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0_3yv6zZvwwy"
   },
   "source": [
    "**d. Convertir un text en objecte `Doc` de spaCy.**\n",
    "\n",
    "Per a realitzar la detecció d'entitats anomenades, proposar un text en anglès que mencioni a entitats de diferent tipus.\n",
    "\n",
    "**Sortida Esperada**: Visualitzar els resultats d'analitzar el text proposat a nivell de cada POS.\n",
    "\n",
    "**Suggeriment:** Per a la visualització es pot utilitzar la funció *get_tokens_to_print()*, prèviament creada, o *displacy.render()* de spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T14:06:13.250017Z",
     "iopub.status.busy": "2025-06-04T14:06:13.249527Z",
     "iopub.status.idle": "2025-06-04T14:06:13.292255Z",
     "shell.execute_reply": "2025-06-04T14:06:13.291744Z",
     "shell.execute_reply.started": "2025-06-04T14:06:13.249990Z"
    },
    "id": "iIDs4LbelUjj",
    "outputId": "31bcaf41-6e51-47df-99e8-37d380a059dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text:\n",
      "\n",
      "     1-------10--------20--------30--------40--------50--------60--------70--------80--------90-------100\n",
      "0    Last Friday, Spider-Man crashed Apple's WWDC keynote in San Francisco, California to challenge Justi\n",
      "1    n Bieber to a dance-off.\n",
      "     1-------10--------20--------30--------40--------50--------60--------70--------80--------90-------100\n",
      "\n",
      "was converted in a spaCy object: <class 'spacy.tokens.doc.Doc'>\n",
      "\n",
      "Token-based analysis. Each token is a spaCy object: <class 'spacy.tokens.token.Token'>\n",
      "\n",
      "Token        Lemma        Syntactic parent   #Tok   Chr_Start   Chr_End   POS     TAG    TAG meaning:           ENT      DEP        DEP meaning:          \n",
      "=====        =====        ================   ====   =========   =======   ===     ===    ============           ===      ===        ============          \n",
      "Last         last         Friday                0           0         3   ADJ     JJ     adjective (English),   DATE     amod       adjectival modifier   \n",
      "Friday       Friday       crashed               1           5        10   PROPN   NNP    noun, proper singula   DATE     npadvmod   noun phrase as adver  \n",
      ",            ,            crashed               2          11        11   PUNCT   ,      punctuation mark, co            punct      punctuation           \n",
      "Spider       Spider       Man                   3          13        18   PROPN   NNP    noun, proper singula   ORG      compound   compound              \n",
      "-            -            Man                   4          19        19   PUNCT   HYPH   punctuation mark, hy   ORG      punct      punctuation           \n",
      "Man          Man          crashed               5          20        22   PROPN   NNP    noun, proper singula   ORG      nsubj      nominal subject       \n",
      "crashed      crash        challenge             6          24        30   VERB    VBD    verb, past tense                ccomp      clausal complement    \n",
      "Apple        Apple        WWDC                  7          32        36   PROPN   NNP    noun, proper singula   ORG      poss       possession modifier   \n",
      "'s           's           Apple                 8          37        38   PART    POS    possessive ending               case       case marking          \n",
      "WWDC         WWDC         crashed               9          40        43   NOUN    NNS    noun, plural                    dobj       direct object         \n",
      "keynote      keynote      crashed              10          45        51   VERB    VBP    verb, non-3rd person            advcl      adverbial clause mod  \n",
      "in           in           keynote              11          53        54   ADP     IN     conjunction, subordi            prep       prepositional modifi  \n",
      "San          San          Francisco            12          56        58   PROPN   NNP    noun, proper singula   GPE      compound   compound              \n",
      "Francisco    Francisco    in                   13          60        68   PROPN   NNP    noun, proper singula   GPE      pobj       object of prepositio  \n",
      ",            ,            challenge            14          69        69   PUNCT   ,      punctuation mark, co            punct      punctuation           \n",
      "California   California   challenge            15          71        80   PROPN   NNP    noun, proper singula   GPE      nsubj      nominal subject       \n",
      "to           to           challenge            16          82        83   PART    TO     infinitival \"to\"                aux        auxiliary             \n",
      "challenge    challenge    challenge            17          85        93   VERB    VB     verb, base form                 ROOT       root                  \n",
      "Justin       Justin       Bieber               18          95       100   PROPN   NNP    noun, proper singula   PERSON   compound   compound              \n",
      "Bieber       Bieber       challenge            19         102       107   PROPN   NNP    noun, proper singula   PERSON   dobj       direct object         \n",
      "to           to           challenge            20         109       110   ADP     IN     conjunction, subordi            prep       prepositional modifi  \n",
      "a            a            off                  21         112       112   DET     DT     determiner                      det        determiner            \n",
      "dance        dance        off                  22         114       118   NOUN    NN     noun, singular or ma            compound   compound              \n",
      "-            -            off                  23         119       119   PUNCT   HYPH   punctuation mark, hy            punct      punctuation           \n",
      "off          off          to                   24         120       122   NOUN    NN     noun, singular or ma            pobj       object of prepositio  \n",
      ".            .            challenge            25         123       123   PUNCT   .      punctuation mark, se            punct      punctuation           \n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# SOLUCIÓ                                   #\n",
    "#############################################\n",
    "\n",
    "import spacy\n",
    "\n",
    "text = (\n",
    "    \"Last Friday, Spider-Man crashed Apple's WWDC keynote in San Francisco, California to challenge Justin Bieber to a dance-off.\"\n",
    ")\n",
    "\n",
    "get_tokens_to_print(nlp, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bM3ErTAQ0bJD"
   },
   "source": [
    "### 2.1.2 Entrenar un nou model de NER amb el corpus escollit de detecció d'entitats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LBfsn9qjwkil"
   },
   "source": [
    "**a. Convertir el corpus escollit al 'format spaCy'.**\n",
    "\n",
    "*Suggeriment:* Si el corpus es gran i l'entrenament triga massa, pots generar una versió més reduïda de tots els arxius del corpus escollit (train, dev y test). La reducció es podria fer del 25%.\n",
    "\n",
    "Recuerda que spaCy conté funcions que permeten convertir formats, com ara *conll*, al format compilat que necessita el mòdul de train de spaCy.\n",
    "\n",
    "**Sortida esperada:** Codi per a convertir el corpus training (train.txt) i el de validació (valid.txt), del format origen a format spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-06-04T14:06:17.703075Z",
     "iopub.status.busy": "2025-06-04T14:06:17.702805Z",
     "iopub.status.idle": "2025-06-04T14:06:19.530400Z",
     "shell.execute_reply": "2025-06-04T14:06:19.529789Z",
     "shell.execute_reply.started": "2025-06-04T14:06:17.703055Z"
    },
    "id": "SawYWFHnjJul",
    "outputId": "fdb0085c-b6a1-489f-fa5a-00db73d2ae38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generat fitxer .spacy a: spacy_v2/train_reduit.spacy\n",
      "Generat fitxer .spacy a: spacy_v2/valid_reduit.spacy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import spacy\n",
    "from spacy.tokens import Doc, DocBin\n",
    "\n",
    "def reduir_corpus(orig_path: str, reduit_path: str, percentatge: float = 0.25):\n",
    "    with open(orig_path, \"r\", encoding=\"utf-8\") as fin, \\\n",
    "         open(reduit_path, \"w\", encoding=\"utf-8\") as fout:\n",
    "        for linia in fin:\n",
    "            if linia.strip() == \"\":\n",
    "                fout.write(\"\\n\")\n",
    "                continue\n",
    "            if random.random() < percentatge:\n",
    "                fout.write(linia)\n",
    "\n",
    "\n",
    "def convert_conll_to_spacy(conll_path: str, output_spacy_path: str):\n",
    "    nlp = spacy.blank(\"en\")\n",
    "    doc_bin = DocBin()\n",
    "\n",
    "    with open(conll_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        tokens = []\n",
    "        iob_tags = []\n",
    "\n",
    "        for linia in f:\n",
    "            linia = linia.rstrip(\"\\n\")\n",
    "            if linia == \"\":\n",
    "                if tokens:\n",
    "                    words = [tok for tok in tokens]\n",
    "                    spaces = [True] * (len(words) - 1) + [False]\n",
    "                    doc = Doc(nlp.vocab, words=words, spaces=spaces)\n",
    "\n",
    "                    ents = []\n",
    "                    start_token_idx = None\n",
    "                    current_label = None\n",
    "\n",
    "                    for idx, tag in enumerate(iob_tags):\n",
    "                        if tag == \"O\":\n",
    "                            if current_label is not None and start_token_idx is not None:\n",
    "                                span = doc[start_token_idx:idx]\n",
    "                                span.label_ = current_label\n",
    "                                ents.append(span)\n",
    "                                start_token_idx = None\n",
    "                                current_label = None\n",
    "                            continue\n",
    "\n",
    "                        prefix, label = tag.split(\"-\", 1)\n",
    "                        if prefix == \"B\":\n",
    "                            if current_label is not None and start_token_idx is not None:\n",
    "                                span = doc[start_token_idx:idx]\n",
    "                                span.label_ = current_label\n",
    "                                ents.append(span)\n",
    "                            # Comencem la nova entitat\n",
    "                            start_token_idx = idx\n",
    "                            current_label = label\n",
    "\n",
    "                        elif prefix == \"I\":\n",
    "                            continue\n",
    "\n",
    "                        else:\n",
    "                            if current_label is not None and start_token_idx is not None:\n",
    "                                span = doc[start_token_idx:idx]\n",
    "                                span.label_ = current_label\n",
    "                                ents.append(span)\n",
    "                                start_token_idx = None\n",
    "                                current_label = None\n",
    "\n",
    "                    if current_label is not None and start_token_idx is not None:\n",
    "                        span = doc[start_token_idx : len(iob_tags)]\n",
    "                        span.label_ = current_label\n",
    "                        ents.append(span)\n",
    "\n",
    "                    doc.ents = ents\n",
    "                    doc_bin.add(doc)\n",
    "\n",
    "                    tokens = []\n",
    "                    iob_tags = []\n",
    "                continue\n",
    "\n",
    "            parts = linia.split()\n",
    "            word = parts[0]\n",
    "            iob_tag = parts[-1]\n",
    "            tokens.append(word)\n",
    "            iob_tags.append(iob_tag)\n",
    "\n",
    "        if tokens:\n",
    "            words = [tok for tok in tokens]\n",
    "            spaces = [True] * (len(words) - 1) + [False]\n",
    "            doc = Doc(nlp.vocab, words=words, spaces=spaces)\n",
    "\n",
    "            ents = []\n",
    "            start_token_idx = None\n",
    "            current_label = None\n",
    "\n",
    "            for idx, tag in enumerate(iob_tags):\n",
    "                if tag == \"O\":\n",
    "                    if current_label is not None and start_token_idx is not None:\n",
    "                        span = doc[start_token_idx:idx]\n",
    "                        span.label_ = current_label\n",
    "                        ents.append(span)\n",
    "                        start_token_idx = None\n",
    "                        current_label = None\n",
    "                    continue\n",
    "\n",
    "                prefix, label = tag.split(\"-\", 1)\n",
    "                if prefix == \"B\":\n",
    "                    if current_label is not None and start_token_idx is not None:\n",
    "                        span = doc[start_token_idx:idx]\n",
    "                        span.label_ = current_label\n",
    "                        ents.append(span)\n",
    "                    start_token_idx = idx\n",
    "                    current_label = label\n",
    "                elif prefix == \"I\":\n",
    "                    continue\n",
    "                else:\n",
    "                    if current_label is not None and start_token_idx is not None:\n",
    "                        span = doc[start_token_idx:idx]\n",
    "                        span.label_ = current_label\n",
    "                        ents.append(span)\n",
    "                        start_token_idx = None\n",
    "                        current_label = None\n",
    "\n",
    "            if current_label is not None and start_token_idx is not None:\n",
    "                span = doc[start_token_idx : len(iob_tags)]\n",
    "                span.label_ = current_label\n",
    "                ents.append(span)\n",
    "\n",
    "            doc.ents = ents\n",
    "            doc_bin.add(doc)\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_spacy_path), exist_ok=True)\n",
    "    doc_bin.to_disk(output_spacy_path)\n",
    "    print(f\"Generat fitxer .spacy a: {output_spacy_path}\")\n",
    "\n",
    "\n",
    "input_train = \"dataset/train.txt\"\n",
    "input_valid = \"dataset/valid.txt\"\n",
    "\n",
    "train_reduit = \"dataset/train_reduit.txt\"\n",
    "valid_reduit = \"dataset/valid_reduit.txt\"\n",
    "\n",
    "output_dir = \"spacy_v2\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "reduir_corpus(input_train, train_reduit, percentatge=0.25)\n",
    "reduir_corpus(input_valid, valid_reduit, percentatge=0.25)\n",
    "\n",
    "train_spacy_out = os.path.join(output_dir, \"train_reduit.spacy\")\n",
    "valid_spacy_out = os.path.join(output_dir, \"valid_reduit.spacy\")\n",
    "\n",
    "convert_conll_to_spacy(train_reduit, train_spacy_out)\n",
    "convert_conll_to_spacy(valid_reduit, valid_spacy_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wsPjyFwFqcA9"
   },
   "source": [
    "**b. Descarregar el model `en_core_web_trf`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-06-04T14:06:28.057665Z",
     "iopub.status.busy": "2025-06-04T14:06:28.057119Z",
     "iopub.status.idle": "2025-06-04T14:08:03.508945Z",
     "shell.execute_reply": "2025-06-04T14:08:03.508233Z",
     "shell.execute_reply.started": "2025-06-04T14:06:28.057643Z"
    },
    "id": "guBDOqACqcA-",
    "outputId": "3245d84f-f16a-4251-e7eb-d5696d86b3ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-trf==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_trf-3.8.0/en_core_web_trf-3.8.0-py3-none-any.whl (457.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m457.4/457.4 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting spacy-curated-transformers<1.0.0,>=0.2.2 (from en-core-web-trf==3.8.0)\n",
      "  Downloading spacy_curated_transformers-0.3.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting curated-transformers<0.2.0,>=0.1.0 (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0)\n",
      "  Downloading curated_transformers-0.1.1-py2.py3-none-any.whl.metadata (965 bytes)\n",
      "Collecting curated-tokenizers<0.1.0,>=0.0.9 (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0)\n",
      "  Downloading curated_tokenizers-0.0.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2.6.0+cu124)\n",
      "Requirement already satisfied: regex>=2022 in /usr/local/lib/python3.11/dist-packages (from curated-tokenizers<0.1.0,>=0.0.9->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2024.11.6)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (4.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.0.2)\n",
      "Downloading spacy_curated_transformers-0.3.1-py2.py3-none-any.whl (237 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.9/237.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading curated_tokenizers-0.0.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (735 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m735.6/735.6 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading curated_transformers-0.1.1-py2.py3-none-any.whl (25 kB)\n",
      "Installing collected packages: curated-tokenizers, curated-transformers, spacy-curated-transformers, en-core-web-trf\n",
      "Successfully installed curated-tokenizers-0.0.9 curated-transformers-0.1.1 en-core-web-trf-3.8.0 spacy-curated-transformers-0.3.1\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_trf')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_trf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvUs8p8b7G26"
   },
   "source": [
    "**Important:**\n",
    "\n",
    "A Google Colab, si després de la descàrrega del model `en_core_web_trf` s'obté el missatge 'Restart to reload dependencies', haurà d'executar-se l'opció de menú 'Runtime>>>Restart session'. A continuació, per a major seguretat, tornar a executar la secció 0 d'aquest notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-06-04T14:08:03.510840Z",
     "iopub.status.busy": "2025-06-04T14:08:03.510557Z",
     "iopub.status.idle": "2025-06-04T14:08:09.639525Z",
     "shell.execute_reply": "2025-06-04T14:08:09.638736Z",
     "shell.execute_reply.started": "2025-06-04T14:08:03.510809Z"
    },
    "id": "OTxeCyRP9Ds5",
    "outputId": "9a980c4f-05b1-46a8-8cdf-54b6ee2d689c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded compatibility table\u001b[0m\n",
      "\u001b[1m\n",
      "================= Installed pipeline packages (spaCy v3.8.7) =================\u001b[0m\n",
      "\u001b[38;5;4mℹ spaCy installation: /usr/local/lib/python3.11/dist-packages/spacy\u001b[0m\n",
      "\n",
      "NAME              SPACY            VERSION                            \n",
      "en_core_web_trf   >=3.8.0,<3.9.0   \u001b[38;5;2m3.8.0\u001b[0m   \u001b[38;5;2m✔\u001b[0m\n",
      "en_core_web_sm    >=3.8.0,<3.9.0   \u001b[38;5;2m3.8.0\u001b[0m   \u001b[38;5;2m✔\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-06-04T14:08:41.518901Z",
     "iopub.status.busy": "2025-06-04T14:08:41.518602Z",
     "iopub.status.idle": "2025-06-04T14:08:41.523331Z",
     "shell.execute_reply": "2025-06-04T14:08:41.522495Z",
     "shell.execute_reply.started": "2025-06-04T14:08:41.518879Z"
    },
    "id": "Kd_Tu0YX9D1C",
    "outputId": "a3b4d0cf-9295-4389-f4e6-bfa0feb302a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spacy version installed: 3.8.7\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "print (f\"Spacy version installed: {spacy.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9awrYehpVIO"
   },
   "source": [
    "**c. Verificar si es pot utilitzar GPU**\n",
    "\n",
    "Si aquest notebook s'està executant en una GPU, al paràmetre 'gpu-id' se li assignarà 0. Amb aquest canvi, SpaCy utilitzarà la GPU i s'accelerarà el temps d'entrenament."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-06-04T14:08:44.691779Z",
     "iopub.status.busy": "2025-06-04T14:08:44.691183Z",
     "iopub.status.idle": "2025-06-04T14:08:44.695930Z",
     "shell.execute_reply": "2025-06-04T14:08:44.695208Z",
     "shell.execute_reply.started": "2025-06-04T14:08:44.691755Z"
    },
    "id": "6uC_sXSz-Ooq",
    "outputId": "0d62f5f1-81b3-452d-ffeb-d656e173209a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    gpu_id = 0    # Use the first available GPU\n",
    "    print(f\"Using GPU {gpu_id}\")\n",
    "else:\n",
    "    gpu_id = -1   # Use CPU\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1IBS4yzD9hGQ"
   },
   "source": [
    "**d. Entrenar el model `en_core_web_trf` utilitzant la funció train de spaCy.**\n",
    "\n",
    "\n",
    "SpaCy realitza l'entrenament del model d'acord amb els paràmetres de l'arxiu de configuración 'config.cfg'. Una descripció de les seccions d'aquesta configuració la pots trobar a: https://spacy.io/usage/training#config; descriu algun canvi que realitzaries si creus que pots millorar l'entrenament.\n",
    "\n",
    "A més, considera que a l'arxiu 'config.cfg' no es determina un nombre prefixat d'*epochs* (veure sección [training] de 'config.cfg'). El criteri per a finalitzar el determinen els paràmetres *max_steps* (20000) i *patience* (1600). Aquests paràmetres determinen que l'entrenament finalitzarà si es compleix una de les condicions:\n",
    "* quan s'hagin processat 20000 'batches', o bé\n",
    "* quan, després de 1600 'batches' processats, no hi ha hagut millora en el model.\n",
    "\n",
    "**`Interrupció del procés`**\n",
    "\n",
    "Per restriccions de temps de procés (o per no consumir les *compute unit* de les que disposem a Google Colab), si s'observa que transcorregudes diverses iteracions (per exemple a partir de la tercera) el model ha anat millorant (columna SCORE) y té un valor superior a 0.9, interrompre manualment el procés. El 'best model' fins a aquesta iteració s'emmagatzemarà al path '{my_path_pra2}/NER/output_ner/model-best'. Aquest model és el que s'utilitzarà per a validar o predir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T10:10:59.900323Z",
     "iopub.status.busy": "2025-06-03T10:10:59.899564Z",
     "iopub.status.idle": "2025-06-03T10:32:38.418866Z",
     "shell.execute_reply": "2025-06-03T10:32:38.418024Z",
     "shell.execute_reply.started": "2025-06-03T10:10:59.900291Z"
    },
    "id": "7k80EbjlqcA_",
    "outputId": "5133d901-5336-46e7-ef48-caf7b7e3f26d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory: /kaggle/working/output_ner\u001b[0m\n",
      "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2025-06-03 10:11:08,002] [INFO] Set up nlp object from config\n",
      "[2025-06-03 10:11:08,022] [INFO] Pipeline: ['transformer', 'ner']\n",
      "[2025-06-03 10:11:08,023] [INFO] Resuming training for: ['ner', 'transformer']\n",
      "[2025-06-03 10:11:08,027] [INFO] Created vocabulary\n",
      "[2025-06-03 10:11:11,813] [WARNING] [W112] The model specified to use for initial vectors (en_core_web_trf) has no vectors. This is almost certainly a mistake.\n",
      "[2025-06-03 10:11:11,815] [INFO] Added vectors: en_core_web_trf\n",
      "[2025-06-03 10:11:11,818] [INFO] Finished initializing nlp object\n",
      "[2025-06-03 10:11:11,818] [INFO] Initialized pipeline components: []\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
      "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  -------------  --------  ------  ------  ------  ------\n",
      "  0       0         139.43     88.97    4.29    3.29    6.15    0.04\n",
      "  2     200       15003.87  15064.49   51.55   64.83   42.79    0.52\n",
      "  4     400        5551.59   8134.19   60.61   60.77   60.45    0.61\n",
      "  6     600        3245.12   5192.23   74.29   75.62   73.02    0.74\n",
      "  8     800        1831.18   2552.26   73.82   75.34   72.35    0.74\n",
      " 10    1000        1304.97   1756.22   73.70   72.82   74.60    0.74\n",
      " 12    1200         941.88   1103.07   74.55   73.85   75.26    0.75\n",
      " 14    1400         790.24    883.38   75.06   74.40   75.73    0.75\n",
      " 16    1600         675.34    733.71   75.32   73.79   76.92    0.75\n",
      " 18    1800         524.42    563.63   74.32   72.72   75.99    0.74\n",
      " 20    2000         486.31    505.81   75.21   74.20   76.26    0.75\n",
      " 22    2200         409.73    420.71   74.49   76.68   72.42    0.74\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "/kaggle/working/output_ner/model-last\n"
     ]
    }
   ],
   "source": [
    "# Entrenament del model\n",
    "\n",
    "!python -m spacy train \\\n",
    "    /kaggle/input/config/config.cfg \\\n",
    "    --output /kaggle/working/output_ner/ \\\n",
    "    --paths.train /kaggle/working/spacy_v2/train_reduit.spacy \\\n",
    "    --paths.dev   /kaggle/working/spacy_v2/valid_reduit.spacy \\\n",
    "    --gpu-id 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-06-04T14:11:29.599830Z",
     "iopub.status.busy": "2025-06-04T14:11:29.599105Z",
     "iopub.status.idle": "2025-06-04T14:25:29.973450Z",
     "shell.execute_reply": "2025-06-04T14:25:29.972730Z",
     "shell.execute_reply.started": "2025-06-04T14:11:29.599800Z"
    },
    "id": "TSaw1g-cjJun",
    "outputId": "a16e0f35-98db-41f7-dd06-b8076a48df39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Created output directory: output_ner\u001b[0m\n",
      "\u001b[38;5;4mℹ Saving to output directory: output_ner\u001b[0m\n",
      "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
      "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  -------------  --------  ------  ------  ------  ------\n",
      "  0       0         203.37    127.59    4.39    3.31    6.52    0.04\n",
      "  2     200       14624.92  14732.90   50.12   56.32   45.15    0.50\n",
      "  4     400        5388.42   7860.08   59.15   60.37   57.97    0.59\n",
      "  6     600        3188.58   5098.04   75.12   75.46   74.77    0.75\n",
      "  8     800        1755.09   2502.37   75.78   74.97   76.61    0.76\n",
      " 10    1000        1260.49   1728.11   75.91   72.73   79.38    0.76\n",
      " 12    1200         884.64   1059.08   76.48   73.78   79.38    0.76\n",
      " 14    1400         744.59    866.69   76.02   74.49   77.60    0.76\n",
      " 16    1600         640.25    706.85   77.00   76.07   77.96    0.77\n",
      " 18    1800         526.82    556.44   75.76   72.81   78.95    0.76\n",
      " 20    2000         423.89    485.35   75.82   74.37   77.32    0.76\n",
      " 22    2200         361.08    418.36   76.62   75.26   78.03    0.77\n",
      " 24    2400         391.46    433.47   76.32   76.59   76.05    0.76\n",
      " 26    2600         313.84    340.61   76.71   77.09   76.33    0.77\n",
      " 28    2800         321.05    337.69   76.82   75.71   77.96    0.77\n",
      " 30    3000         258.48    309.28   76.83   76.13   77.53    0.77\n",
      " 32    3200         274.77    279.39   75.40   75.32   75.48    0.75\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "output_ner/model-last\n"
     ]
    }
   ],
   "source": [
    "# Entrenament del model 2\n",
    "\n",
    "!python -m spacy train \\\n",
    "    config.cfg \\\n",
    "    --output output_ner/ \\\n",
    "    --paths.train spacy_v2/train_reduit.spacy \\\n",
    "    --paths.dev  spacy_v2/valid_reduit.spacy \\\n",
    "    --gpu-id 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3IuVvU7d2bEM"
   },
   "source": [
    "**e. Predicció d'un text d'exemple (inferència amb el model entrenat).**\n",
    "\n",
    "Carregar el millor model entrenat i utilitzar-lo per a predir una frase d'exemple. Recordar que, si el model ja està entrenat y emmagatzemat en una carpeta local, és millor, a l'iniciar una nova sessió, recuperar la millor versió entrenada des de local.\n",
    "\n",
    "**Resultat esperat:** visualitzar els resultats de la predicció.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-06-04T14:39:45.774872Z",
     "iopub.status.busy": "2025-06-04T14:39:45.774590Z",
     "iopub.status.idle": "2025-06-04T14:41:10.818805Z",
     "shell.execute_reply": "2025-06-04T14:41:10.818022Z",
     "shell.execute_reply.started": "2025-06-04T14:39:45.774852Z"
    },
    "id": "BojihhN_t1me",
    "outputId": "88502368-ad2f-4d8a-e131-4a4f48bcee9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy-transformers in /usr/local/lib/python3.11/dist-packages (1.3.9)\n",
      "Requirement already satisfied: spacy<4.1.0,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from spacy-transformers) (3.8.7)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy-transformers) (2.0.2)\n",
      "Requirement already satisfied: transformers<4.50.0,>=3.4.0 in /usr/local/lib/python3.11/dist-packages (from spacy-transformers) (4.49.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from spacy-transformers) (2.6.0+cu124)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from spacy-transformers) (2.5.1)\n",
      "Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from spacy-transformers) (0.9.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (1.1.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (0.16.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (4.67.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (2.11.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (75.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (3.5.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->spacy-transformers) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->spacy-transformers) (4.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->spacy-transformers) (3.5)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->spacy-transformers) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->spacy-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->spacy-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->spacy-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->spacy-transformers) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->spacy-transformers) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->spacy-transformers) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->spacy-transformers) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->spacy-transformers) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->spacy-transformers) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->spacy-transformers) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->spacy-transformers) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->spacy-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->spacy-transformers) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->spacy-transformers) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->spacy-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->spacy-transformers) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers<4.50.0,>=3.4.0->spacy-transformers) (0.32.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers<4.50.0,>=3.4.0->spacy-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<4.50.0,>=3.4.0->spacy-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<4.50.0,>=3.4.0->spacy-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<4.50.0,>=3.4.0->spacy-transformers) (0.5.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers<4.50.0,>=3.4.0->spacy-transformers) (1.1.2)\n",
      "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.1.0,>=3.5.0->spacy-transformers) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.1.0,>=3.5.0->spacy-transformers) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.1.0,>=3.5.0->spacy-transformers) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (2025.4.26)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<4.1.0,>=3.5.0->spacy-transformers) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<4.1.0,>=3.5.0->spacy-transformers) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (0.21.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<4.1.0,>=3.5.0->spacy-transformers) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (2.19.1)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (1.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "# Donat que s'ha instal·lat un model spacy-transformers, y tot i que per a les funcionalitats\n",
    "# que s'utilitzen en aquest notebook no és necessari, podria ser que en alguna configuració\n",
    "# spacy fos necessari instal·lar i importar la llibreria spacy_transformers:\n",
    "\n",
    "!pip install spacy-transformers\n",
    "\n",
    "import spacy_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rmr1vYmY_MUC",
    "outputId": "75794055-b72f-42af-f6e4-59367586b353",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text:\n",
      "\n",
      "     1-------10--------20--------30--------40--------50--------60--------70--------80--------90-------100\n",
      "0    Last Friday, Spider-Man crashed Apple's WWDC keynote in San Francisco, California to challenge Justi\n",
      "1    n Bieber to a dance-off.\n",
      "     1-------10--------20--------30--------40--------50--------60--------70--------80--------90-------100\n",
      "\n",
      "was converted in a spaCy object: <class 'spacy.tokens.doc.Doc'>\n",
      "\n",
      "Token-based analysis. Each token is a spaCy object: <class 'spacy.tokens.token.Token'>\n",
      "\n",
      "Token        Lemma   Syntactic parent   #Tok   Chr_Start   Chr_End   POS   TAG   TAG meaning:   ENT    DEP   DEP meaning:  \n",
      "=====        =====   ================   ====   =========   =======   ===   ===   ============   ===    ===   ============  \n",
      "Last                 Last                  0           0         3               None                        None          \n",
      "Friday               Friday                1           5        10               None                        None          \n",
      ",                    ,                     2          11        11               None                        None          \n",
      "Spider               Spider                3          13        18               None           MISC         None          \n",
      "-                    -                     4          19        19               None           MISC         None          \n",
      "Man                  Man                   5          20        22               None           MISC         None          \n",
      "crashed              crashed               6          24        30               None                        None          \n",
      "Apple                Apple                 7          32        36               None           ORG          None          \n",
      "'s                   's                    8          37        38               None                        None          \n",
      "WWDC                 WWDC                  9          40        43               None           MISC         None          \n",
      "keynote              keynote              10          45        51               None                        None          \n",
      "in                   in                   11          53        54               None                        None          \n",
      "San                  San                  12          56        58               None           LOC          None          \n",
      "Francisco            Francisco            13          60        68               None           LOC          None          \n",
      ",                    ,                    14          69        69               None                        None          \n",
      "California           California           15          71        80               None           LOC          None          \n",
      "to                   to                   16          82        83               None                        None          \n",
      "challenge            challenge            17          85        93               None                        None          \n",
      "Justin               Justin               18          95       100               None           PER          None          \n",
      "Bieber               Bieber               19         102       107               None           PER          None          \n",
      "to                   to                   20         109       110               None                        None          \n",
      "a                    a                    21         112       112               None                        None          \n",
      "dance                dance                22         114       118               None                        None          \n",
      "-                    -                    23         119       119               None                        None          \n",
      "off                  off                  24         120       122               None                        None          \n",
      ".                    .                    25         123       123               None                        None          \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/spacy/glossary.py:20: UserWarning: [W118] Term '' not found in glossary. It may however be explained in documentation for the corpora used to train the language. Please check `nlp.meta[\"sources\"]` for any relevant links.\n",
      "  warnings.warn(Warnings.W118.format(term=term))\n"
     ]
    }
   ],
   "source": [
    "import spacy_transformers\n",
    "\n",
    "#############################################\n",
    "# SOLUCIÓ                                   #\n",
    "#############################################\n",
    "\n",
    "import spacy\n",
    "\n",
    "model_dir = \"output_ner/model-best\"\n",
    "nlp = spacy.load(model_dir)\n",
    "\n",
    "text_example = (\n",
    "    \"Last Friday, Spider-Man crashed Apple's WWDC keynote \"\n",
    "    \"in San Francisco, California to challenge Justin Bieber to a dance-off.\"\n",
    ")\n",
    "get_tokens_to_print(nlp, text_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XxnoxzWzzJSk"
   },
   "source": [
    "**f. Avaluar els resultats obtinguts i calcular les mètriques.**\n",
    "\n",
    "**Sortida Esperada**: Càlcul de les mètriques utilitzant les dades de prova.\n",
    "\n",
    "**Important:** Abans del càlcul de les mètriques, no oblidar convertir el format de l'arxiu test.txt al 'format spaCy'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T513UTi-DAuQ",
    "outputId": "6f0fc408-4a24-4208-c029-8a22ac445f77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU 0\n"
     ]
    }
   ],
   "source": [
    "#Usar GPU si és possible:\n",
    "\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    gpu_id = 0    # Use the first available GPU\n",
    "    print(f\"Using GPU {gpu_id}\")\n",
    "else:\n",
    "    gpu_id = -1   # Use CPU\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SbhfmtRKtgvE"
   },
   "outputs": [],
   "source": [
    "def get_tokens_to_print_from_doc(doc):\n",
    "    print (f\"Text del Doc:\\n\\n{get_text_to_print(doc.text)}\\n\\nDoc: {type(doc)}\\n\")\n",
    "    print (f\"Cada token és un objecte spaCy: {type(doc[0])}\\n\")\n",
    "\n",
    "    rows = []\n",
    "    head_align = [\n",
    "        ('Token', '<'), ('Lemma', '<'), ('Syntactic parent', '<'), ('#Tok', '>'),\n",
    "        ('Chr_Start', '>'), ('Chr_End', '>'), ('POS', '<'),\n",
    "        ('TAG', '<'), ('TAG meaning:', '<'), ('ENT', '<'), ('DEP', '<'), ('DEP meaning:', '<')\n",
    "    ]\n",
    "    head, align = list(zip(*head_align))\n",
    "    rows.append(head)\n",
    "    rows.append(['='*len(h) for h in head])\n",
    "\n",
    "    for tok in doc:\n",
    "        rows.append([\n",
    "            tok.text,\n",
    "            tok.lemma_,\n",
    "            tok.head.text,\n",
    "            str(tok.i),\n",
    "            str(tok.idx),\n",
    "            str(tok.idx + len(tok) - 1),\n",
    "            tok.pos_,\n",
    "            tok.tag_,\n",
    "            str(spacy.explain(tok.tag_))[:20],\n",
    "            tok.ent_type_,\n",
    "            tok.dep_,\n",
    "            str(spacy.explain(tok.dep_))[:20]\n",
    "        ])\n",
    "\n",
    "    column_widths = [max(len(cell) for cell in column) for column in zip(*rows)]\n",
    "    for row in rows:\n",
    "        print(*[f\"{row[i]:{align[i]}{column_widths[i]}}  \" for i in range(len(row))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cJqZUm9k7gNb",
    "outputId": "60872874-61ae-4cce-dc15-ae4a7ea9746d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
      "\u001b[1m\n",
      "================================== Results ==================================\u001b[0m\n",
      "\n",
      "TOK     100.00\n",
      "NER P   76.07 \n",
      "NER R   77.96 \n",
      "NER F   77.00 \n",
      "SPEED   992   \n",
      "\n",
      "\u001b[1m\n",
      "=============================== NER (per type) ===============================\u001b[0m\n",
      "\n",
      "           P       R       F\n",
      "ORG    70.70   68.31   69.48\n",
      "PER    71.70   78.01   74.72\n",
      "LOC    82.20   86.98   84.52\n",
      "MISC   80.68   74.55   77.49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# SOLUCIÓ                                   #\n",
    "#############################################\n",
    "\n",
    "!python -m spacy evaluate output_ner/model-best spacy_v2/valid_reduit.spacy --gpu-id 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wPUPNSqbXT-T"
   },
   "source": [
    "## 2.2 NEL (1 punt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NO5zKmXnzWg7"
   },
   "source": [
    "En aquesta secció, obtindrem els enllaços a Wikidata relacionats amb les entitats que s'obtenen utilitzant spaCy.\n",
    "\n",
    "Es desenvoluparà una funció que, donat un text, obtingui automàticament les entitats i les relacionarà amb la corresponent entrada a Wikidata.\n",
    "Per a implementar la solució, podeu usar, por exemple, la llibreria `wikidata.client`, o realitzar sol·licituds directes a la API, utilitzant la llibreria `requests`.\n",
    "\n",
    "**Important:** En el `Notebook d'Exemple` es proporciona un text en català, és per això que es carrega el model `ca_core_news_sm`. Per a analitzar frases en castellà, canviar el model, per ejemplo, usar `es_core_news_sm`. A més, si s'utilitza `requests`, modificar l'idioma a la URL d'accés al EndPoint de WikiData.\n",
    "\n",
    "**Sortida Esperada**: Llista de les entitats reconegudes en el text, amb la seva respectiva `URI`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0bp_251gCFn-",
    "outputId": "7d86f6b0-4995-4b60-ff58-adcf0f2b614c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wikidata in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
      "Collecting ca-core-news-sm==3.8.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/ca_core_news_sm-3.8.0/ca_core_news_sm-3.8.0-py3-none-any.whl (19.6 MB)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('ca_core_news_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "nel_model = \"ca_core_news_sm\" # Model a usar, es pot canvar a \"es_core_news_sm\" per a processar frases en castellà.\n",
    "\n",
    "!pip install wikidata\n",
    "!python -m spacy download '{nel_model}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PKZ_bvCVXjI2"
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓ                                   #\n",
    "#############################################\n",
    "\n",
    "import spacy\n",
    "import requests\n",
    "\n",
    "nlp = spacy.load(\"ca_core_news_sm\")\n",
    "\n",
    "def cercar_wikidata_català(entitat):\n",
    "    url = \"https://www.wikidata.org/w/api.php\"\n",
    "    params = {\n",
    "        \"action\": \"wbsearchentities\",\n",
    "        \"search\": entitat,\n",
    "        \"language\": \"ca\",\n",
    "        \"format\": \"json\",\n",
    "        \"limit\": 1\n",
    "    }\n",
    "    try:\n",
    "        resposta = requests.get(url, params=params, timeout=10)\n",
    "        resposta.raise_for_status()\n",
    "    except requests.RequestException:\n",
    "        return \"No trobada\"\n",
    "\n",
    "    dades = resposta.json()\n",
    "    if \"search\" in dades and len(dades[\"search\"]) > 0:\n",
    "        qid = dades[\"search\"][0][\"id\"]\n",
    "        return f\"https://www.wikidata.org/wiki/{qid}\"\n",
    "    else:\n",
    "        return \"No trobada\"\n",
    "\n",
    "def obtenir_entitats_wikidata(text):\n",
    "    doc = nlp(text)\n",
    "    resultats = []\n",
    "    vistos = set()\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        ent_text = ent.text.strip()\n",
    "        ent_label = ent.label_\n",
    "        clau = ent_text.lower()\n",
    "        if clau in vistos:\n",
    "            continue\n",
    "        vistos.add(clau)\n",
    "\n",
    "        uri = cercar_wikidata_català(ent_text)\n",
    "        resultats.append((ent_text, ent_label, uri))\n",
    "\n",
    "    return resultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0TaDAacMwCCX",
    "outputId": "d5879a96-7a93-48aa-ffe9-4a11cd96acc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entitats reconegudes i URI corresponents a Wikidata:\n",
      "\n",
      "  • Universitat Autònoma de Barcelona  [ORG]  →  https://www.wikidata.org/wiki/Q43452\n",
      "  • UAB                             [ORG]  →  https://www.wikidata.org/wiki/Q469482\n",
      "  • Catalunya                       [LOC]  →  https://www.wikidata.org/wiki/Q5705\n",
      "  • Parc Güell                      [LOC]  →  https://www.wikidata.org/wiki/Q212867\n",
      "  • Antoni Gaudí                    [PER]  →  https://www.wikidata.org/wiki/Q25328\n",
      "  • Barcelona                       [LOC]  →  https://www.wikidata.org/wiki/Q1492\n",
      "  • Generalitat de Catalunya        [ORG]  →  https://www.wikidata.org/wiki/Q8022\n",
      "  • Andorra                         [LOC]  →  https://www.wikidata.org/wiki/Q228\n"
     ]
    }
   ],
   "source": [
    "    text_exemple = (\n",
    "        \"La Universitat Autònoma de Barcelona (UAB) és una de les principals universitats de Catalunya. \"\n",
    "        \"El Parc Güell va ser dissenyat per Antoni Gaudí i es troba a Barcelona. \"\n",
    "        \"La llengua catalana és cooficial a la Generalitat de Catalunya i a Andorra.\"\n",
    "    )\n",
    "\n",
    "    entitats_amb_uri = obtenir_entitats_wikidata(text_exemple)\n",
    "\n",
    "    print(\"Entitats reconegudes i URI corresponents a Wikidata:\\n\")\n",
    "    for ent_text, ent_label, uri in entitats_amb_uri:\n",
    "        print(f\"  • {ent_text:30s}  [{ent_label:>3s}]  →  {uri}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7526353,
     "sourceId": 11968981,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7543493,
     "sourceId": 11993054,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7571414,
     "sourceId": 12033322,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7580350,
     "sourceId": 12045810,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7590491,
     "sourceId": 12059755,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 360147,
     "modelInstanceId": 339110,
     "sourceId": 415570,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 366275,
     "modelInstanceId": 344985,
     "sourceId": 423326,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 367426,
     "modelInstanceId": 346155,
     "sourceId": 424704,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
