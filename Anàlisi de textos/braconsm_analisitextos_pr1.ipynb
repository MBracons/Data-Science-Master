{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1894f082",
   "metadata": {
    "id": "1894f082"
   },
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"float: left; width: 50%;\">\n",
    "<img src=\"https://www.uoc.edu/content/dam/news/images/noticies/2016/202-nova-marca-uoc.jpg\", align=\"left\" width=\"380\" height=\"120\">\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">M2.993 - Anàlisi de textos</p>\n",
    "<p style=\"margin: 0; text-align:right;\">Màster en Ciència de Dades</p>\n",
    "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudis d'Informàtica, Multimèdia y Telecomunicacions</p>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"width:100%;\">&nbsp;</div>\n",
    "\n",
    "# Processament i anàlisi d'informació textual (PRA1)\n",
    "\n",
    "A la PRA1 treballarem amb un dataset de ressenyes (opinions o reviews) i ho analitzarem seguint un conjunt de tasques: passant per la preparació i neteja de les dades, fins a l'avaluació de models de classificació de sentiments. Per tant, els objectius d‟aquesta activitat són:\n",
    "\n",
    "- Aplicar tècniques de processament de llenguatge natural per netejar i preprocessar les dades del dataset triat.\n",
    "- Implementar algorismes d'aprenentatge automàtic, com ara LDA i classificació supervisada, per analitzar els textos de les ressenyes.\n",
    "- Avaluar el rendiment dels models creats, utilitzant les mètriques adequades\n",
    "\n",
    "Per tant, en aquesta primera pràctica, revisarem i aplicarem els coneixements apresos als primers mòduls de l'assignatura. Concretament tractarem els temes següents:\n",
    "\n",
    "<ul>\n",
    "<li>1. Elecció i preparació del dataset (10%).\n",
    "<li>2. Obtenció de dades (30%).\n",
    "<li>3. Detecció de temes (30%).\n",
    "<li>4. Classificació automàtica d'opinions positives i negatives (20%).\n",
    "<li>5. Avaluació (10%).\n",
    "</ul>\n",
    "  \n",
    "A continuació, es descriu lestructura de la pràctica a realitzar. Considereu que per cada apartat, s'han plantejat diversos exercicis a resoldre; i en alguns pocs casos, es deixa la solució per orientar una mica millor el desenvolupament."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02783e52-8d17-47ea-aa0b-8d32613cac63",
   "metadata": {
    "id": "02783e52-8d17-47ea-aa0b-8d32613cac63"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce11941-7b11-4a49-8a18-6fe3bdd9e3dc",
   "metadata": {
    "id": "1ce11941-7b11-4a49-8a18-6fe3bdd9e3dc"
   },
   "source": [
    "# 1. Elecció i preparació del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0bf012",
   "metadata": {
    "id": "bb0bf012"
   },
   "source": [
    "## 1.1. Descripció i càrrega del dataset\n",
    "\n",
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 1em;\">\n",
    "\n",
    "<strong>Exercici 1.1.1:</strong> En paraules, descriure el títol del dataset seleccionat, l'adreça original (font), i una descripció del mateix.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usrsRuOTa-BA",
   "metadata": {
    "id": "usrsRuOTa-BA"
   },
   "source": [
    " * Nom del joc de dades: Large Movie Review Dataset (IMDb Movie Reviews)\n",
    " * Font: https://ai.stanford.edu/~amaas/data/sentiment/\n",
    " * Descripció: Aquest conjunt de dades conté 50.000 ressenyes de pel·lícules en anglès, etiquetades amb sentiment positiu o negatiu. Les dades estan equilibrades i dividides entre entrenament i prova, amb opinions que segueixen un criteri basat en la puntuació de la ressenya."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vJpqjBndVvFT",
   "metadata": {
    "id": "vJpqjBndVvFT"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 1em;\">\n",
    "\n",
    "<strong>Exercici 1.1.2:</strong> Càrrega del dataset i descripció de les seves principals característiques: mida, estructura, distribució de classe/ràting, distribució de longituds de text, exploració preliminar del text de les opinions (orientada a descobrir potencials tasques de neteja a realitzar).\n",
    "\n",
    "</div>\n",
    "\n",
    "<b>Important</b>: En cas d'haver triat un dataset sense una columna que denoti el sentiment de cada text, però sí el rating, en aquest exercici, afegir una nova columna de sentiment. Per exemple, si tenim els valors 1 a 5 per a rating, podríem considerar els valors de 1 i 2, com a sentiment negatiu (0), i els valors 4 i 5 com a positiu (1). Per ara, ens centrarem en la classificació binària, per tant, no cal considerar els valors de sentiment “neutral” o rating=3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe396c5-3186-44b8-b2b0-e35d0d4b68ef",
   "metadata": {},
   "source": [
    "El dataset ha d'estar organitzat amb les carpetes 'train' i 'test', i dins \n",
    "d'aquestes, amb subcarpetes 'pos' i 'neg' que corresponen a les opinions positives \n",
    "i negatives respectivament.\n",
    "\n",
    "Per seguir la pràctica farem dues coses\n",
    " * Reduir el nombre de resenyes a 7500 per tindre temps d'entrenament més curts\n",
    " * Unir en un únic dataframe test i training\n",
    "\n",
    "En aquets dataset hi ha originalment 25000 resenyes positives i 25000 negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbf74bac",
   "metadata": {
    "id": "bbf74bac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de mostres reduïdes: 7500\n",
      "Nombre total de ressenyes: 7500\n",
      "\n",
      "Distribució de classes:\n",
      "label\n",
      "pos    3775\n",
      "neg    3725\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Estadístiques de longitud (nombre de paraules per ressenya):\n",
      "count    7500.000000\n",
      "mean      230.359467\n",
      "std       170.456526\n",
      "min         6.000000\n",
      "25%       127.000000\n",
      "50%       172.000000\n",
      "75%       279.000000\n",
      "max      2125.000000\n",
      "Name: length, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mostra de ressenyes:\n",
      "[\"A handful of critics have awarded this film with positive comments. I don't wish to argue with their opinion, but I strongly disagree. When I first watched this film I was mildly impressed. But after comparing it with other films, particularly with the late master, Bruce Lee I quickly changed my mind. In fact, if it wasn't for the title of the film, I would never have bought it. Game of Death 2 doesn't relate to the original Game of Death, (except it shares one character, Billy Lo.)<br /><br />I was stunned to see how similar Game of Death 2 was compared to Enter the Dragon. The plots have striking similarities: Both Bruce Lee and Bobby Lo are on a mission to avenge a relative. The two locations are similar, in which they both are very isolated and are surrounded by thousands of Blackbelts. There is an element of prostitution in both films (women are sent two the guests rooms in both films.) Both Han (Enter the Dragon) and Lewis's henchman have a hand missing. Their is an underground drug operation in Enter the Dragon, believe it or not, there is one in Game of Death 2. Han has a pet cat in Enter the Dragon, the director has used his imagination and awarded Lewis with a pet monkey! The list continues. <br /><br />Regarding other aspects of the film, such as the script and the acting, I felt it was very poor. It seemed to me that the director was looking for a group of martial artists to star in the film and prayed they could act. <br /><br />On a positive scale, I cannot deny that the choreography is impressive. Although the fighting sequences have strong elements of acrobatics in them, they are none the less skillfully performed. However, as the plot is insufficient, i couldn't relate to the characters, therefore the fighting sequences were more exhibitions rather than having a meaning to the film. <br /><br />In conclusion I would say this film is recommendable to any martial-arts fans, but for those who enjoy a solid action film, with a good storyline and strong characters, I seriously wouldn't recommend this film. My opinions towards this film may seem very bias and one-sided, but when Bruce Lee set a new standard in the martial arts cinema, particularly after his masterpiece: Enter the Dragon, this film failed to rise to these standards. If anything they imitated a truly brilliant martial-arts film, in hope of achieving the same level of fame. <br /><br />In reference to my evaluation, awarding this film a very harsh 1 out of 10, the film is barley watchable, and must be thankful that it had the fighting sequences it did.\"\n",
      " 'Oh gosh,I\\'m really fed up with all these generic Japanese horror films about long-haired female ghosts and ghostly kids.\"Ghost Train\" is no exception.It is clearly influenced by \"Ringu\",\"Ju-On\",\"Shutter\" and \"Pulse\".Two years ago I was into such modern ghost stories,because they usually managed to give me some goosebumps,unfortunately there is nothing fresh or interesting in \"Ghost Train\".In fact the film is really boring.Noriko goes missing in a subway tunnel-like an elementary-school classmate-Nana must investigate a mystery of multiple disappearances,with the help of a youthful train conductor and another \"disappeared\" child\\'s mother.The film offers some mildly creepy moments,however the CGI effects are laughable and the climax is illogical.Skip it.'\n",
      " \"If a movie has an unimaginative, hackneyed story and bland characters it needs to make up for it by being really, really funny. You can get away with a lot if you're funny. But while there are a few amusing moments scattered here and there in Grandma's Boy, they are so far and few between that they cannot begin to make up for the hack work the film displays in such abundance.<br /><br />The movie certainly doesn't aim to surprise anyone. When Alex hides marijuana in his grandma's house in a tea tin you know what's going to happen later on and it does. The movie appears to have been written by a committee who did a study of mediocre comedies and grabbed any gag that appeared in more than one of them.<br /><br />The most interesting thing about the movie is its somewhat unusual setting. The game takes place in a video game development company, which should be an interesting source for some clever comedy. But don't be fooled, this is not a movie about video game developers. This is basically a college frat house movie in which all the frat boys have been shoved into a big room to play video games.<br /><br />The way the movie completely fails to think through its setting and use it for original laughs can be seen in the character of J.P. J.P. is I think more-or-less conspired by the creator of Doom, John Carmack. At least inspired to the extent that he's an odd genius who makes games.<br /><br />In the movie, J.P. is a weird, obnoxious geek who is despised and jeered by the company game testers. That makes no sense at all. If you are one of the most significant people in the history of video games (as J.P. is supposed to be) then even if you're quirky and obnoxious, people will still admire and respect you on some level. If Stephen Hawking is obnoxious his associates still aren't going to make jun of him to his face.<br /><br />Also, game testers are just as likely to be geeks as J.P., but in the movie they are basically frat boys. It's a fun normal guys against the obnoxious dweebs movie. And while that formula has worked, very occasionally, in the past, it is absurd in the setting of a game company. If you decide to use an unusual setting for a movie, you don't simply cram in all the conventions of movies from different settings into that one. Unless you're a hack.<br /><br />About two thirds of the way through the movie I gave up. Something happened that I knew would result in a series of painfully predictable events. And I realized I hadn't actually laughed at anything for the last half hour anyway. So I stopped (although I did fast forward just to make sure I was right that they would follow the most predictable clichés, which they did).<br /><br />Normally if a movie's bad I just say it's bad and then run out of things to say, but this movie is such a phenomenally shoddy production that it deserves a long diatribe.<br /><br />Shame on the movie for luring a good actress like Linda Cardellini into it, then surrounding her with talentless nobodies. I'll give the movie 1 point for giving Shirley Jones the chance to be the anti-Shirley Partridge though.\"]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_reviews(data_dir):\n",
    "    \"\"\"\n",
    "    Carrega les ressenyes d'un dataset d'opinions i retorna un DataFrame amb \n",
    "    les ressenyes, les seves etiquetes, la longitud (en nombre de paraules) de cada text, \n",
    "    i una nova columna \"Positive\" que val 1 si la ressenya és positiva i 0 si és negativa.\n",
    "    \"\"\"\n",
    "    reviews = []\n",
    "    labels = []\n",
    "    lengths = []\n",
    "    \n",
    "    # Els conjunts es troben en les carpetes \"train\" i \"test\". Dintre de cada\n",
    "    # una d'elles hi ha les carpetes \"pos\" i \"neg\"\n",
    "    for dataset in ['train', 'test']:\n",
    "        for sentiment in ['pos', 'neg']:\n",
    "            path = os.path.join(data_dir, dataset, sentiment)\n",
    "            # Agafem tots els fitxers de la carpeta\n",
    "            files = glob.glob(os.path.join(path, '*.txt'))\n",
    "            for f in files:\n",
    "                with open(f, 'r', encoding='utf-8') as file:\n",
    "                    text = file.read()\n",
    "                    reviews.append(text)\n",
    "                    labels.append(sentiment)\n",
    "                    # Comptem el nombre de paraules\n",
    "                    lengths.append(len(text.split()))\n",
    "    \n",
    "    # Creació del dataframe\n",
    "    df = pd.DataFrame({\n",
    "        'review': reviews,\n",
    "        'label': labels,\n",
    "        'length': lengths\n",
    "    })\n",
    "    \n",
    "    # Afegim la columna \"Positive\": 1 per a ressenyes positives, 0 per a negatives\n",
    "    df['Positive'] = df['label'].apply(lambda x: 1 if x == 'pos' else 0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Carreguem les dades\n",
    "data_dir = \"aclImdb_v1/aclImdb\"\n",
    "df = load_reviews(data_dir)\n",
    "df = df.sample(n=7500, random_state=42).reset_index(drop=True)\n",
    "print(\"Nombre de mostres reduïdes:\", len(df))\n",
    "\n",
    "# Mida i distribució\n",
    "print(\"Nombre total de ressenyes:\", len(df))\n",
    "print(\"\\nDistribució de classes:\")\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "# Longitud dels textos\n",
    "print(\"\\nEstadístiques de longitud (nombre de paraules per ressenya):\")\n",
    "print(df['length'].describe())\n",
    "\n",
    "# Visualització dels resultats\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['length'], bins=50, edgecolor='black')\n",
    "plt.xlabel(\"Nombre de paraules\")\n",
    "plt.ylabel(\"Nombre de ressenyes\")\n",
    "plt.title(\"Distribució de la Longitud de les Ressenyes\")\n",
    "plt.show()\n",
    "\n",
    "# 3 resenyes a l'atzar\n",
    "print(\"\\nMostra de ressenyes:\")\n",
    "print(df['review'].sample(3, random_state=42).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a63cd298-b650-478d-94ef-9d6fa98bdaae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>length</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yeah I watched this mini series with My Mom an...</td>\n",
       "      <td>pos</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I was initially forced to attend by my wife as...</td>\n",
       "      <td>pos</td>\n",
       "      <td>372</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This work is striking in its accurate depictio...</td>\n",
       "      <td>pos</td>\n",
       "      <td>228</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Atlantis: The Lost Empire\" was everything the...</td>\n",
       "      <td>pos</td>\n",
       "      <td>234</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It is fitting that the title character in Sydn...</td>\n",
       "      <td>neg</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7495</th>\n",
       "      <td>The One and the Only!&lt;br /&gt;&lt;br /&gt;The only real...</td>\n",
       "      <td>pos</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7496</th>\n",
       "      <td>Former private eye-turned-security guard ditch...</td>\n",
       "      <td>neg</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7497</th>\n",
       "      <td>This movie is not great, but it is a good and ...</td>\n",
       "      <td>pos</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7498</th>\n",
       "      <td>If you're interested in learning about the 're...</td>\n",
       "      <td>pos</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499</th>\n",
       "      <td>While it certainly wasn't the best movie I've ...</td>\n",
       "      <td>pos</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review label  length  \\\n",
       "0     Yeah I watched this mini series with My Mom an...   pos     125   \n",
       "1     I was initially forced to attend by my wife as...   pos     372   \n",
       "2     This work is striking in its accurate depictio...   pos     228   \n",
       "3     \"Atlantis: The Lost Empire\" was everything the...   pos     234   \n",
       "4     It is fitting that the title character in Sydn...   neg     100   \n",
       "...                                                 ...   ...     ...   \n",
       "7495  The One and the Only!<br /><br />The only real...   pos      64   \n",
       "7496  Former private eye-turned-security guard ditch...   neg     175   \n",
       "7497  This movie is not great, but it is a good and ...   pos     160   \n",
       "7498  If you're interested in learning about the 're...   pos      47   \n",
       "7499  While it certainly wasn't the best movie I've ...   pos      77   \n",
       "\n",
       "      Positive  \n",
       "0            1  \n",
       "1            1  \n",
       "2            1  \n",
       "3            1  \n",
       "4            0  \n",
       "...        ...  \n",
       "7495         1  \n",
       "7496         0  \n",
       "7497         1  \n",
       "7498         1  \n",
       "7499         1  \n",
       "\n",
       "[7500 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe resultant\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2776d767-d133-4b8b-8dff-db3bea0b1bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive\n",
       "1    50.333333\n",
       "0    49.666667\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graficar histograma\n",
    "df.Positive.hist()\n",
    "\n",
    "# Distribución de calificaciones por sentimiento:\n",
    "df['Positive'].value_counts(normalize=True) * 100 # valor porcentual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c5dede0-87e9-41f9-8bd9-95810c565161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>length</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1838</th>\n",
       "      <td>Read the book, forget the movie!</td>\n",
       "      <td>neg</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                review label  length  Positive\n",
       "1838  Read the book, forget the movie!   neg       6         0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reseñas muy cortas:\n",
    "df[df.length<10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da2b0fc5-acfa-48f2-8b69-18d2f6900e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CANTIDAD TOTAL DE REVIEWS ANTES DEL FILTRADO: 7499 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df[df['length'] > 7 ]\n",
    "print(\"CANTIDAD TOTAL DE REVIEWS ANTES DEL FILTRADO:\", df.shape[0], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658e4c98-40c6-43a5-8072-64a19c4f1563",
   "metadata": {},
   "source": [
    "No hi ha ressenyes molt curtes de les que preocupar-nos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gmUCKPB5xGjC",
   "metadata": {
    "id": "gmUCKPB5xGjC"
   },
   "source": [
    "## 1.2 Neteja de text\n",
    "\n",
    "Abans de treballar amb els textos de les ressenyes, cal netejar-los. En general, depenent del dataset podria ser necessari:\n",
    "\n",
    "1. Eliminar mencions (@), hashtags (#), o codi HTML.\n",
    "2. Eliminar pàgines web.\n",
    "3. Corregir paraules mal escrites (les que ressaltin al corpus).\n",
    "4. Eliminar duplicats.\n",
    "5. Convertir contraccions, (per exemple, en lloc de wouldn't, es canviaria a would not).\n",
    "6. Filtrar tokens no alfabètics.\n",
    "7. Filtrar signes de puntuació (!) i treure espais doble. Es recomana no treure el \".\" perquè després es farà servir aquest signe per crear la llista de sentències. Com a referència vegeu l'exemple de PRA proporcionat (*Exemple_PRA1.ipynb*).\n",
    "9. Convertir text a minúscules.\n",
    "\n",
    "Per cada punt, fer les verificacions necessàries per determinar l'existència de cada element esmentat al punt anterior (mencions, hashtags, codi HTML, pàgines web, etc.) i implementar les accions de neteja (segons es requereixi).\n",
    "\n",
    "<b>IMPORTANT</b>:\n",
    "- Abans d'implementar qualsevol acció, se suggereix crear una columna, anomenada *text*, a partir del contingut de la columna de text original del datset triat; i sobre la nova columna aplicar les tasques de neteja.\n",
    "- Per cada acció de neteja realitzada, enllistar almenys una ressenya que mostri que la funció implementada funciona. És a dir, presentar el text original i el text transformat (*text*).\n",
    "- Afegir les cel·les de text i codi necessàries, de manera que es realitzi les verificacions suggerides, i es doni solució als problemes de qualitat de dades trobades. Com a orientació, es recomana revisar el fitxer <b>Exemple_PRA1.ipynb</b> per veure la millor manera d'organitzar la solució."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14f55c4a-d217-4b77-800b-e03ce9913f1f",
   "metadata": {
    "id": "14f55c4a-d217-4b77-800b-e03ce9913f1f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29448/2826761890.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['review']\n"
     ]
    }
   ],
   "source": [
    "#Crear la columna 'text' per aplicar-hi les tasques de preprocessament i neteja:\n",
    "df['text'] = df['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "190e1f7d-b2e2-4044-905f-9beedcc69804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is fitting that the title character in Sydney White is defined from the beginning of the film by her awkwardness because the film, like the character, tends to begin every scene with a well-meant but inappropriate statement, then backtracks inadvertently making it worse and leaving the viewer in total confusion.<br /><br />This scenario gets old quick. Now imagine a hour and a half of this, throw on the most predictable storyline imaginable; add some vague Snow White and the Seven Dwarfs references and Amanda Bynes blinking in wide-eyed puzzlement and you have Sydney White...for more of my review http://www.helium.com/items/1433421-sydney-white-review\n"
     ]
    }
   ],
   "source": [
    "import contractions\n",
    "import re\n",
    "\n",
    "print(df[df['text'].str.contains('@|#|http', case=False, na=False)].head(1)['text'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a315473d-7e70-467b-b966-229eb0c6d835",
   "metadata": {
    "id": "a315473d-7e70-467b-b966-229eb0c6d835"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text original:\n",
      "Whether you're a fan of the series which inspired it or not, there's no denying this is a patchy piece of work. But in the best possible sense. Keen to get away from the trappings of old sitcoms which made an uneasy transition to the big screen, Messrs Pemberton, Dyson, Shearmsith and Gatiss have gone down a different road, addressing the problems of dealing with their success along with adding other creations and, inevitably, rehashing some of their best-loved characters. It's a pity they didn't stick to just a more consistent League of Gents movie because as inventive as including themselves in the screenplay is, it weakens the finished movie. Well worth renting though.\n",
      "\n",
      "Text netejat:\n",
      "whether you are a fan of the series which inspired it or not there is no denying this is a patchy piece of work. but in the best possible sense. keen to get away from the trappings of old sitcoms which made an uneasy transition to the big screen messrs pemberton dyson shearmsith and gatiss have gone down a different road addressing the problems of dealing with their success along with adding other creations and inevitably rehashing some of their best loved characters. it is a pity they did not stick to just a more consistent league of gents movie because as inventive as including themselves in the screenplay is it weakens the finished movie. well worth renting though.\n"
     ]
    }
   ],
   "source": [
    "# Funció per eliminar contraccions (don't -> do not)\n",
    "def expand_contractions(text):\n",
    "    return contractions.fix(text)\n",
    "\n",
    "\n",
    "# Funció per eliminar mencions (@example, #example) i HTML\n",
    "def remove_mentions_hashtags_html(text):\n",
    "    text = re.sub(r'@\\w+', '', text)      # Elimina mencions\n",
    "    text = re.sub(r'#\\w+', '', text)       # Elimina hashtags\n",
    "    text = re.sub(r'<[^>]+>', '', text)    # Elimina etiquetes HTML\n",
    "    return text\n",
    "\n",
    "\n",
    "# Funció per eliminar URLs\n",
    "def remove_urls(text):\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+', '', text)\n",
    "    return text\n",
    "    \n",
    "\n",
    "# Funció per eliminar signes de puntuació. (deixem el punt (.))\n",
    "def remove_punctuation(text):\n",
    "    # Defineix els signes de puntuació a eliminar\n",
    "    punctuation = ';,!\"#$%&\\()*+-<>@[\\\\]^_`{|}~?'\n",
    "    text = re.sub(f\"[{re.escape(punctuation)}]\", \" \", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "# Funció per eliminar espais extra\n",
    "def remove_extra_spaces(text):\n",
    "    text = re.sub(r'\\s\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "# Apliquem els canvis\n",
    "df.loc[:, 'text'] = df['text'].apply(expand_contractions)\n",
    "df.loc[:, 'text'] = df['text'].apply(remove_mentions_hashtags_html)\n",
    "df.loc[:, 'text'] = df['text'].apply(remove_urls)\n",
    "df.loc[:, 'text'] = df['text'].apply(remove_punctuation)\n",
    "df.loc[:, 'text'] = df['text'].apply(lambda x: x.lower())\n",
    "df.loc[:, 'text'] = df['text'].apply(remove_extra_spaces)\n",
    "\n",
    "# Eliminar duplicats a la columna 'text'\n",
    "df = df.drop_duplicates(subset='text')\n",
    "\n",
    "# Comparativa entre text original i text netejat\n",
    "sample_index = 73\n",
    "print(\"\\nText original:\")\n",
    "print(df.iloc[sample_index]['review'])\n",
    "print(\"\\nText netejat:\")\n",
    "print(df.iloc[sample_index]['text'])    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd14cd0",
   "metadata": {
    "id": "9dd14cd0"
   },
   "source": [
    "# 2. Obtenció de dades\n",
    "\n",
    "En aquesta part analitzarem el text, trobarem el conjunt de termes multiparaula rellevants del dataset i analitzarem l'objecte i aspectes de les opinions del text utilitzant el model Word2Wec. Per això començarem calculant els **millors bigrames i trigrames de les opinions del dataset i avaluar-los** segons diferents mètriques (PMI i Likehood). Posteriorment, detectarem els **n-grames que compleixin un patró sintàctic d'un sintagma nominal** (e.g: adjectiu + nom en singular/plural, nom + nom i nom en singular/plural) i acabarem **detectant col·locacions** amb un model de detecció de frases, per exemple amb el mòdul Phraser de Gensim. Un cop analitzats els termes multiparaula, **crearem un model word2vec** amb les opinions lematitzades i l'utilitzarem per analitzar els targets de les opinions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8d66db0-6e3c-48bb-b58c-ac11b3c8d31c",
   "metadata": {
    "id": "c8d66db0-6e3c-48bb-b58c-ac11b3c8d31c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_eng is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_rus is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package bcp47 to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package english_wordnet to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package english_wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker_tab is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger_tab is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pe08 to /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package pe08 is already up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt_tab to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package punkt_tab is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets_json to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package tagsets_json is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2022 to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2022 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to /home/win001/nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    }
   ],
   "source": [
    "# Per a aquest apartat cal carregar les llibreries següents:\n",
    "import nltk\n",
    "nltk.download('all')\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.collocations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d804647e-a178-43d4-b097-a8a445672fc9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d804647e-a178-43d4-b097-a8a445672fc9",
    "outputId": "6c2e0f09-351e-4b69-9a0e-623ee8e40519"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['would',\n",
       " 'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importar la llista de stopwords a l'idioma dels *reviews* de la llibreria NLTK i afegim algunes addicionals:\n",
    "stopwords =  [\"would\"]\n",
    "stopwords = stopwords + nltk.corpus.stopwords.words('english')\n",
    "stopwords[:15] # extracto de stopwords."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd45f9c3-8a17-4f60-9cde-84336516e1a5",
   "metadata": {
    "id": "cd45f9c3-8a17-4f60-9cde-84336516e1a5"
   },
   "source": [
    "### 2.1. Detecció de col·locacions\n",
    "\n",
    "Les col·locacions són termes multiparaula, és a dir, seqüències de paraules que, en conjunt, tenen un significat que difereix significativament del significat de cada paraula individual (e.g. \"free version\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de41ffd0",
   "metadata": {
    "id": "de41ffd0"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 1em;\">\n",
    "\n",
    "<strong>Exercici 2.1.1:</strong> Calcular els millors bigrames i trigrames de les opinions. Dels millors bigrames i trigrames, escull els que no comencen, ni acaben amb una stopword.\n",
    "<br>\n",
    "<b>Sortida esperada:</b> Imprimir els primers 20 n-grams obtinguts amb cada mètrica.\n",
    "</div>\n",
    "<br>\n",
    "<b>Passos a realitzar</b>:\n",
    "\n",
    "- Obtenir els tokens del text de les opinions i etiquetar-los pel seu PoS\n",
    "- Aplicar les mètriques PMI i Likehood Ratio per calcular els millors bigrames i els millors trigrames a partir dels tokens etiquetatge iels que no comencen ni terennen amb una stopword."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Jtmvp_5FB1xY",
   "metadata": {
    "id": "Jtmvp_5FB1xY"
   },
   "source": [
    "<div style=\"background-color: #F8F7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "    \n",
    "<i>Primer pas</i>: Obtenir els tokens del text de les ressenyes. Etiqueta aquests tokens pel seu PoS.\n",
    "\n",
    "Utilitza els mètodes *word_tokenize* per tokenitzar el text de les ressenyes i *pos_tag* per determinar l'etiqueta de cada token.\n",
    "<br>\n",
    "<b>Sortida esperada:</b> Imprimeix els deu primers tokens, amb la seva respectiva etiqueta:\n",
    "</div>\n",
    "<br>\n",
    "Abans de categoritzar els tokens pel seu tag POS, primer convertirem el text a minúscules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d964fd1a-ad1d-4d2c-b6b1-108f2df72630",
   "metadata": {
    "id": "d964fd1a-ad1d-4d2c-b6b1-108f2df72630"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yeah i watched this mini series with my mom and dad as a kid. it was one of the few mini series that my 9 year old mind actually could follow. i recall it was very well done and did not necessarily have the feel of the typical crap mini series. it wa'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creem text en minúscula que reculli totes les ressenyes.\n",
    "#A les següents línies df és el dataframe on es va carregar el dataset, i text és la columna que té el text preprocessat.\n",
    "#Se suggereix actualitzar la línia següent amb els objectes propis i fer córrer les instruccions.\n",
    "opinions = \" \".join(df['text']).lower()\n",
    "opinions[:250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c27f9b8",
   "metadata": {
    "id": "2c27f9b8"
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓ PAS 1                           #\n",
    "#############################################\n",
    "\n",
    "# Obtenció de les etiquetes POS per a cada token\n",
    "tokens = word_tokenize(opinions)\n",
    "tagged_tokens = pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a63aa1e-f1c4-44a1-8ff0-f8d2d5e1c21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Primeres 10 tuples (token, PoS):\n",
      "[('yeah', 'NN'), ('i', 'NN'), ('watched', 'VBD'), ('this', 'DT'), ('mini', 'NN'), ('series', 'NN'), ('with', 'IN'), ('my', 'PRP$'), ('mom', 'NN'), ('and', 'CC')]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPrimeres 10 tuples (token, PoS):\")\n",
    "print(tagged_tokens[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7287ecb",
   "metadata": {
    "id": "c7287ecb"
   },
   "source": [
    "<div style=\"background-color: #F8F7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "    \n",
    "<i>Segon pas</i>: Calcular els 300 millors bigrames i els 300 millors trigrames a partir dels tokens etiquetats (e.g. [(we, PRP), ...]) del text. Utilitza les mètriques PMI i Likehood Ratio.\n",
    "<br>\n",
    "<b>Condició</b>: De la llista de millors bigrames i trigrames, escull els que no comencen ni acabin amb una stopword. Per al filtratge de stopwords considera:\n",
    "- La llista prèviament carregada (des del paquet NLTK), i\n",
    "- Les categories POS que representen paraules buides com a determinants, preposicions, entre d'altres.\n",
    "<br>\n",
    "<b>Sortida esperada:</b> Imprimeix els primers 20 n-grams obtinguts amb cada mètrica.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2fe029",
   "metadata": {
    "id": "de2fe029"
   },
   "source": [
    "Recordeu la classificació d'etiquetes PoS.\n",
    "\n",
    "<b>Etiquetes PoS</b>\n",
    "\n",
    "<ul>\n",
    "<li>DT: Determinant</li>\n",
    "<li>JJ: Adjectiu</li>\n",
    "<li>NN: Nom en singular</li>\n",
    "<li>NNS: Nom en plural</li>\n",
    "<li>VBD: Verb en passat</li>\n",
    "<li>VBG: Verb en gerundi</li>\n",
    "<li>MD: Verb modal</li>\n",
    "<li>IN: Preposició o conjunció subordinada</li>\n",
    "<li>PRP: Pronom</li>\n",
    "<li>RB: Adverbi</li>\n",
    "<li>RP: Partícula</li>    \n",
    "<li>CC: Conjunció coordinada</li>\n",
    "<li>CD: Numeral</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43dfad33",
   "metadata": {
    "id": "43dfad33"
   },
   "outputs": [],
   "source": [
    "#Carreguem les mètriques per al càlcul de bigrames i trigrames:\n",
    "\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "\n",
    "##############################################\n",
    "# SOLUCIÓ PAS 2 #\n",
    "##############################################\n",
    "\n",
    "ngrams_num = 300\n",
    "\n",
    "words = [word for word, tag in tagged_tokens]\n",
    "\n",
    "# Funció per verificar n-grama (no comença ni acaba amb una stopword o amb POS buits)\n",
    "def valid_ngram(ngram):\n",
    "    # Mirem si la primera o l'última paraula està en la llista de stopwords\n",
    "    if ngram[0].lower() in stopwords or ngram[-1].lower() in stopwords:\n",
    "        return False\n",
    "    # Mirem si la primera o l'última paraula té etiqueta POS buida (ex. determinants, preposicions)\n",
    "    pos_first = nltk.pos_tag([ngram[0]])[0][1]\n",
    "    pos_last = nltk.pos_tag([ngram[-1]])[0][1]\n",
    "    if pos_first in ['DT', 'IN'] or pos_last in ['DT', 'IN']:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "358878ec-53a1-44d6-a01b-6ad21d695b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primers 20 bigrames per PMI:\n",
      "(\"'90s/early\", \"'00s\")\n",
      "(\"'achcha\", 'pitaji')\n",
      "(\"'aldar\", 'kose')\n",
      "(\"'alka\", 'fizz')\n",
      "(\"'apadi\", 'podu')\n",
      "(\"'carl\", 'spackler')\n",
      "(\"'chokher\", 'bali')\n",
      "(\"'clickety\", 'clack')\n",
      "(\"'club\", '905')\n",
      "(\"'coon\", 'huntin')\n",
      "(\"'deewana\", 'mastana')\n",
      "(\"'den\", 'brysomme')\n",
      "(\"'dewey\", 'cheetam')\n",
      "(\"'donna\", 'snartlebutt')\n",
      "(\"'drill\", 'seargent')\n",
      "(\"'errol\", 'flynt')\n",
      "(\"'eureka\", 'maru')\n",
      "(\"'faux\", 'terribles')\n",
      "(\"'greenhouse\", \"effect'before\")\n",
      "(\"'iedereen\", 'beroemd')\n",
      "\n",
      "Primers 20 bigrames per Likelihood Ratio:\n",
      "('special', 'effects')\n",
      "('.', '.')\n",
      "('low', 'budget')\n",
      "('sci', 'fi')\n",
      "('ever', 'seen')\n",
      "('let', 'us')\n",
      "('new', 'york')\n",
      "('year', 'old')\n",
      "('years', 'ago')\n",
      "('movie', '.')\n",
      "('high', 'school')\n",
      "('.', 'however')\n",
      "('much', 'better')\n",
      "('real', 'life')\n",
      "('martial', 'arts')\n",
      "('main', 'character')\n",
      "('film', '.')\n",
      "('pretty', 'much')\n",
      "('years', 'later')\n"
     ]
    }
   ],
   "source": [
    "from nltk.collocations import BigramCollocationFinder, TrigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures, TrigramAssocMeasures\n",
    "\n",
    "# BIGRAMES\n",
    "\n",
    "bigram_finder = BigramCollocationFinder.from_words(words)\n",
    "\n",
    "# 300 millors segons PMI\n",
    "top300_bigrams_pmi = bigram_finder.nbest(BigramAssocMeasures.pmi, ngrams_num)\n",
    "\n",
    "# Likelihood Ratio\n",
    "bigram_finder = BigramCollocationFinder.from_words(words)\n",
    "top300_bigrams_ll = bigram_finder.nbest(BigramAssocMeasures.likelihood_ratio, ngrams_num)\n",
    "\n",
    "# Filtrar per no començar ni acabar amb stopwords o POS buits\n",
    "filtered_bigrams_pmi = [bg for bg in top300_bigrams_pmi if valid_ngram(bg)]\n",
    "filtered_bigrams_ll = [bg for bg in top300_bigrams_ll if valid_ngram(bg)]\n",
    "\n",
    "print(\"Primers 20 bigrames per PMI:\")\n",
    "for bg in filtered_bigrams_pmi[:20]:\n",
    "    print(bg)\n",
    "\n",
    "print(\"\\nPrimers 20 bigrames per Likelihood Ratio:\")\n",
    "for bg in filtered_bigrams_ll[:20]:\n",
    "    print(bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7dc7bb5a-0154-4ddc-a917-3bef380bfeee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Primeres 20 trigrames per PMI:\n",
      "(\"'den\", 'brysomme', 'mannen')\n",
      "(\"'shark\", 'fralick', 'sangster')\n",
      "('.colonel', 'marmaduke', 'oldfish')\n",
      "('2.carrie', '3.scream', '4.any')\n",
      "('7/10molly', 'celaschi', 'myspace.com/horroryearbook')\n",
      "('a.żmijewski', 'd.stenka', 'm.komorowska')\n",
      "('aan', 'pyasa', 'kagaz')\n",
      "('abdul', 'salam', 'yusoufzai')\n",
      "('adi', 'hasak', 'ric')\n",
      "('aimée', 'giulia', 'boschi')\n",
      "('alpert', 'sayid', 'jarrah')\n",
      "('ammmmm', 'daaaarrrkk', 'heeeeaaarrt')\n",
      "('antietam', 'gettysburg', 'appomatox')\n",
      "('arcaica', 'proibido', 'proibir')\n",
      "('assef', 'elham', 'ehsas')\n",
      "('auger', 'grégori', 'deràngere')\n",
      "('baleful', 'kô', 'nishimura')\n",
      "('battlecry', 'buza', 'chika')\n",
      "('bonita', 'granville', 'nacy')\n",
      "('bunuels', 'chien', 'andalou')\n",
      "\n",
      "Primeres 20 trigrames per Likelihood Ratio:\n",
      "('.', 'this', 'movie')\n"
     ]
    }
   ],
   "source": [
    "# TRIGRAMES\n",
    "\n",
    "trigram_finder = TrigramCollocationFinder.from_words(words)\n",
    "\n",
    "# 300 millors segons PMI\n",
    "top300_trigrams_pmi = trigram_finder.nbest(TrigramAssocMeasures.pmi, ngrams_num)\n",
    "\n",
    "# Likelihood Ratio\n",
    "trigram_finder = TrigramCollocationFinder.from_words(words)\n",
    "top300_trigrams_ll = trigram_finder.nbest(TrigramAssocMeasures.likelihood_ratio, ngrams_num)\n",
    "\n",
    "# Filtrar els trigrames que compleixin la condició (només primer i últim token)\n",
    "filtered_trigrams_pmi = [tg for tg in top300_trigrams_pmi if valid_ngram(tg)]\n",
    "filtered_trigrams_ll = [tg for tg in top300_trigrams_ll if valid_ngram(tg)]\n",
    "\n",
    "print(\"\\nPrimeres 20 trigrames per PMI:\")\n",
    "for tg in filtered_trigrams_pmi[:20]:\n",
    "    print(tg)\n",
    "\n",
    "print(\"\\nPrimeres 20 trigrames per Likelihood Ratio:\")\n",
    "for tg in filtered_trigrams_ll[:20]:\n",
    "    print(tg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3883d1ca",
   "metadata": {
    "id": "3883d1ca"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<strong>Exercici 2.1.2:</strong> Detectar n-grames que compleixen el patró sintàctic d'un sintagma nominal (e.g: adjectiu + nom en singular/plural, nom + nom i nom en singular/plural). Les paraules components de cada n-grama han d'estar separades per un guió \"-\".\n",
    "<br>\n",
    "<b>Sortida esperada:</b> Llista dels 20 primers n-grames que compleixin el patró sintàctic especificat, per exemple, 'new_york' i 'tourism'.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50c96d2e",
   "metadata": {
    "id": "50c96d2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeres 20 n-grams (sintagmes nominals) que compleixen el patró:\n",
      "yeah_i\n",
      "mini_series\n",
      "few_mini\n",
      "old_mind\n",
      "typical_crap\n",
      "crap_mini\n",
      "original_concept\n",
      "plot_twists\n",
      "history_channel\n",
      "royal_families\n",
      "visual_aspect\n",
      "many_ways\n",
      "dumpy_woman\n",
      "bright_intelligent\n",
      "early_years\n",
      "young_woman\n",
      "true_love\n",
      "passionate_relationship\n",
      "sound_performances\n",
      "historical_accuracy\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# SOLUCIÓ                                  #\n",
    "#############################################\n",
    "\n",
    "noun_phrases = []\n",
    "\n",
    "# Bigrames:\n",
    "#  - adjectiu i després nom (JJ -> NN/NNS)\n",
    "#  - nom i després nom (NN/NNS -> NN/NNS)\n",
    "for i in range(len(tagged_tokens) - 1):\n",
    "    word1, pos1 = tagged_tokens[i]\n",
    "    word2, pos2 = tagged_tokens[i + 1]\n",
    "    if (pos1 == 'JJ' and pos2 in ['NN', 'NNS']) or (pos1 in ['NN', 'NNS'] and pos2 in ['NN', 'NNS']):\n",
    "        noun_phrases.append(word1 + \"_\" + word2)\n",
    "\n",
    "# Trigrames:\n",
    "#  - (JJ, NN/NNS, NN/NNS) o (NN/NNS, NN/NNS, NN/NNS)\n",
    "for i in range(len(tagged_tokens) - 2):\n",
    "    word1, pos1 = tagged_tokens[i]\n",
    "    word2, pos2 = tagged_tokens[i + 1]\n",
    "    word3, pos3 = tagged_tokens[i + 2]\n",
    "    if ((pos1 == 'JJ' and pos2 in ['NN', 'NNS'] and pos3 in ['NN', 'NNS']) or\n",
    "            (pos1 in ['NN', 'NNS'] and pos2 in ['NN', 'NNS'] and pos3 in ['NN', 'NNS'])):\n",
    "        noun_phrases.append(word1 + \"_\" + word2 + \"_\" + word3)\n",
    "\n",
    "# Eliminem duplicats\n",
    "unique_noun_phrases = []\n",
    "for phrase in noun_phrases:\n",
    "    if phrase not in unique_noun_phrases:\n",
    "        unique_noun_phrases.append(phrase)\n",
    "    if len(unique_noun_phrases) >= 20:\n",
    "        break\n",
    "\n",
    "print(\"Primeres 20 n-grams (sintagmes nominals) que compleixen el patró:\")\n",
    "for phrase in unique_noun_phrases[:20]:\n",
    "    print(phrase)      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535c0a10",
   "metadata": {
    "id": "535c0a10"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 1em;\">\n",
    "\n",
    "<strong>Exercici 2.1.3:</strong> Detectar col·locacions amb un model de detecció de frases, amb el mòdul Phraser de Gensim. Entrenar el model amb totes les opinions.\n",
    "<br>\n",
    "</div>\n",
    "<br>\n",
    "<b>Passos a realitzar</b>:\n",
    "\n",
    "1. Crear la llista de sentències. Prendre com a referència el codi comentat que consta a la cel·la següent.\n",
    "2. Convertir les ressenyes en una llista de phrases. Les phrases no han de ser stopwords. Tampoc no han de començar ni acabar amb una stopword.\n",
    "3. Entrenar el model amb totes les opinions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9964125a-792f-409b-ac9c-fdb846aad084",
   "metadata": {
    "id": "9964125a-792f-409b-ac9c-fdb846aad084"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeres 10 sentències filtrades:\n",
      "['yeah i watched this mini series with my mom and dad as a kid', 'although most twists in this movie are either spelled out or predictable it is still worth the time', 'although viewers should not expect to be electrified this film is very well made and the visual aspect is second to none', 'spoiler alert the historical accuracy is somewhat questionable as at no time did prince albert get shot while defending victoria', 'though this is a broad generalization parents of that time were too self absorbed to be real parents and those who were home tended to be far too distracted from the real issues where their children were concerned', \"baio's skateboarding through a pack of goons and outrunning them was meant to show us that the troubled times will pass and we are meant to get through them to better times.the whole metaphor of moving on and the procession of life is present throughout the film and serves to give us hope in the end.i like this movie though i do not watch it often as it tends to make me melancholy.it should not be viewed by young children and probably only those raised in the 1970's 80's would want to.it rates a 7.4/10 from...the fiend :\", 'atlantis gets and keeps your attention', 'michael j', 'fox as milo was an excellent choice', \"ocean's 13 will be about the same thieves who are trying to steal a screenplay well hidden somewhere in hollywood\"]\n"
     ]
    }
   ],
   "source": [
    "#Crear la lista de sentences. Las siguientes líneas pueden ser tomadas como referencia\n",
    "#Actualizar el nombre del dataframe y de la columna del texto pre-procesado.#\n",
    "opinions_string = \" \".join(df['text'])\n",
    "\n",
    "opinion_sentences = opinions_string.split('. ')\n",
    "\n",
    "opinion_sentences[:10]\n",
    "\n",
    "def valid_sentence(sent):\n",
    "    tokens = nltk.word_tokenize(sent)\n",
    "    if not tokens:\n",
    "        return False\n",
    "    # Mirem si primera i l'última paraula no son stopwords\n",
    "    return (tokens[0] not in stopwords) and (tokens[-1] not in stopwords)\n",
    "\n",
    "filtered_sentences = [sent for sent in opinion_sentences if valid_sentence(sent)]\n",
    "print(\"Primeres 10 sentències filtrades:\")\n",
    "print(filtered_sentences[:10])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33a69db6-a328-4325-802f-1592cf2a4205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exemple d'una sentència amb col·locacions detectades:\n",
      "['yeah', 'i_watched', 'this', 'mini_series', 'with', 'my', 'mom', 'and', 'dad', 'as', 'a', 'kid']\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "# Entrenar el model de detecció de frases\n",
    "phrases_model = Phrases([nltk.word_tokenize(sent) for sent in filtered_sentences],\n",
    "                         min_count=5, threshold=10)\n",
    "phraser = Phraser(phrases_model)\n",
    "\n",
    "# Detectar col·locacions a les sentències tokenitzades\n",
    "collocated_sentences = [phraser[nltk.word_tokenize(sent)] for sent in filtered_sentences]\n",
    "\n",
    "print(\"\\nExemple d'una sentència amb col·locacions detectades:\")\n",
    "print(collocated_sentences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a766d9-8390-4766-83d4-1cbcb7cbd816",
   "metadata": {
    "id": "d9a766d9-8390-4766-83d4-1cbcb7cbd816"
   },
   "source": [
    "<div style=\"background-color: #F8F7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<i>Segon pas</i>: Converteix les ressenyes en una llista de *phrases*. Les phrases no han de ser stopwords. Tampoc no han de començar, ni acabar amb una stopword. Fes servir la llista de stopwords per al filtratge.\n",
    "<br>\n",
    "<b> Sortida esperada:</b> Llista de les 20 primeres phrases* que no siguin, o no continguin stopwords.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97f2bd0b",
   "metadata": {
    "id": "97f2bd0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeres 20 sentències filtrades:\n",
      "yeah i watched this mini series with my mom and dad as a kid\n",
      "although most twists in this movie are either spelled out or predictable it is still worth the time\n",
      "although viewers should not expect to be electrified this film is very well made and the visual aspect is second to none\n",
      "spoiler alert the historical accuracy is somewhat questionable as at no time did prince albert get shot while defending victoria\n",
      "though this is a broad generalization parents of that time were too self absorbed to be real parents and those who were home tended to be far too distracted from the real issues where their children were concerned\n",
      "baio's skateboarding through a pack of goons and outrunning them was meant to show us that the troubled times will pass and we are meant to get through them to better times.the whole metaphor of moving on and the procession of life is present throughout the film and serves to give us hope in the end.i like this movie though i do not watch it often as it tends to make me melancholy.it should not be viewed by young children and probably only those raised in the 1970's 80's would want to.it rates a 7.4/10 from...the fiend :\n",
      "atlantis gets and keeps your attention\n",
      "michael j\n",
      "fox as milo was an excellent choice\n",
      "ocean's 13 will be about the same thieves who are trying to steal a screenplay well hidden somewhere in hollywood\n",
      "13 people because it is the lucky number of andy garcia's character\n",
      "alexandra staden as modesty is stunningly beautiful and an excellent choice\n",
      "also you have to play the game for about 2 hours just to get past the intro/tutorials\n",
      "people's proved a screenplay with bizarre twists and fantastic ideas about the nature of time  i especially love the idea one cannot change the past it is a nice counterpoint to so many time travelling movies which say otherwise  biological holocausts and the thin line between sanity and madness\n",
      "gilliam visualized his ideas with unique quirkiness perfection and originality.the story itself is engaging: one man james cole played by bruce willis in a heart warming performance travels several decades to the past to retrieve information about a virus that is wiped out mankind and left only a few survivors alive living underground: with the information he will collect scientists hope to find a cure so everyone in the future can return to the surface\n",
      "brad pitt still steals all the scenes he is in playing jeffrey goines  almost a prelude to his tyler durden character in fight club  a rich kid with some anarchist/non conformist ideas who is also crazy and according to cole perhaps responsible for the virus\n",
      "cole is a rather ambiguous character peoples' tried to imbue some darkness in him and he does other disturbing things to other people and to himself: the scene where he removes his own teeth reveals how far his dementia has gone unchecked\n",
      "ironically cole did not start as a crazy character but when he starts warning everyone about the end of the world he is considered mad and convinced it is all in his mind until he arrives at a point when he cannot distinguish past from future reality from fiction\n",
      "willis spends a lot of time looking confused and insecure and it works perfectly\n",
      "one of the fun twists in the narrative is when cole's shrink dr\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.phrases import Phraser\n",
    "from gensim.models import Phrases\n",
    "\n",
    "#############################################\n",
    "# SOLUCIÓ PAS 2                           #\n",
    "#############################################\n",
    "\n",
    "opinions_string = \" \".join(df['text'])\n",
    "opinion_sentences = opinions_string.split('. ')\n",
    "\n",
    "# Funció per determinar si una sentència és vàlida:\n",
    "# - No és buida.\n",
    "# - No comença ni acaba amb una stopword.\n",
    "def valid_sentence(sent):\n",
    "    tokens = nltk.word_tokenize(sent)\n",
    "    if not tokens:\n",
    "        return False\n",
    "    # Mirem que la primera i l'última paraula no siguin stopwords\n",
    "    if tokens[0] in stopwords or tokens[-1] in stopwords:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "# Filtrem\n",
    "filtered_sentences = [sent for sent in opinion_sentences if valid_sentence(sent)]\n",
    "\n",
    "print(\"Primeres 20 sentències filtrades:\")\n",
    "for sent in filtered_sentences[:20]:\n",
    "    print(sent)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e13a71",
   "metadata": {
    "id": "d4e13a71"
   },
   "source": [
    "## 2.2 Vectorització de paraules i termes amb Word2Vec\n",
    "\n",
    "Abans de desenvolupar els exercicis, cal importar gensim i treure espais del text. (ja està fet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8035bde3-06ee-49c0-9bd5-9466a4e1803b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i_watched', 'mini_series', 'this_movie', 'not_expect', 'to_be', 'this_film', 'very_well', 'spoiler_alert', 'to_be', 'those_who']\n"
     ]
    }
   ],
   "source": [
    "opinion_phrases_no_stopwords = []\n",
    "for sentence in collocated_sentences:\n",
    "    for token in sentence:\n",
    "        if '_' in token:\n",
    "            opinion_phrases_no_stopwords.append(token)\n",
    "\n",
    "opinion_phrases_stripped_no_stopwords = [c.strip() for c in opinion_phrases_no_stopwords]\n",
    "print(opinion_phrases_stripped_no_stopwords[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4OGwpBv8fOtp",
   "metadata": {
    "id": "4OGwpBv8fOtp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i_watched',\n",
       " 'mini_series',\n",
       " 'this_movie',\n",
       " 'not_expect',\n",
       " 'to_be',\n",
       " 'this_film',\n",
       " 'very_well',\n",
       " 'spoiler_alert',\n",
       " 'to_be',\n",
       " 'those_who']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importar el paquet gensim, que implementa un mètode per entrenar models Word2Vec.\n",
    "\n",
    "import gensim\n",
    "\n",
    "#Abans de continuar se suggereix treure espais del text: considerar el codi comentat següent.\n",
    "#Considereu que, opinion_phrases_no_stopwords és l'objecte generat en el segon pas de l'Exercici 2.1.3.\n",
    "\n",
    "opinion_phrases_stripped_no_stopwords = [c.strip() for c in opinion_phrases_no_stopwords]\n",
    "opinion_phrases_stripped_no_stopwords[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aaa498",
   "metadata": {
    "id": "20aaa498"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<strong>Exercici 2.2.1:</strong> Obtenir targets de les opinions i els seus aspectes utilitzant el model Word2vec.\n",
    "<br>\n",
    "<b>Sortida esperada:</b> Llista dels primers 15 termes que tinguin més relació semàntica amb el terme/aspecte seleccionat.\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "Passos a realitzar:\n",
    "1. Convertir les frases de cada oració en un token.\n",
    "2. Crear una sentence stream on tots els tokens de les oracions estiguin lematitzats. Els tokens no poden ser stopwords ni tenir un stopword al començament o al final.\n",
    "3. Crear un model word2vec de les opinions lematitzades. El model s'ha de dir w2v_opinions.\n",
    "4. A partir del vocabulari del model word2vec, seleccionar possibles aspectes representatius de les opinions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d68931",
   "metadata": {
    "id": "a9d68931"
   },
   "source": [
    "<b><i>Primer pas</i></b>: Convertir les phrases de cada oració en un token. Per completar aquest pas:\n",
    "\n",
    "- Concatenar els tokens de la phrase amb el caràcter '_' (e.g: 'mew york' -> 'new_york').\n",
    "- En cada oració substituir els bigrames que són phrases per la forma tokenitzada (e.g: Aquesta és una best apps acordada amb un grup de persones -> Aquesta one of the best_apps és acordada amb un conjunt de persones).\n",
    "- En fer els passos anteriors, les col·locacions formaran part del vocabulari del model word2vec que generarem.\n",
    "\n",
    "<i>Important:</i> El codi següent es pot prendre com a referència per completar aquest primer pas. Considereu que:\n",
    "\n",
    "- *opinion_phrases_stripped_no_stopwords* és l'objecte creat en iniciar aquest apartat (2.2).\n",
    "- *opinion_sentences* és la llista de sentències creada al primer pas de l'Exercici 2.1.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dee08237",
   "metadata": {
    "id": "dee08237"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sit_back\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'yeah i watched this mini series with my mom and dad as a kid'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "\n",
    "# collocation_phrases = [phrase for phrase in list(set(opinion_phrases_stripped_no_stopwords)) if ' ' in phrase]\n",
    "collocation_phrases = [phrase for phrase in list(set(opinion_phrases_stripped_no_stopwords)) if '_' in phrase]\n",
    "print(collocation_phrases[9])\n",
    "\n",
    "def transform_sentence(sentence):\n",
    "    transformed_sentence = sentence\n",
    "    n_grams = list(ngrams(nltk.word_tokenize(sentence), 2))\n",
    "    ngrams_t = [' '.join(gram) for gram in n_grams]\n",
    "    for ngram in ngrams_t:\n",
    "        if ngram.lower() in collocation_phrases:\n",
    "            opt = ngram.replace(' ', '_')\n",
    "            transformed_sentence = transformed_sentence.replace(ngram,opt)\n",
    "    return transformed_sentence\n",
    "\n",
    "opinion_sentences_transformed = [transform_sentence(os) for os in opinion_sentences]\n",
    "opinion_sentences_transformed[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53930c4",
   "metadata": {
    "id": "b53930c4"
   },
   "source": [
    "<div style=\"background-color: #F8F7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<i>Segon pas</i>: Crear una sentence stream on tots els tokens de les oracions estiguin lematitzats. Els tokens no poden ser stopwords ni tenir un stopword al començament o al final. Per simplificar la tasca, podem considerar que el lema d'una col·locació no canvia i el seu PoS és col. (e.g: ['We run a top of the line system utilizing Windows 10 Pro'] -> [run', 'top', 'line', 'system', 'utilize', 'window', 'pro]).\n",
    "<br>\n",
    "<b> Sortida esperada:</b> Llista dels 10 primers tokens lematitzats (que no siguin, ni continguin stopwords).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9cfcef92",
   "metadata": {
    "id": "9cfcef92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yeah', 'watch', 'mini', 'series', 'mom', 'dad', 'kid', 'one', 'mini', 'series']\n"
     ]
    }
   ],
   "source": [
    "##############################################\n",
    "# SOLUCIÓ #\n",
    "##############################################\n",
    "\n",
    "#Importar els mètodes de la llibreria NLTK que lematitzen segons Wordnet\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet, stopwords as nltk_stopwords\n",
    "\n",
    "#Per obtenir el lema, el terme ha de tenir una etiqueta PoS. El format de l'etiqueta PoS de Wordnet és\n",
    "#diferent de l'etiqueta del pos tagger de NLTK\n",
    "\n",
    "stopwords_list = set(nltk_stopwords.words('english'))\n",
    "\n",
    "# Funció per convertir l'etiqueta del pos tagger de NLTK a WordNet\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def process_sentence(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    pos_tokens = pos_tag(tokens)\n",
    "    \n",
    "    lemmatized_tokens = []\n",
    "    for token, tag in pos_tokens:\n",
    "        token_lower = token.lower()\n",
    "        # Si stopword -> descartem\n",
    "        if token_lower in stopwords_list:\n",
    "            continue\n",
    "        \n",
    "        if '_' in token_lower:\n",
    "            # No comença amb stopword\n",
    "            parts = token_lower.split('_')\n",
    "            if parts[0] in stopwords_list or parts[-1] in stopwords_list:\n",
    "                continue\n",
    "            lemma = token_lower\n",
    "        else:\n",
    "            wn_tag = get_wordnet_pos(tag)\n",
    "            lemma = lemmatizer.lemmatize(token_lower, wn_tag)\n",
    "        lemmatized_tokens.append(lemma)\n",
    "    return lemmatized_tokens\n",
    "\n",
    "sentence_stream = []\n",
    "for sentence in opinion_sentences_transformed:\n",
    "    tokens = process_sentence(sentence)\n",
    "    sentence_stream.extend(tokens)\n",
    "\n",
    "print(sentence_stream[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b807880",
   "metadata": {
    "id": "7b807880"
   },
   "source": [
    "<div style=\"background-color: #F8F7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<i>Tercer pas</i>: Crear un model word2vec de les opinions lematitzades. El model s'ha de dir w2v_opinions.\n",
    "<br>\n",
    "<b> Sortida esperada:</b> Presentar la quantitat d'oracions usades al model (usa l'atribut *corpus_count*).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b033b7ad",
   "metadata": {
    "id": "b033b7ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'oracions utilitzades en el model: 73193\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# SOLUCIÓ                                   #\n",
    "#############################################\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "tokenized_sentences = [process_sentence(sentence) for sentence in opinion_sentences_transformed]\n",
    "\n",
    "# Entrenar el model Word2Vec\n",
    "w2v_opinions = Word2Vec(\n",
    "    sentences=tokenized_sentences,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=2,\n",
    "    workers=4\n",
    ")\n",
    "\n",
    "print(\"Nombre d'oracions utilitzades en el model:\", w2v_opinions.corpus_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e07b3c",
   "metadata": {
    "id": "00e07b3c"
   },
   "source": [
    "<div style=\"background-color: #F8F7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<i>Quart pas</i>: A partir del vocabulari del model word2vec, seleccionar possibles aspectes de la ressenya (e.g: desktop) i llista els termes semànticament relacionats amb aquests aspectes segons aquest model.\n",
    "<br>\n",
    "\n",
    "<b>Sortida esperada:</b> Llista els primers 20 termes que tinguin més relació semàntica amb un terme rellevant del domini.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "568d1445",
   "metadata": {
    "id": "568d1445"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alguns termes del vocabulari:\n",
      "['movie', 'film', \"'s\", 'one', 'make', 'like', 'see', 'good', 'get', 'would', 'time', 'character', 'go', 'watch', 'bad', 'well', 'even', 'story', 'think', 'really']\n",
      "\n",
      "Termes més relacionats amb 'story':\n",
      "plot: 0.7660\n",
      "characters.the: 0.7105\n",
      "interesting.the: 0.7066\n",
      "interest: 0.7020\n",
      "straddle: 0.6988\n",
      "along: 0.6909\n",
      "event: 0.6888\n",
      "twist: 0.6879\n",
      "storyline: 0.6671\n",
      "premise: 0.6641\n",
      "groaner: 0.6632\n",
      "element: 0.6622\n",
      "paradigm: 0.6595\n",
      "concept: 0.6581\n",
      "movie.what: 0.6574\n",
      "tale: 0.6574\n",
      "line: 0.6572\n",
      "cohesion: 0.6558\n",
      "unbelievable.the: 0.6544\n",
      "situation: 0.6498\n"
     ]
    }
   ],
   "source": [
    "##############################################\n",
    "# SOLUCIÓ                                    #\n",
    "##############################################\n",
    "\n",
    "# Vocabulari del model d'opinions\n",
    "vocab = list(w2v_opinions.wv.key_to_index.keys())\n",
    "print(\"Alguns termes del vocabulari:\")\n",
    "print(vocab[:20])\n",
    "\n",
    "aspect = 'story'\n",
    "\n",
    "# Extreure els 20 termes més semblants\n",
    "if aspect in w2v_opinions.wv:\n",
    "    related_terms = w2v_opinions.wv.most_similar(aspect, topn=20)\n",
    "    print(f\"\\nTermes més relacionats amb '{aspect}':\")\n",
    "    for term, score in related_terms:\n",
    "        print(f\"{term}: {score:.4f}\")\n",
    "else:\n",
    "    print(f\"\\nEl terme '{aspect}' no existeix al vocabulari del model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80090d4b",
   "metadata": {
    "id": "80090d4b"
   },
   "source": [
    "# 3. Detecció de temes\n",
    "\n",
    "En aquesta part ens dedicarem a explorar els temes detectats utilitzant WordNet i farem l'extracció de temes a partir de LDA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bb679a",
   "metadata": {
    "id": "00bb679a"
   },
   "source": [
    "## 3.1 Exploració dels temes amb WordNet\n",
    "\n",
    "Per accedir a Wordnet, utilitzeu la llibreria nltk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "320fee0c",
   "metadata": {
    "id": "320fee0c"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccd9034",
   "metadata": {
    "id": "7ccd9034"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<strong>Exercici 3.1.1:</strong> Comprovar si, segons Wordnet, hi ha aspectes que estan allunyats semànticament del sentit del target, encara que en el model word2vec siguin similars. Comprovar calculant la similitud de Wu and Palmer entre el sentit de wordnet del terme elegit (i.e 'word.n.01') i alguns dels seus aspectes.\n",
    "<br>\n",
    "<b> Sortida esperada: </b>\n",
    "<br>\n",
    "- Llista de dos termes que segons Wordnet no estiguin tan propers, i el seu respectiu resultat de similitud, i\n",
    "<br>\n",
    "- Llista dels mateixos termes que segons el model *word2vec* estan més propers.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f87758dd-35b7-4b01-a609-cdac75ddd2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Termes més propers segons Word2Vec a 'story':\n",
      "plot: 0.7660\n",
      "characters.the: 0.7105\n",
      "interesting.the: 0.7066\n",
      "interest: 0.7020\n",
      "straddle: 0.6988\n",
      "\n",
      "Similitud de Wu & Palmer amb 'story':\n",
      "plot: 0.2667\n",
      "characters.the: No s'ha trobat synset a WordNet.\n",
      "\n",
      "Similituds segons Word2Vec per 'story':\n",
      "plot: 0.7660\n",
      "characters.the: 0.7105\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# Triem el aspect\n",
    "aspect = 'story'\n",
    "\n",
    "# Termes propers segons word2vec\n",
    "if aspect in w2v_opinions.wv:\n",
    "    related_terms = w2v_opinions.wv.most_similar(aspect, topn=20)\n",
    "    print(f\"Termes més propers segons Word2Vec a '{aspect}':\")\n",
    "    for term, score in related_terms[:5]:\n",
    "        print(f\"{term}: {score:.4f}\")\n",
    "else:\n",
    "    print(f\"El terme '{aspect}' no existeix al vocabulari del model.\")\n",
    "\n",
    "# Agafem dos termes propers\n",
    "term1 = related_terms[0][0]\n",
    "term2 = related_terms[1][0]\n",
    "\n",
    "aspect_synset = wn.synset('story.n.01')\n",
    "\n",
    "# Per cada terme, busquem si existeix un synset relacionat amb el significat correcte\n",
    "def get_first_noun_synset(word):\n",
    "    synsets = wn.synsets(word, pos=wn.NOUN)\n",
    "    return synsets[0] if synsets else None\n",
    "\n",
    "synset1 = get_first_noun_synset(term1)\n",
    "synset2 = get_first_noun_synset(term2)\n",
    "\n",
    "# Calculem la similitud de Wu & Palmer\n",
    "if synset1:\n",
    "    similarity1 = aspect_synset.wup_similarity(synset1)\n",
    "else:\n",
    "    similarity1 = None\n",
    "\n",
    "if synset2:\n",
    "    similarity2 = aspect_synset.wup_similarity(synset2)\n",
    "else:\n",
    "    similarity2 = None\n",
    "\n",
    "print(f\"\\nSimilitud de Wu & Palmer amb '{aspect}':\")\n",
    "if similarity1 is not None:\n",
    "    print(f\"{term1}: {similarity1:.4f}\")\n",
    "else:\n",
    "    print(f\"{term1}: No s'ha trobat synset a WordNet.\")\n",
    "\n",
    "if similarity2 is not None:\n",
    "    print(f\"{term2}: {similarity2:.4f}\")\n",
    "else:\n",
    "    print(f\"{term2}: No s'ha trobat synset a WordNet.\")\n",
    "\n",
    "print(f\"\\nSimilituds segons Word2Vec per '{aspect}':\")\n",
    "print(f\"{term1}: {w2v_opinions.wv.similarity(aspect, term1):.4f}\")\n",
    "print(f\"{term2}: {w2v_opinions.wv.similarity(aspect, term2):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3209e5cc",
   "metadata": {
    "id": "3209e5cc"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<strong>Exercici 3.1.2:</strong> Identificar els termes monoparaula del vocabulari de word2vec que no són a Wordnet. Filtrar els termes que siguin noms o adjectius.\n",
    "\n",
    "Del conjunt de termes identificats, cal esmentar:\n",
    "- Abreviatures o termes específics del domini o expressions típiques de l'argot tech.<br>\n",
    "\n",
    "<b>Sortida esperada:</b>\n",
    "<br>\n",
    "- Quantitat de termes que no consten a Wordnet.\n",
    "- Llista dels 20 primers termes monoparaula que no consten a <i>Wordnet</i>.\n",
    "- Llista d'almenys 3 termes dels enlistats que, siguin inherents al vocabulari programari.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "302a9e46-5f9f-4088-9518-0ad342fe9827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantitat de termes monoparaula (noms o adjectius) que no consten a WordNet: 5722\n",
      "\n",
      "Primers 20 termes monoparaula que no consten a WordNet:\n",
      "['..', 'something', 'anything', 'anyone', 'everything', 'everyone', 'others', 'etc', '\\x96', 'dr', 'towards', 'richard', 'imdb', 'fi', 'joe', 'william', 'charlie', 'jane', 'everybody', 'cgi']\n",
      "\n",
      "Llista de 3 termes inherents al vocabulari del domini cinema/narrativa:\n",
      "['..', 'something', 'anything']\n"
     ]
    }
   ],
   "source": [
    "# Agafem tot el vocabulari del model\n",
    "vocab = list(w2v_opinions.wv.key_to_index.keys())\n",
    "\n",
    "# Filtrem\n",
    "single_word_vocab = [word for word in vocab if '_' not in word]\n",
    "tagged_words = nltk.pos_tag(single_word_vocab)\n",
    "nouns_adjectives = [word for word, pos in tagged_words if pos in ['NN', 'NNS', 'JJ']]\n",
    "\n",
    "# Filtrem les que no estan a wornet\n",
    "not_in_wordnet = [word for word in nouns_adjectives if not wn.synsets(word)]\n",
    "\n",
    "print(f\"Quantitat de termes monoparaula (noms o adjectius) que no consten a WordNet: {len(not_in_wordnet)}\\n\")\n",
    "\n",
    "print(\"Primers 20 termes monoparaula que no consten a WordNet:\")\n",
    "print(not_in_wordnet[:20])\n",
    "\n",
    "domain_terms = []\n",
    "for term in not_in_wordnet:\n",
    "    try:\n",
    "        # Mirem si la paraula té bona similitud amb conceptes clau\n",
    "        similarity_to_film = w2v_opinions.wv.similarity(term, 'film')\n",
    "        similarity_to_movie = w2v_opinions.wv.similarity(term, 'movie')\n",
    "        # Si similitud> 0.4 la considerem del domini\n",
    "        if similarity_to_film > 0.4 or similarity_to_movie > 0.4:\n",
    "            domain_terms.append(term)\n",
    "        if len(domain_terms) >= 3:\n",
    "            break\n",
    "    except KeyError:\n",
    "        continue\n",
    "\n",
    "print(\"\\nLlista de 3 termes inherents al vocabulari del domini cinema/narrativa:\")\n",
    "print(domain_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552e2929-2792-4ff5-ad74-96654530b4f6",
   "metadata": {},
   "source": [
    "Fem una tria manual, ja que els termes son molt generics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76c8b179-040f-4b04-8818-5b470bd7849e",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_terms = ['imdb', 'cgi', 'fi']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f788a4",
   "metadata": {
    "id": "f5f788a4"
   },
   "source": [
    "## 3.2. LDA\n",
    "\n",
    "Aquest apartat té com a objectiu comparar diferents models LDA i triar el més adequat de manera justificada.\n",
    "\n",
    "<b>Passos a seguir:</b>\n",
    "\n",
    "1. Convertir les opinions transformades en llistes de noms i col·locacions.\n",
    "2. Extreure temes a partir de les llistes de noms i col·locacions de cada oració transformada. Triar 3 dels millors experiments, segons el paràmetre *num_topics*, i presentar-ne els resultats. Assigna noms als temes trobats.\n",
    "3. Utilitzar la llibreria pyLDAvis per visualitzar els tòpics del millor model que vas trobar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6825ff",
   "metadata": {
    "id": "1c6825ff"
   },
   "source": [
    "<i>Primer pas</i>: Convertir les opinions transformades (opinion_sentences_transformed) en llistes de noms i col·locacions. Això és necessari ja que els noms i les col·locacions expressen els temes de les opinions (e.g: [['This és una de les millors opinions') -> ['one', 'best_apps', 'according' , 'people', 'opinion'].\n",
    "\n",
    "<b>Important:</b> El codi següent es pot prendre com a referència per implementar aquest primer pas:\n",
    "\n",
    "- opinion_sentences_transformed és l'objecte creat al primer pas de l'Exercici 2.2.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76ad1379",
   "metadata": {
    "id": "76ad1379"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeres 15 oracions convertides a noms i col·locacions:\n",
      "[['yeah', 'mini', 'series', 'mom', 'dad', 'kid'], ['mini', 'series', 'year', 'mind'], ['feel', 'crap', 'mini', 'series'], ['concept', 'attention'], ['miniseries', 'anyone', 'fan', 'history', 'plot', 'twist'], ['twist', 'movie', 'time'], ['netflix'], [], ['history', 'channel', 'something'], ['wife', 'family', 'britain', 'history', 'cinema'], ['viewer', 'film', 'aspect', 'none'], ['way', 'myth', 'victoria', 'woman', 'photograph'], ['intelligent', 'history', 'year', 'fun', 'woman'], ['love', 'albert', 'essence', 'love', 'number', 'child', 'passionate', 'relationship'], ['film']]\n"
     ]
    }
   ],
   "source": [
    "lem = WordNetLemmatizer()\n",
    "\n",
    "def get_noun_and_collocation(sentence):\n",
    "    nouns_and_collocations = []\n",
    "    noun_tags = ['NN', 'NNS']\n",
    "    tokens_pos_tagged = pos_tag(word_tokenize(sentence))\n",
    "    \n",
    "    for token, pos in tokens_pos_tagged:\n",
    "        lemma = lem.lemmatize(token)\n",
    "        if '_' in lemma:\n",
    "            nouns_and_collocations.append(lemma)\n",
    "        elif pos in noun_tags and lemma not in stopwords_list:\n",
    "            nouns_and_collocations.append(lemma)\n",
    "    \n",
    "    return nouns_and_collocations\n",
    "\n",
    "noun_and_collocation_stream = [\n",
    "    get_noun_and_collocation(opinion) for opinion in opinion_sentences_transformed\n",
    "]\n",
    "\n",
    "print(\"Primeres 15 oracions convertides a noms i col·locacions:\")\n",
    "print(noun_and_collocation_stream[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef21d0c",
   "metadata": {
    "id": "eef21d0c"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<strong>Exercici 3.2.1:</strong> Extreure temes a partir de les llistes de noms i col·locacions de cada oració transformada. A més, utilitza la llibreria pyLDAvis per visualitzar els tòpics del millor model que vas trobar.\n",
    "\n",
    "<b>Sortida esperada:</b>\n",
    "- De 3 dels millors experiments, i per cadascun imprimeix les 10 paraules que més es destaquin de cada tòpic.\n",
    "- Visualització del millor experiment, usant pyLDAvis.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3284e474",
   "metadata": {
    "id": "3284e474"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tòpic: 0 \n",
      "Paraules: 0.027*\"actor\" + 0.024*\"show\" + 0.015*\"series\" + 0.015*\"minute\" + 0.011*\"episode\" + 0.011*\"character\" + 0.009*\"role\" + 0.009*\"film\" + 0.008*\"tv\" + 0.008*\"time\"\n",
      "Tòpic: 1 \n",
      "Paraules: 0.015*\"guy\" + 0.015*\"woman\" + 0.014*\"girl\" + 0.010*\"character\" + 0.010*\"man\" + 0.010*\"friend\" + 0.008*\"family\" + 0.008*\"child\" + 0.008*\"life\" + 0.007*\"scene\"\n",
      "Tòpic: 2 \n",
      "Paraules: 0.015*\"kid\" + 0.006*\"time\" + 0.005*\"money\" + 0.005*\"game\" + 0.005*\"eye\" + 0.005*\"man\" + 0.005*\"world\" + 0.004*\"part\" + 0.004*\"scene\" + 0.004*\"war\"\n",
      "Tòpic: 3 \n",
      "Paraules: 0.084*\"film\" + 0.028*\"story\" + 0.024*\"character\" + 0.013*\"plot\" + 0.012*\"time\" + 0.011*\"..\" + 0.009*\"director\" + 0.008*\"scene\" + 0.008*\"acting\" + 0.007*\"life\"\n",
      "Tòpic: 4 \n",
      "Paraules: 0.130*\"movie\" + 0.034*\"film\" + 0.023*\"people\" + 0.021*\"time\" + 0.020*\"thing\" + 0.013*\"lot\" + 0.010*\"scene\" + 0.009*\"way\" + 0.008*\"horror\" + 0.007*\"effect\"\n"
     ]
    }
   ],
   "source": [
    "##############################################\n",
    "# SOLUCIÓ #\n",
    "##############################################\n",
    "\n",
    "import gensim.corpora as corpora\n",
    "\n",
    "dictionary = corpora.Dictionary(noun_and_collocation_stream)\n",
    "corpus = [dictionary.doc2bow(text) for text in noun_and_collocation_stream]\n",
    "\n",
    "# Experiment 1: amb 5 tòpics\n",
    "lda_model_5 = gensim.models.LdaMulticore(corpus, num_topics=5, id2word=dictionary, passes=10, workers=2)\n",
    "\n",
    "for idx, topic in lda_model_5.print_topics(-1):\n",
    "    print('Tòpic: {} \\nParaules: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0qiR1Dm4axdi",
   "metadata": {
    "id": "0qiR1Dm4axdi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tòpic: 0 \n",
      "Paraules: 0.072*\"character\" + 0.042*\"actor\" + 0.039*\"plot\" + 0.024*\"performance\" + 0.024*\"role\" + 0.020*\"acting\" + 0.020*\"script\" + 0.019*\"cast\" + 0.015*\"line\" + 0.012*\"word\"\n",
      "Tòpic: 1 \n",
      "Paraules: 0.021*\"effect\" + 0.019*\"person\" + 0.013*\"screen\" + 0.012*\"city\" + 0.009*\"set\" + 0.008*\"parent\" + 0.008*\"event\" + 0.008*\"image\" + 0.006*\"york\" + 0.006*\"business\"\n",
      "Tòpic: 2 \n",
      "Paraules: 0.257*\"movie\" + 0.036*\"people\" + 0.032*\"thing\" + 0.023*\"nothing\" + 0.022*\"series\" + 0.016*\"lot\" + 0.015*\"part\" + 0.012*\"book\" + 0.012*\"tv\" + 0.011*\"way\"\n",
      "Tòpic: 3 \n",
      "Paraules: 0.126*\"time\" + 0.045*\"show\" + 0.023*\"minute\" + 0.019*\"hour\" + 0.016*\"episode\" + 0.010*\"kind\" + 0.010*\"way\" + 0.008*\"thing\" + 0.008*\"couple\" + 0.008*\"life\"\n",
      "Tòpic: 4 \n",
      "Paraules: 0.081*\"scene\" + 0.022*\"music\" + 0.019*\"everything\" + 0.016*\"camera\" + 0.016*\"action\" + 0.015*\"work\" + 0.014*\"shot\" + 0.014*\"sequence\" + 0.013*\"sex\" + 0.013*\"story\"\n",
      "Tòpic: 5 \n",
      "Paraules: 0.056*\"film\" + 0.055*\"movie\" + 0.030*\"something\" + 0.023*\"fan\" + 0.021*\"horror\" + 0.020*\"one\" + 0.018*\"reason\" + 0.017*\"anyone\" + 0.015*\"dvd\" + 0.013*\"budget\"\n",
      "Tòpic: 6 \n",
      "Paraules: 0.039*\"..\" + 0.021*\"end\" + 0.014*\"car\" + 0.013*\"killer\" + 0.011*\"country\" + 0.010*\"mind\" + 0.008*\"jack\" + 0.007*\"guy\" + 0.007*\"john\" + 0.007*\"mark\"\n",
      "Tòpic: 7 \n",
      "Paraules: 0.199*\"film\" + 0.030*\"way\" + 0.017*\"story\" + 0.017*\"character\" + 0.017*\"director\" + 0.010*\"audience\" + 0.010*\"people\" + 0.010*\"life\" + 0.009*\"point\" + 0.007*\"end\"\n",
      "Tòpic: 8 \n",
      "Paraules: 0.032*\"man\" + 0.023*\"war\" + 0.017*\"eye\" + 0.016*\"men\" + 0.011*\"look\" + 0.011*\"world\" + 0.010*\"day\" + 0.009*\"case\" + 0.009*\"laugh\" + 0.009*\"theater\"\n",
      "Tòpic: 9 \n",
      "Paraules: 0.047*\"story\" + 0.026*\"girl\" + 0.021*\"love\" + 0.021*\"family\" + 0.021*\"woman\" + 0.020*\"child\" + 0.019*\"life\" + 0.019*\"friend\" + 0.015*\"guy\" + 0.015*\"kid\"\n"
     ]
    }
   ],
   "source": [
    "#Experiment 2: amb n2 tòpics:\n",
    "\n",
    "##############################################\n",
    "# SOLUCIÓ                                    #\n",
    "##############################################\n",
    "\n",
    "lda_model_10 = gensim.models.LdaMulticore(corpus, num_topics=10, id2word=dictionary, passes=10, workers=2)\n",
    "\n",
    "for idx, topic in lda_model_10.print_topics(-1):\n",
    "    print('Tòpic: {} \\nParaules: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "vj-uBeYebAp1",
   "metadata": {
    "id": "vj-uBeYebAp1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tòpic: 0 \n",
      "Paraules: 0.087*\"plot\" + 0.040*\"child\" + 0.039*\"kid\" + 0.032*\"acting\" + 0.029*\"everyone\" + 0.019*\"joke\" + 0.019*\"way\" + 0.017*\"school\" + 0.012*\"vampire\" + 0.011*\"parent\"\n",
      "Tòpic: 1 \n",
      "Paraules: 0.406*\"movie\" + 0.060*\"time\" + 0.016*\"fan\" + 0.016*\"horror\" + 0.014*\"star\" + 0.013*\"people\" + 0.013*\"money\" + 0.011*\"year\" + 0.009*\"number\" + 0.009*\"way\"\n",
      "Tòpic: 2 \n",
      "Paraules: 0.339*\"film\" + 0.022*\"time\" + 0.021*\"minute\" + 0.016*\"dvd\" + 0.011*\"horror\" + 0.010*\"budget\" + 0.010*\"director\" + 0.010*\"year\" + 0.009*\"people\" + 0.009*\"war\"\n",
      "Tòpic: 3 \n",
      "Paraules: 0.111*\"thing\" + 0.053*\"lot\" + 0.046*\"action\" + 0.016*\"name\" + 0.015*\"john\" + 0.013*\"flick\" + 0.013*\"production\" + 0.012*\"scene\" + 0.012*\"rating\" + 0.012*\"thriller\"\n",
      "Tòpic: 4 \n",
      "Paraules: 0.079*\"show\" + 0.069*\"something\" + 0.055*\"series\" + 0.041*\"tv\" + 0.035*\"episode\" + 0.032*\"line\" + 0.019*\"matter\" + 0.017*\"mr\" + 0.016*\"time\" + 0.015*\"opinion\"\n",
      "Tòpic: 5 \n",
      "Paraules: 0.164*\"character\" + 0.045*\"end\" + 0.020*\"scene\" + 0.016*\"story\" + 0.015*\"humor\" + 0.014*\"death\" + 0.014*\"time\" + 0.012*\"laugh\" + 0.012*\"none\" + 0.011*\"fight\"\n",
      "Tòpic: 6 \n",
      "Paraules: 0.040*\"people\" + 0.035*\"work\" + 0.025*\"camera\" + 0.024*\"couple\" + 0.024*\"word\" + 0.018*\"day\" + 0.018*\"killer\" + 0.013*\"guess\" + 0.013*\"time\" + 0.011*\"attention\"\n",
      "Tòpic: 7 \n",
      "Paraules: 0.030*\"sex\" + 0.025*\"case\" + 0.019*\"scene\" + 0.018*\"body\" + 0.017*\"stuff\" + 0.016*\"room\" + 0.016*\"blood\" + 0.015*\"violence\" + 0.013*\"city\" + 0.011*\"york\"\n",
      "Tòpic: 8 \n",
      "Paraules: 0.038*\"bit\" + 0.032*\"idea\" + 0.032*\"anyone\" + 0.029*\"year\" + 0.025*\"night\" + 0.024*\"game\" + 0.017*\"wife\" + 0.016*\"piece\" + 0.013*\"murder\" + 0.013*\"face\"\n",
      "Tòpic: 9 \n",
      "Paraules: 0.066*\"actor\" + 0.054*\"scene\" + 0.037*\"role\" + 0.034*\"music\" + 0.030*\"cast\" + 0.027*\"book\" + 0.019*\"song\" + 0.017*\"performance\" + 0.015*\"dialogue\" + 0.015*\"job\"\n",
      "Tòpic: 10 \n",
      "Paraules: 0.044*\"love\" + 0.036*\"moment\" + 0.029*\"problem\" + 0.021*\"others\" + 0.020*\"story\" + 0.018*\"course\" + 0.016*\"set\" + 0.014*\"dream\" + 0.013*\"reality\" + 0.012*\"documentary\"\n",
      "Tòpic: 11 \n",
      "Paraules: 0.050*\"nothing\" + 0.049*\"..\" + 0.036*\"anything\" + 0.028*\"reason\" + 0.026*\"sense\" + 0.023*\"kind\" + 0.018*\"point\" + 0.017*\"viewer\" + 0.014*\"feeling\" + 0.013*\"story\"\n",
      "Tòpic: 12 \n",
      "Paraules: 0.042*\"family\" + 0.039*\"friend\" + 0.027*\"house\" + 0.022*\"hand\" + 0.018*\"picture\" + 0.016*\"group\" + 0.016*\"brother\" + 0.015*\"watch\" + 0.014*\"art\" + 0.014*\"home\"\n",
      "Tòpic: 13 \n",
      "Paraules: 0.043*\"comedy\" + 0.035*\"performance\" + 0.034*\"director\" + 0.031*\"audience\" + 0.030*\"girl\" + 0.029*\"everything\" + 0.029*\"hour\" + 0.024*\"fun\" + 0.020*\"script\" + 0.018*\"half\"\n",
      "Tòpic: 14 \n",
      "Paraules: 0.065*\"life\" + 0.038*\"man\" + 0.038*\"guy\" + 0.035*\"one\" + 0.034*\"woman\" + 0.027*\"story\" + 0.015*\"boy\" + 0.014*\"head\" + 0.014*\"father\" + 0.013*\"men\"\n"
     ]
    }
   ],
   "source": [
    "#Experiment 3: amb n3 tòpics:\n",
    "\n",
    "##############################################\n",
    "# SOLUCIÓ                                    #\n",
    "##############################################\n",
    "\n",
    "lda_model_15 = gensim.models.LdaMulticore(corpus, num_topics=15, id2word=dictionary, passes=10, workers=2)\n",
    "\n",
    "for idx, topic in lda_model_15.print_topics(-1):\n",
    "    print('Tòpic: {} \\nParaules: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153c549e-7fbb-47b3-88a0-ed7ba24ce913",
   "metadata": {
    "id": "153c549e-7fbb-47b3-88a0-ed7ba24ce913"
   },
   "source": [
    "Fes servir la llibreria pyLDAvis per visualitzar els tòpics del millor model trobat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4cd5532b-628f-4c13-b34d-f65d18c48e33",
   "metadata": {
    "id": "4cd5532b-628f-4c13-b34d-f65d18c48e33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyLDAvis in /home/win001/anaconda3/envs/textos_new/lib/python3.9/site-packages (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.24.2 in /home/win001/anaconda3/envs/textos_new/lib/python3.9/site-packages (from pyLDAvis) (1.26.4)\n",
      "Requirement already satisfied: scipy in /home/win001/anaconda3/envs/textos_new/lib/python3.9/site-packages (from pyLDAvis) (1.13.1)\n",
      "Requirement already satisfied: pandas>=2.0.0 in /home/win001/anaconda3/envs/textos_new/lib/python3.9/site-packages (from pyLDAvis) (2.2.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/win001/anaconda3/envs/textos_new/lib/python3.9/site-packages (from pyLDAvis) (1.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/win001/anaconda3/envs/textos_new/lib/python3.9/site-packages (from pyLDAvis) (3.1.6)\n",
      "Requirement already satisfied: numexpr in /home/win001/anaconda3/envs/textos_new/lib/python3.9/site-packages (from pyLDAvis) (2.10.2)\n",
      "Requirement already satisfied: funcy in /home/win001/anaconda3/envs/textos_new/lib/python3.9/site-packages (from pyLDAvis) (2.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /home/win001/anaconda3/envs/textos_new/lib/python3.9/site-packages (from pyLDAvis) (1.6.1)\n",
      "Requirement already satisfied: gensim in /home/win001/anaconda3/envs/textos_new/lib/python3.9/site-packages (from pyLDAvis) (4.3.3)\n",
      "Requirement already satisfied: setuptools in /home/win001/anaconda3/envs/textos_new/lib/python3.9/site-packages (from pyLDAvis) (75.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/win001/anaconda3/envs/textos_new/lib/python3.9/site-packages (from pandas>=2.0.0->pyLDAvis) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/win001/anaconda3/envs/textos_new/lib/python3.9/site-packages (from pandas>=2.0.0->pyLDAvis) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/win001/anaconda3/envs/textos_new/lib/python3.9/site-packages (from pandas>=2.0.0->pyLDAvis) (2025.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/win001/anaconda3/envs/textos_new/lib/python3.9/site-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.6.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/win001/anaconda3/envs/textos_new/lib/python3.9/site-packages (from gensim->pyLDAvis) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/win001/anaconda3/envs/textos_new/lib/python3.9/site-packages (from jinja2->pyLDAvis) (3.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/win001/anaconda3/envs/textos_new/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.16.0)\n",
      "Requirement already satisfied: wrapt in /home/win001/anaconda3/envs/textos_new/lib/python3.9/site-packages (from smart-open>=1.8.1->gensim->pyLDAvis) (1.17.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyLDAvis\n",
    "\n",
    "#Instal·lar la versió colles 1.5.3 si utilitzeu Google Colab com a entorn d'execució.\n",
    "#!pip install pandes==1.5.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bd0176bf-8795-49b8-9f7c-eda69c3b3842",
   "metadata": {
    "id": "bd0176bf-8795-49b8-9f7c-eda69c3b3842"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el294481241067965022566529873082\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el294481241067965022566529873082_data = {\"mdsDat\": {\"x\": [0.0944140350604231, -0.17548311231903285, 0.19390798605701942, 0.007332503130981084, -0.044933621718211844, 0.22938306459208838, -0.1948762805660917, 0.15566232569422206, -0.14219027362373388, -0.12321662630766372], \"y\": [-0.2562100813886287, -0.0915581036916489, 0.127390061992815, 0.08986837432465679, -0.19479485707979943, 0.05191718669615502, 0.02460033125946053, -0.0021696930054696598, 0.09728953323918368, 0.1536672476532758], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [11.078327628429498, 7.560098576362413, 11.674889519299596, 9.221080915955921, 9.06379150927978, 11.003673203680973, 7.389799946903894, 13.015887520218921, 8.792442093732358, 11.200009086136646]}, \"tinfo\": {\"Term\": [\"movie\", \"film\", \"time\", \"scene\", \"character\", \"story\", \"actor\", \"show\", \"plot\", \"people\", \"..\", \"something\", \"man\", \"way\", \"thing\", \"girl\", \"role\", \"nothing\", \"fan\", \"performance\", \"love\", \"family\", \"horror\", \"series\", \"woman\", \"minute\", \"war\", \"acting\", \"script\", \"child\", \"actor\", \"acting\", \"script\", \"word\", \"actress\", \"cast\", \"play\", \"lead\", \"dialogue\", \"talent\", \"location\", \"stage\", \"season\", \"development\", \"yes\", \"hole\", \"skill\", \"decision\", \"casting\", \"atmosphere\", \"chemistry\", \"charm\", \"dozen\", \"sub\", \"robin\", \"winner\", \"fashion\", \"dick\", \"f\", \"subtitle\", \"role\", \"twist\", \"plot\", \"character\", \"performance\", \"dialog\", \"line\", \"voice\", \"sense\", \"direction\", \"name\", \"job\", \"guess\", \"fact\", \"song\", \"lot\", \"bit\", \"director\", \"part\", \"rest\", \"person\", \"city\", \"parent\", \"york\", \"party\", \"costume\", \"match\", \"folk\", \"information\", \"phone\", \"design\", \"machine\", \"editing\", \"bomb\", \"mile\", \"desire\", \"field\", \"spot\", \"v\", \"presence\", \"mention\", \"cgi\", \"theory\", \"display\", \"moore\", \"extra\", \"surface\", \"belief\", \"robot\", \"planet\", \"image\", \"business\", \"effect\", \"set\", \"screen\", \"club\", \"event\", \"america\", \"writing\", \"hair\", \"air\", \"monster\", \"heart\", \"century\", \"ability\", \"place\", \"career\", \"world\", \"nothing\", \"opinion\", \"language\", \"break\", \"demon\", \"research\", \"expectation\", \"you.s\", \"anybody\", \"cousin\", \"think\", \"storm\", \"porn\", \"health\", \"market\", \"tell\", \"twin\", \"jet\", \"columbo\", \"streep\", \"tactic\", \"snowman\", \"tongue\", \"hate\", \"batman\", \"trek\", \"transformation\", \"freak\", \"jazz\", \"population\", \"series\", \"movie\", \"seagal\", \"fun\", \"book\", \"people\", \"beginning\", \"thing\", \"tv\", \"wait\", \"lot\", \"alien\", \"part\", \"everyone\", \"appearance\", \"idea\", \"rating\", \"television\", \"message\", \"problem\", \"star\", \"way\", \"rate\", \"end\", \"action\", \"kind\", \"kid\", \"year\", \"fact\", \"life\", \"thriller\", \"comedy\", \"sense\", \"plot\", \"bit\", \"show\", \"time\", \"hour\", \"waste\", \"second\", \"top\", \"opportunity\", \"setting\", \"bed\", \"doo\", \"hunter\", \"sight\", \"edge\", \"everybody\", \"food\", \"clue\", \"pain\", \"funny\", \"reaction\", \"sign\", \"magic\", \"wayne\", \"jerry\", \"running\", \"max\", \"seat\", \"shakespeare\", \"scooby\", \"boring\", \"crowd\", \"ball\", \"trouble\", \"minute\", \"episode\", \"van\", \"number\", \"attention\", \"hero\", \"couple\", \"kind\", \"sorry\", \"truth\", \"james\", \"turn\", \"way\", \"life\", \"thing\", \"course\", \"villain\", \"period\", \"credit\", \"tv\", \"year\", \"money\", \"day\", \"half\", \"someone\", \"scene\", \"everything\", \"camera\", \"shot\", \"sequence\", \"sound\", \"violence\", \"fight\", \"score\", \"zombie\", \"opening\", \"motion\", \"cat\", \"flashback\", \"pleasure\", \"opera\", \"viewing\", \"angle\", \"beast\", \"background\", \"rape\", \"lynch\", \"catherine\", \"montage\", \"section\", \"hoffman\", \"degree\", \"reno\", \"skin\", \"button\", \"cinematography\", \"music\", \"storyline\", \"sex\", \"use\", \"detail\", \"success\", \"picture\", \"drug\", \"work\", \"half\", \"action\", \"anything\", \"viewer\", \"moment\", \"face\", \"watch\", \"story\", \"effect\", \"minute\", \"something\", \"fan\", \"horror\", \"reason\", \"dvd\", \"quality\", \"flick\", \"video\", \"budget\", \"comment\", \"anyone\", \"crap\", \"sequel\", \"rock\", \"release\", \"slasher\", \"soundtrack\", \"imdb\", \"copy\", \"shame\", \"taste\", \"fantasy\", \"disney\", \"classic\", \"cost\", \"cheesy\", \"rent\", \"cover\", \"keaton\", \"scream\", \"store\", \"one\", \"genre\", \"someone\", \"review\", \"entertainment\", \"humor\", \"film\", \"movie\", \"gore\", \"bit\", \"version\", \"piece\", \"thing\", \"year\", \"lot\", \"comedy\", \"..\", \"car\", \"killer\", \"country\", \"jack\", \"mark\", \"door\", \"bill\", \"decade\", \"chase\", \"jeff\", \"mission\", \"bos\", \"jim\", \"president\", \"leader\", \"dollar\", \"ford\", \"prison\", \"evil\", \"connection\", \"intention\", \"cable\", \"charlie\", \"scale\", \"torture\", \"pointless\", \"behavior\", \"west\", \"treatment\", \"mind\", \"end\", \"town\", \"richard\", \"brother\", \"god\", \"lee\", \"none\", \"john\", \"hell\", \"conclusion\", \"guy\", \"space\", \"try\", \"george\", \"joke\", \"dream\", \"level\", \"question\", \"element\", \"student\", \"subject\", \"maker\", \"well\", \"flaw\", \"depth\", \"science\", \"aspect\", \"nature\", \"hitchcock\", \"gay\", \"imagination\", \"fiction\", \"festival\", \"tragedy\", \"puppet\", \"existence\", \"answer\", \"humanity\", \"task\", \"path\", \"criminal\", \"smile\", \"stand\", \"knife\", \"topic\", \"comparison\", \"whole\", \"film\", \"view\", \"audience\", \"way\", \"director\", \"situation\", \"mystery\", \"right\", \"reality\", \"issue\", \"history\", \"point\", \"filmmaker\", \"story\", \"character\", \"writer\", \"viewer\", \"life\", \"people\", \"end\", \"interest\", \"year\", \"part\", \"attempt\", \"work\", \"fact\", \"idea\", \"men\", \"laugh\", \"theater\", \"cop\", \"documentary\", \"spoiler\", \"hope\", \"value\", \"doctor\", \"war\", \"force\", \"hit\", \"office\", \"government\", \"month\", \"process\", \"suit\", \"officer\", \"jackson\", \"american\", \"arm\", \"network\", \"hotel\", \"program\", \"finger\", \"loss\", \"wish\", \"walker\", \"see\", \"let\", \"police\", \"gun\", \"eye\", \"man\", \"stuff\", \"case\", \"look\", \"street\", \"head\", \"water\", \"michael\", \"day\", \"world\", \"money\", \"woman\", \"production\", \"home\", \"people\", \"comedy\", \"guy\", \"girl\", \"love\", \"family\", \"child\", \"wife\", \"father\", \"boy\", \"mother\", \"son\", \"daughter\", \"mr\", \"house\", \"husband\", \"sister\", \"friend\", \"dog\", \"girlfriend\", \"ghost\", \"horse\", \"past\", \"affair\", \"tracy\", \"yeah\", \"marriage\", \"spirit\", \"jr\", \"childhood\", \"meet\", \"oh\", \"mom\", \"boyfriend\", \"friendship\", \"dad\", \"school\", \"woman\", \"story\", \"kid\", \"game\", \"relationship\", \"guy\", \"memory\", \"life\", \"lady\", \"year\", \"man\", \"adult\", \"home\", \"thing\", \"one\"], \"Freq\": [15040.0, 13409.0, 4852.0, 3061.0, 4246.0, 3581.0, 1949.0, 1733.0, 1993.0, 2639.0, 1209.0, 1392.0, 1680.0, 2509.0, 2463.0, 1194.0, 1140.0, 1120.0, 1066.0, 1365.0, 987.0, 975.0, 956.0, 1172.0, 1274.0, 1116.0, 859.0, 940.0, 935.0, 916.0, 1948.4589851984315, 939.8041716279066, 935.0333598126504, 574.5000359260135, 425.08298978369146, 882.8484527776287, 352.1511807646852, 315.5840851509385, 438.1533607613809, 356.0725238424938, 250.57612978622376, 203.2877561971389, 195.98884077497232, 173.4985652224899, 167.74608165766716, 138.76676290141398, 132.80720778424887, 130.128476443482, 128.33076228623656, 123.70852862891849, 119.29411767742072, 98.86312938473323, 92.58799322995415, 91.7156143114291, 88.10146617919138, 86.54068729041875, 86.1134741152177, 83.48781713304984, 77.22880931651872, 74.59352683906916, 1124.8071781726073, 254.43611435564796, 1799.1257248611926, 3338.2572288604792, 1125.3590828251479, 272.6029329120482, 670.4436678187695, 306.3391886057435, 445.26309281474425, 314.3009647799074, 352.8729748724096, 350.53993509295844, 194.38553586858384, 339.91274445611526, 226.29459999640628, 300.93382379384457, 258.8301261248375, 259.881333224934, 222.05912453411972, 204.5223949765504, 593.0451426998058, 373.31274986216494, 242.58894829360926, 198.48283607312166, 193.29175460328895, 191.6989330721085, 167.90516187242667, 140.32266175754873, 132.06373360969516, 124.23268328957921, 123.69162251291955, 123.66646098260794, 121.82116004453484, 118.58328264116328, 116.25205514113247, 115.73256034432369, 115.76660456854331, 112.15697214543995, 110.16010154660157, 106.79040437980188, 96.31340238918605, 93.10325685871614, 88.18653566090154, 87.35229472488358, 86.25843454144506, 84.82819633272621, 83.61503856770847, 83.53657355103537, 82.74543528306575, 82.26409286487262, 236.79794446951365, 195.89373217905043, 665.0595514506437, 294.0964608614415, 419.9497488154964, 171.8206211262644, 239.4345740713038, 158.39952237053097, 143.9226938412346, 141.29064838320903, 147.7174714828677, 177.63463354414318, 187.98563016454025, 144.88533474014068, 129.8907322986756, 185.45374751547917, 138.82377855897516, 149.6205794990199, 1118.1965984917883, 262.3969062558519, 166.1183883304567, 116.40426975696938, 109.83023565189848, 106.62548873528304, 103.35024394549573, 97.90016125471429, 88.48821457035329, 88.39907445401107, 80.12794597537938, 69.83509817174765, 66.53330642057583, 65.63843351396088, 53.64475384124649, 52.68460198485857, 50.71056541286292, 49.72471474082162, 49.514911758463356, 47.90693488402528, 47.00173156240511, 46.26558912937195, 45.689785819657295, 45.11994497443251, 110.792383477907, 41.47380605642016, 40.78871068779153, 40.10947600616504, 40.06000083851554, 39.74766269156801, 1074.0151267688561, 12506.783911032426, 136.44124900201817, 407.2799872006547, 606.5241206367812, 1738.7380123184168, 258.69005706640496, 1571.685600674396, 571.0046368712163, 80.37071920945927, 780.8684595499244, 112.6081956366071, 736.3654162001849, 404.8538832996596, 126.40630535230977, 419.20125219084485, 184.16953046923732, 166.26077503579953, 167.95507618275246, 304.1714987143615, 352.4396758281915, 526.2672791274888, 127.36578434641766, 376.4538478873339, 301.27751239363374, 263.8032675813896, 261.22576401308214, 336.01989111450393, 227.655816716493, 283.0703566747634, 148.7724963300289, 196.7950278229029, 176.2145454847335, 193.29625705282757, 180.83317395236935, 1732.8133476678506, 4848.846397167948, 724.7023294822193, 229.1522200371002, 152.39195776192307, 152.78690344034123, 136.93710224547695, 135.1010666141278, 131.02392102858312, 130.52609904811555, 113.84054177936129, 112.83018716818518, 130.21002103310215, 107.29168540906791, 105.77765849811163, 101.46918860741177, 95.72822114115299, 93.80050073462263, 91.69995028427772, 88.5383126827636, 86.97926957434865, 84.05528891370363, 82.4378944525114, 81.90809668099183, 81.78203346453712, 81.75483617857252, 76.54422025451633, 75.95382925213175, 70.48358419558971, 68.95322998126946, 86.3318669869683, 158.523789080759, 870.7060065083554, 616.7843562260076, 140.37954624220998, 264.6619612253041, 198.85103153056897, 232.9096791664066, 288.5034861686495, 391.6799676553927, 108.06513334933256, 160.71673884910194, 138.97101264636964, 133.72689359599056, 378.53713153592474, 287.94278442030316, 297.88688030249443, 194.98842742576977, 145.50826662767517, 135.2261384024242, 145.63505331873188, 171.84906584492754, 194.65480738460383, 162.94293272199667, 174.43203094625267, 143.01690591546435, 145.7939855047596, 3060.867950720117, 715.8397849503831, 599.9645769736994, 528.8505929987713, 510.3550370197216, 319.7727753455372, 310.2310795820489, 310.174153754748, 283.60847503331814, 256.2081534140103, 219.4226557180002, 147.1452479527526, 137.55106875379164, 114.17748560556885, 113.21949170929832, 109.30319847378475, 103.95377734328123, 91.93197148108, 84.04453990777822, 205.17906571984068, 81.84912918101364, 80.83450795807892, 78.89188337342945, 77.8882715563299, 77.04717577704137, 75.65463518920937, 74.4804829348304, 70.8431341545786, 69.51837515984909, 68.65199901046294, 270.5299505789799, 845.4070415429475, 231.11692736688954, 478.08072676926633, 194.49823885020032, 185.5514548556143, 165.13480145547805, 329.31777217488997, 189.83225248623557, 568.2417203112182, 282.5061472997826, 599.4382325569285, 443.52148193933414, 336.5643141018103, 365.70984603175646, 230.54693162171947, 210.52342111895115, 475.6082635545107, 268.21267257757563, 245.28097572480445, 1391.40416664749, 1065.3146350425766, 955.4254863960318, 811.25278834501, 707.0824532757251, 490.7307629370042, 473.946430071022, 471.30573471130367, 611.8359708441012, 370.3374543359435, 793.2385554203062, 273.66047978457874, 267.55691741780373, 239.5605755029158, 236.55273911589296, 211.21572353429733, 206.24632701306243, 203.00227801943436, 194.14188580320317, 161.49105132259658, 141.2799622839218, 139.20989911139006, 133.58435764496866, 133.83392529155566, 116.22816686985418, 115.4808388703627, 106.45659427612674, 98.53558470059356, 89.76514981672172, 87.5669720547398, 176.25701450679858, 914.1180173203687, 344.0935750497907, 449.3206316545537, 350.4932078879256, 185.46709986489918, 251.62824505440543, 2551.9384248234032, 2532.819720499599, 191.57688676746778, 360.78232292091525, 244.22401050961193, 221.0715085549171, 284.31997601419005, 238.70975393740426, 216.10300734362508, 207.25269802270338, 1208.4270105132812, 426.38962534754535, 413.71577432032217, 329.656242428799, 238.10464814824408, 223.26989562858202, 194.38135239108854, 185.88275232562137, 139.7484274069848, 125.56997370025582, 123.58398405879885, 115.26479819962005, 113.97984460585786, 112.87802019835867, 112.63995368780832, 111.08498046093958, 108.88750896331706, 108.71010614310359, 107.24069914092948, 103.11440145093914, 102.96786374373247, 93.2083822957837, 92.85948912830285, 88.69339319426848, 86.07151207688736, 91.10490193890614, 85.91127403890727, 83.58388561153674, 95.76302871778614, 75.7128308434766, 312.3853220006986, 652.2406518411087, 205.03369599143272, 116.16205533795846, 220.82760050847074, 175.99112782312287, 120.53407855309037, 169.67305636972924, 224.9080514802773, 155.54470836593336, 123.04680797561049, 227.5596166476675, 134.48403593852925, 121.40607525919295, 116.30300983826689, 117.88364434299494, 116.70277461013995, 324.1798482186194, 315.7033729607082, 297.9872378472566, 245.34426863401978, 202.7907324327214, 173.47387372539396, 166.01713381968216, 162.65267409609027, 160.6492483377486, 155.61916918133247, 238.70002140009922, 149.9436976382042, 143.8577877533867, 129.4010537641937, 124.70362445098053, 122.93234125708437, 119.74882489334269, 106.59374337379691, 100.9763169274322, 97.93426342386327, 95.99813039010357, 94.19919256550567, 91.91872250246578, 88.3195734921116, 81.87675056063301, 78.91496293641794, 77.77538664866556, 75.72290496688622, 73.77707043400412, 72.65500601406333, 90.47145929322896, 10800.75565200817, 270.96832955194014, 558.433317668776, 1604.0242555812679, 901.9313406285064, 274.3749866992652, 205.30601155411765, 198.73608574622253, 226.60351905185112, 158.5378390316702, 261.54656644321716, 510.00726674074434, 180.3575632872323, 933.695271686272, 902.3126933841328, 231.83277206549369, 292.7460076742037, 523.4014123621212, 552.7778795007036, 383.99960699577076, 213.30271962865785, 372.61757372519213, 279.1569243277708, 209.28466001227363, 248.9548400721906, 230.310765077768, 209.80700284546447, 599.8488024089377, 323.79276964672533, 320.0651585642075, 292.355158876274, 285.4074575928465, 276.05172336554676, 259.1463349767137, 257.263230832996, 220.60074061997764, 855.7740933261914, 185.71792903070374, 180.44784350611945, 165.24889103090476, 144.0462506398455, 138.44701578259242, 136.1124554968895, 129.78334851663604, 127.49861030700728, 119.10252591424285, 113.35610727601316, 106.7525871140188, 100.36869288327219, 98.23518383686533, 95.98771424345884, 83.96223213249903, 83.66341890837312, 77.41901797403985, 74.41918393234893, 72.4685687464022, 68.54587655712295, 250.72359364410107, 243.75918280285185, 613.5276790848338, 1188.5912846526207, 270.9780645696075, 344.91375293258824, 417.1824712794767, 183.80988829916632, 292.1084842418448, 158.42343694063425, 216.71259173677646, 378.5288183755221, 385.4517874693907, 277.57382611428505, 308.4599022442988, 229.3464482378694, 215.14037734776124, 311.53013445365275, 201.01110910415503, 182.94482375982398, 1193.8629445988802, 986.5852416077219, 974.1145268871725, 915.5475583596406, 590.2829991894973, 569.5885038018148, 516.251051252041, 466.47594094194733, 430.13559782032604, 375.4786483587707, 360.4016375790888, 649.0101368590488, 309.62033873038644, 269.61268204571854, 887.0154066683277, 247.26782829317224, 202.16155517474564, 169.43893653813183, 149.47228644354243, 147.3575091677662, 129.02134275176462, 108.73613354810865, 108.10883333820685, 106.70924100678783, 103.31332756741368, 95.99162115712542, 95.23418080717585, 88.65823619892441, 86.85246581536649, 86.82748142535898, 98.76451959461035, 86.87557881706469, 102.02490112588042, 403.3282911729008, 963.5527367283776, 2169.783551055505, 684.2111570807186, 396.5713317841586, 284.67439626008985, 692.0548452214503, 148.74291149391826, 902.1777961494248, 208.65645510842, 626.2887272327897, 487.06177647278435, 177.71806690470848, 240.28892767526224, 308.642226440731, 233.257367817623], \"Total\": [15040.0, 13409.0, 4852.0, 3061.0, 4246.0, 3581.0, 1949.0, 1733.0, 1993.0, 2639.0, 1209.0, 1392.0, 1680.0, 2509.0, 2463.0, 1194.0, 1140.0, 1120.0, 1066.0, 1365.0, 987.0, 975.0, 956.0, 1172.0, 1274.0, 1116.0, 859.0, 940.0, 935.0, 916.0, 1949.3761692325784, 940.7213248849779, 935.9585309550529, 575.4177113341462, 426.0001725393446, 885.1261894522319, 353.0683613568088, 316.5012608087984, 439.4462564486352, 357.23727314540133, 251.49334130254633, 204.20492747756444, 196.906039470836, 174.4156936452489, 168.66325905625837, 139.68391735153202, 133.72438690258252, 131.0456704613495, 129.2478930626581, 124.62568525995333, 120.21129951583407, 99.78029848392929, 93.50519540421371, 92.65838621429072, 89.01875858693211, 87.45785233038166, 87.03173032408682, 84.40510808138032, 78.14598822244655, 75.51067077253332, 1140.943722216886, 263.98023792789496, 1993.630447010519, 4246.475626867151, 1365.5710132454342, 300.3029839551935, 894.0805132214675, 388.73459698456963, 623.8256215555954, 425.0918875389899, 554.3224807761309, 709.5998571374334, 283.2270415533356, 1024.7369773508453, 557.268978767219, 1476.954118970437, 943.9441347724377, 1446.9291364152941, 1432.2160243109745, 491.10816884249186, 593.954767047747, 374.2223804608794, 243.5033977298161, 199.39245807076094, 194.20138179584862, 192.60853588998484, 168.81475179750674, 141.23226986372197, 132.97335539016433, 125.14228084035997, 124.60123308861601, 124.57635255869614, 122.73078903285706, 119.49290220286964, 117.16183942217596, 116.64216696648982, 116.67651158914035, 113.06658548800581, 111.06971043935641, 107.70002692177322, 97.2230143179209, 94.0128423795506, 89.09617533519366, 88.26191755435629, 87.16804959412976, 85.73786480775476, 84.52463605551897, 84.44622010345351, 83.65501923324095, 83.17368472485158, 241.59334528455244, 199.7118641939021, 934.0808279011269, 391.627031321203, 623.5779443327342, 220.2517297327336, 363.7923521545354, 212.22730120173136, 184.6652962026081, 183.01793638519348, 205.35632473690092, 315.7701651612244, 405.20339708644735, 212.04664470661083, 165.05543267945063, 766.966143925872, 286.4278278061024, 1267.9217865520227, 1120.2505678916339, 263.3251021787824, 167.03876662267712, 117.32474679204392, 110.75068735966454, 107.54595928614054, 104.27058253929052, 98.82054316811816, 89.40858330074049, 89.31952388579433, 81.04835135852794, 70.75568056651313, 67.45369702175078, 66.55886772318725, 54.56518516900039, 53.60502607358963, 51.630951460737386, 50.64525219167467, 50.435377672340636, 48.82736748924314, 47.9225064405058, 47.186154080180124, 46.61026699762219, 46.040321733364124, 113.2324202070113, 42.39416560674607, 41.70911486429659, 41.02988395148748, 40.980413368355975, 40.66810632668584, 1172.811955998052, 15040.424289962182, 146.45816700295276, 513.9175352078188, 802.8859039133393, 2639.857159715277, 322.99994019709067, 2463.4362980526507, 829.8381298370905, 90.797519666781, 1476.954118970437, 138.73210959473604, 1432.2160243109745, 682.9292555073463, 162.48671833059134, 773.6728269760398, 274.31246338159457, 248.02693609686574, 263.30950980527575, 672.1537807134071, 929.8966795327035, 2509.58587782289, 176.44731475857097, 1483.616441087916, 1173.7463304346056, 929.4181102737675, 946.2548652604099, 2005.634911031084, 1024.7369773508453, 2172.5390035731334, 304.18544847560213, 996.9351690711408, 623.8256215555954, 1993.630447010519, 943.9441347724377, 1733.7281013050372, 4852.460468475837, 725.6170596651884, 230.06692523687735, 153.30671035151926, 153.74723209698286, 137.85184015234012, 136.01581167487927, 131.93865370575617, 131.44086153288274, 114.75963176891393, 113.74496446725261, 131.31716046555704, 108.20639188475164, 106.69244908037955, 102.38394444530438, 96.64297713555844, 94.71522940148643, 92.61471215408886, 89.45306353514522, 87.89399856613106, 84.9700336819623, 83.35266511184408, 82.82284284766683, 82.6968091178698, 82.66955462543487, 77.45891619886577, 76.86853438999076, 71.39833371701214, 69.8680383290868, 87.97026527185339, 170.24516318471902, 1116.803056218094, 820.7730868506563, 158.85236914799168, 424.65546789900424, 292.8173111780989, 375.94019103465325, 553.7644701321638, 929.4181102737675, 127.3773117658157, 254.98787575143956, 207.8983707504393, 205.6505674213781, 2509.58587782289, 2172.5390035731334, 2463.4362980526507, 759.9288289823737, 298.9304698975065, 247.0848059924974, 342.64149610125094, 829.8381298370905, 2005.634911031084, 704.7399735341463, 1178.6377018418307, 426.34201269850087, 644.3027885655208, 3061.7829024298076, 716.7547544297871, 600.8795277767146, 529.7655378984842, 511.78772356031385, 320.68773145111476, 311.1460234899305, 311.08912281400575, 284.5234124574525, 257.12310503410134, 220.3376088318645, 148.06018675712613, 138.46602618078364, 115.09251317302098, 114.13449807101378, 110.21815525999162, 104.8687225877952, 92.84692132411361, 84.95960433107345, 207.41508219155796, 82.76412321139318, 81.74948587005987, 79.80689754428796, 78.8032192840603, 77.96216523698418, 76.56971249441416, 75.39547267065342, 71.75897976229396, 70.43332440560602, 69.56697989130873, 278.45925870028395, 1027.2445175983057, 264.34714442871734, 620.3262969694408, 227.581760728566, 228.18273885739617, 202.60154686649136, 503.6419437793379, 246.94823219214817, 1037.6921924494313, 426.34201269850087, 1173.7463304346056, 804.1410867406694, 630.1804612214862, 750.6139205456493, 385.56445965947125, 339.26657083858953, 3581.4607465914737, 934.0808279011269, 1116.803056218094, 1392.3202524820415, 1066.2306443820812, 956.3414792646876, 812.1688484597965, 707.9984505170778, 491.6467979540534, 474.8624474760371, 472.22173165694124, 613.0926172894059, 371.2535194516111, 795.8804936914702, 274.5768752602758, 268.53511141158265, 240.48058040692808, 237.46875433003825, 212.1317329888202, 207.16232298715758, 203.92817881726123, 195.0605383381261, 162.40704963772728, 142.19599167262038, 140.12592825424755, 134.50034392435126, 134.7663644446079, 117.14417647616081, 116.39683204354453, 107.37258193170723, 99.4515996564662, 90.68119492489228, 88.48302659519217, 178.77062824831793, 1157.6557924861918, 422.11466216873754, 644.3027885655208, 493.98894888941356, 231.85551667316213, 366.11043258133265, 13409.343522413465, 15040.424289962182, 256.3066835404877, 943.9441347724377, 688.62170326565, 544.0525697645614, 2463.4362980526507, 2005.634911031084, 1476.954118970437, 996.9351690711408, 1209.3352244705713, 427.2980544804197, 414.6529736420091, 330.56452691797847, 239.0323447450569, 224.18302261072833, 195.2896219135044, 186.79254932034422, 140.65671907723228, 126.47819743961625, 124.49228799166715, 116.1730442187529, 114.88808514817211, 113.78624564470253, 113.54820134439409, 111.99488719786152, 109.79585483138924, 109.61836170405319, 108.14894349821947, 104.02265550994402, 103.87610282912465, 94.11660675872807, 93.76776188280458, 89.60159751878186, 86.97979195999308, 92.06787046882633, 86.81950590554453, 84.49656366998157, 96.86209455910837, 76.62111591582443, 500.01828131579185, 1483.616441087916, 331.5569892164243, 139.68778293228723, 431.34258972882765, 296.494608135421, 154.50297093836306, 304.23198567985486, 587.8014419902648, 283.01669920683804, 167.8468340661381, 1327.688786554098, 240.4204582585793, 295.341679169974, 219.97909858772857, 426.5123332438003, 318.96005200498655, 325.0976380131285, 316.6211829349502, 298.9050409477992, 246.2621226037941, 203.71959754320835, 174.3917148600294, 166.93498284393218, 163.57052936437466, 161.56704947793594, 156.5369403910703, 240.14373324219983, 150.8614846041955, 144.77558113246766, 130.3189187701236, 125.62145694704203, 123.8501220431715, 120.6665861824481, 107.5115449186782, 101.89420749382985, 98.85216239435651, 96.91593312940398, 95.11701949895229, 92.83658190111281, 89.23746360015308, 82.79462333225568, 79.83285106792283, 78.69409975148973, 76.64084958185366, 74.69491010085994, 73.57279744168555, 91.81324265001533, 13409.343522413465, 304.31789936650847, 707.8286675908415, 2509.58587782289, 1446.9291364152941, 362.15127826831747, 255.3758701514212, 245.66569774103627, 291.68765918740525, 185.50237902124252, 359.2911765350747, 1011.8161724246457, 231.2485663339073, 3581.4607465914737, 4246.475626867151, 391.94057285684937, 630.1804612214862, 2172.5390035731334, 2639.857159715277, 1483.616441087916, 356.52263594820704, 2005.634911031084, 1432.2160243109745, 468.1399911587469, 1037.6921924494313, 1024.7369773508453, 773.6728269760398, 600.764963195875, 324.70549080013933, 320.9778803069288, 293.26787666766154, 286.3203371618086, 276.96442930788095, 260.0590560091702, 258.17595892776035, 221.5134716523135, 859.4137998345217, 186.6306470605016, 181.3605895918149, 166.16160611700872, 144.95897150583974, 139.35974699187213, 137.02807654580437, 130.69610807722987, 128.41129944001386, 120.01522040339798, 114.2697030754668, 107.66531226675852, 101.28143747361848, 99.14873609101434, 96.9004466791916, 84.87497217409104, 84.57611468605586, 78.33173763865713, 75.33187630561386, 73.38130965834254, 69.45861495163736, 256.7850284969485, 254.58593149386712, 670.0109962889293, 1680.7605302260945, 329.86711999570906, 506.1904994118363, 647.0438031473699, 231.88898171475194, 467.1223278774786, 199.96146539887292, 336.22967225903926, 1178.6377018418307, 1267.9217865520227, 704.7399735341463, 1274.8615957618285, 577.0476270253533, 517.7025991992693, 2639.857159715277, 996.9351690711408, 1327.688786554098, 1194.9517968782575, 987.4989389077357, 975.0283500418482, 916.4612626076811, 591.1966502021968, 570.5021653122343, 517.1647308447067, 467.3895919983956, 431.0492575564114, 376.3923262435966, 361.3152940387116, 650.68677921669, 310.5339998808809, 270.52635172823875, 890.264329023748, 248.18731559364474, 203.2012113700635, 170.35261365417287, 150.38595779422735, 148.27142267943287, 129.9352629587045, 109.6500644314776, 109.02251770763104, 107.62288445007746, 104.22943642716781, 96.90528470296343, 96.14784638184727, 89.58161069545183, 87.76616825850878, 87.74114118188575, 99.85132261391583, 87.79024256150765, 104.24799801170127, 481.5283514995489, 1274.8615957618285, 3581.4607465914737, 946.2548652604099, 568.2308495846405, 399.2559697237549, 1327.688786554098, 170.4615867956441, 2172.5390035731334, 279.9835728757268, 2005.634911031084, 1680.7605302260945, 231.0281857600564, 517.7025991992693, 2463.4362980526507, 1157.6557924861918], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.1635, -3.8926, -3.8977, -4.3848, -4.686, -3.9552, -4.8743, -4.9839, -4.6557, -4.8632, -5.2146, -5.4237, -5.4603, -5.5821, -5.6159, -5.8055, -5.8494, -5.8698, -5.8837, -5.9204, -5.9567, -6.1446, -6.2102, -6.2196, -6.2598, -6.2777, -6.2826, -6.3136, -6.3915, -6.4263, -3.7129, -5.1993, -3.2433, -2.6251, -3.7125, -5.1303, -4.2304, -5.0136, -4.6396, -4.988, -4.8722, -4.8788, -5.4685, -4.9096, -5.3165, -5.0314, -5.1821, -5.1781, -5.3354, -5.4176, -3.9709, -4.4338, -4.8648, -5.0655, -5.092, -5.1003, -5.2328, -5.4123, -5.4729, -5.5341, -5.5384, -5.5386, -5.5537, -5.5806, -5.6004, -5.6049, -5.6046, -5.6363, -5.6543, -5.6853, -5.7886, -5.8225, -5.8768, -5.8863, -5.8989, -5.9156, -5.93, -5.9309, -5.9404, -5.9463, -4.889, -5.0786, -3.8563, -4.6723, -4.3161, -5.2098, -4.8779, -5.2911, -5.3869, -5.4054, -5.3609, -5.1765, -5.1198, -5.3803, -5.4895, -5.1334, -5.423, -5.3481, -3.7713, -5.2209, -5.6781, -6.0337, -6.0918, -6.1214, -6.1526, -6.2068, -6.3079, -6.3089, -6.4071, -6.5446, -6.5931, -6.6066, -6.8084, -6.8264, -6.8646, -6.8843, -6.8885, -6.9215, -6.9406, -6.9564, -6.9689, -6.9814, -6.0831, -7.0657, -7.0824, -7.0992, -7.1004, -7.1082, -3.8116, -1.3567, -5.8749, -4.7813, -4.383, -3.3298, -5.2351, -3.4309, -4.4434, -6.4041, -4.1304, -6.0668, -4.189, -4.7872, -5.9513, -4.7524, -5.5749, -5.6772, -5.6671, -5.0732, -4.9259, -4.525, -5.9437, -4.86, -5.0827, -5.2156, -5.2254, -4.9736, -5.3629, -5.1451, -5.7883, -5.5086, -5.6191, -5.5265, -5.5932, -3.0973, -2.0683, -3.9691, -5.1204, -5.5284, -5.5258, -5.6353, -5.6488, -5.6794, -5.6832, -5.82, -5.8289, -5.6857, -5.8793, -5.8935, -5.9351, -5.9933, -6.0136, -6.0363, -6.0714, -6.0891, -6.1233, -6.1428, -6.1492, -6.1508, -6.1511, -6.2169, -6.2247, -6.2994, -6.3214, -6.0966, -5.4889, -3.7855, -4.1303, -5.6105, -4.9764, -5.2623, -5.1042, -4.8901, -4.5844, -5.8721, -5.4752, -5.6206, -5.659, -4.6185, -4.8921, -4.8581, -5.2819, -5.5746, -5.6479, -5.5737, -5.4082, -5.2836, -5.4614, -5.3933, -5.5919, -5.5726, -2.5112, -3.9642, -4.1407, -4.2669, -4.3025, -4.77, -4.8003, -4.8005, -4.89, -4.9916, -5.1466, -5.5462, -5.6136, -5.7999, -5.8083, -5.8435, -5.8937, -6.0166, -6.1063, -5.2137, -6.1327, -6.1452, -6.1695, -6.1823, -6.1932, -6.2114, -6.2271, -6.2771, -6.296, -6.3086, -4.9372, -3.7978, -5.0947, -4.3678, -5.2672, -5.3143, -5.4308, -4.7406, -5.2915, -4.1951, -4.8939, -4.1416, -4.4429, -4.7188, -4.6358, -5.0972, -5.188, -4.373, -4.9458, -5.0352, -3.4935, -3.7605, -3.8694, -4.033, -4.1704, -4.5357, -4.5705, -4.576, -4.3151, -4.8171, -4.0554, -5.1197, -5.1422, -5.2527, -5.2654, -5.3787, -5.4025, -5.4183, -5.463, -5.6471, -5.7808, -5.7956, -5.8368, -5.835, -5.976, -5.9824, -6.0638, -6.1411, -6.2344, -6.2591, -5.5596, -3.9136, -4.8906, -4.6238, -4.8722, -5.5087, -5.2036, -2.8869, -2.8945, -5.4763, -4.8433, -5.2335, -5.3331, -5.0815, -5.2563, -5.3558, -5.3976, -3.2363, -4.2781, -4.3082, -4.5354, -4.8607, -4.925, -5.0636, -5.1083, -5.3936, -5.5006, -5.5165, -5.5862, -5.5974, -5.6071, -5.6092, -5.6231, -5.6431, -5.6447, -5.6583, -5.6976, -5.699, -5.7986, -5.8023, -5.8482, -5.8782, -5.8214, -5.8801, -5.9076, -5.7715, -6.0065, -4.5892, -3.853, -5.0102, -5.5784, -4.936, -5.163, -5.5415, -5.1996, -4.9177, -5.2865, -5.5209, -4.906, -5.432, -5.5343, -5.5772, -5.5637, -5.5738, -5.1182, -5.1447, -5.2024, -5.3968, -5.5873, -5.7435, -5.7874, -5.8079, -5.8203, -5.8521, -5.4243, -5.8892, -5.9307, -6.0366, -6.0736, -6.0879, -6.1141, -6.2305, -6.2846, -6.3152, -6.3352, -6.3541, -6.3786, -6.4185, -6.4943, -6.5311, -6.5457, -6.5724, -6.5984, -6.6138, -6.3945, -1.6121, -5.2975, -4.5744, -3.5192, -4.095, -5.285, -5.575, -5.6075, -5.4763, -5.8335, -5.3329, -4.6651, -5.7046, -4.0603, -4.0945, -5.4535, -5.2202, -4.6391, -4.5845, -4.9489, -5.5368, -4.9789, -5.2677, -5.5558, -5.3822, -5.4601, -5.5533, -4.1105, -4.7271, -4.7387, -4.8292, -4.8533, -4.8866, -4.9498, -4.9571, -5.1109, -3.7552, -5.283, -5.3118, -5.3998, -5.5371, -5.5767, -5.5937, -5.6413, -5.6591, -5.7272, -5.7767, -5.8367, -5.8984, -5.9199, -5.943, -6.0768, -6.0804, -6.158, -6.1975, -6.2241, -6.2797, -4.9829, -5.011, -4.088, -3.4267, -4.9052, -4.6639, -4.4737, -5.2933, -4.8301, -5.4419, -5.1286, -4.5709, -4.5528, -4.8811, -4.7756, -5.072, -5.1359, -4.7657, -5.2039, -5.298, -3.6643, -3.855, -3.8677, -3.9297, -4.3686, -4.4043, -4.5026, -4.604, -4.6851, -4.821, -4.862, -4.2738, -5.0139, -5.1523, -3.9614, -5.2388, -5.4402, -5.6167, -5.7421, -5.7564, -5.8893, -6.0603, -6.0661, -6.0791, -6.1115, -6.185, -6.1929, -6.2644, -6.285, -6.2853, -6.1565, -6.2848, -6.124, -4.7495, -3.8786, -3.0669, -4.221, -4.7664, -5.0979, -4.2096, -5.747, -3.9444, -5.4085, -4.3094, -4.5608, -5.569, -5.2674, -5.0171, -5.2971], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 2.1997, 2.1992, 2.1992, 2.1986, 2.198, 2.1976, 2.1976, 2.1973, 2.1972, 2.1969, 2.1965, 2.1957, 2.1955, 2.1949, 2.1947, 2.1936, 2.1933, 2.1932, 2.1931, 2.1928, 2.1925, 2.1909, 2.1903, 2.19, 2.1898, 2.1896, 2.1896, 2.1893, 2.1884, 2.188, 2.1859, 2.1634, 2.0975, 1.9595, 2.0067, 2.1034, 1.9123, 1.962, 1.863, 1.8982, 1.7485, 1.495, 1.8238, 1.0967, 1.299, 0.6093, 0.9063, 0.4832, 0.3361, 1.3242, 2.5808, 2.5799, 2.5785, 2.5777, 2.5776, 2.5776, 2.5769, 2.5758, 2.5754, 2.575, 2.575, 2.575, 2.5748, 2.5746, 2.5745, 2.5745, 2.5745, 2.5742, 2.5741, 2.5738, 2.5729, 2.5726, 2.572, 2.5719, 2.5718, 2.5716, 2.5715, 2.5715, 2.5714, 2.5713, 2.5622, 2.563, 2.2426, 2.2959, 2.1869, 2.334, 2.164, 2.2897, 2.333, 2.3235, 2.2528, 2.007, 1.8143, 2.2014, 2.3427, 1.1626, 1.858, 0.4453, 2.1459, 2.1442, 2.1422, 2.1399, 2.1394, 2.1391, 2.1389, 2.1384, 2.1374, 2.1374, 2.1363, 2.1346, 2.134, 2.1338, 2.1307, 2.1304, 2.1297, 2.1294, 2.1293, 2.1287, 2.1283, 2.128, 2.1278, 2.1275, 2.1259, 2.1258, 2.1254, 2.125, 2.125, 2.1248, 2.0597, 1.9633, 2.0769, 1.9152, 1.8673, 1.7302, 1.9257, 1.6983, 1.7739, 2.0257, 1.5104, 1.9391, 1.4825, 1.6249, 1.8966, 1.5349, 1.7493, 1.7477, 1.6981, 1.3548, 1.1775, 0.5857, 1.8218, 0.7763, 0.7878, 0.8884, 0.8606, 0.3612, 0.6434, 0.1098, 1.4325, 0.5252, 0.8836, -0.1858, 0.4952, 2.3832, 2.3829, 2.3824, 2.3797, 2.3777, 2.3774, 2.377, 2.3769, 2.3767, 2.3767, 2.3756, 2.3756, 2.3752, 2.3752, 2.3751, 2.3747, 2.3742, 2.374, 2.3738, 2.3734, 2.3732, 2.3729, 2.3726, 2.3726, 2.3726, 2.3726, 2.3718, 2.3717, 2.3708, 2.3705, 2.3649, 2.3123, 2.1348, 2.098, 2.2601, 1.9109, 1.9967, 1.9049, 1.7316, 1.5196, 2.2193, 1.9221, 1.9809, 1.9533, 0.4921, 0.3628, 0.2711, 1.0234, 1.6637, 1.7809, 1.5281, 0.8091, 0.0512, 0.9192, 0.4731, 1.2914, 0.8977, 2.4006, 2.3996, 2.3994, 2.3992, 2.3981, 2.398, 2.3979, 2.3979, 2.3977, 2.3973, 2.3967, 2.3947, 2.3943, 2.3929, 2.3928, 2.3925, 2.3921, 2.391, 2.3901, 2.39, 2.3898, 2.3896, 2.3894, 2.3892, 2.3891, 2.3889, 2.3887, 2.388, 2.3878, 2.3876, 2.372, 2.2061, 2.2665, 2.1404, 2.2438, 2.1941, 2.1964, 1.976, 2.1378, 1.7987, 1.9893, 1.7289, 1.8059, 1.7737, 1.6818, 1.8866, 1.9237, 0.382, 1.1531, 0.8851, 2.2063, 2.2061, 2.206, 2.2058, 2.2056, 2.2051, 2.205, 2.205, 2.2049, 2.2045, 2.2036, 2.2036, 2.2033, 2.2031, 2.2031, 2.2026, 2.2025, 2.2024, 2.2022, 2.2013, 2.2005, 2.2004, 2.2001, 2.2, 2.1991, 2.199, 2.1984, 2.1977, 2.1968, 2.1965, 2.1928, 1.9707, 2.0026, 1.8465, 1.8638, 1.9837, 1.832, 0.5478, 0.4255, 1.9159, 1.2451, 1.1703, 1.3064, 0.0477, 0.0785, 0.285, 0.6362, 2.6043, 2.6029, 2.6028, 2.6023, 2.6012, 2.601, 2.6004, 2.6002, 2.5986, 2.5979, 2.5977, 2.5972, 2.5971, 2.5971, 2.597, 2.5969, 2.5968, 2.5967, 2.5966, 2.5963, 2.5963, 2.5954, 2.5953, 2.5949, 2.5946, 2.5946, 2.5946, 2.5942, 2.5937, 2.5931, 2.1347, 1.7832, 2.1244, 2.4206, 1.9355, 2.0835, 2.3568, 2.0212, 1.6444, 2.0065, 2.2946, 0.8413, 2.0241, 1.7161, 1.9677, 1.3191, 1.5996, 2.0362, 2.0361, 2.0359, 2.0353, 2.0344, 2.0337, 2.0335, 2.0334, 2.0333, 2.0331, 2.033, 2.0329, 2.0326, 2.0319, 2.0317, 2.0316, 2.0314, 2.0304, 2.03, 2.0297, 2.0295, 2.0293, 2.0291, 2.0287, 2.0279, 2.0274, 2.0273, 2.0269, 2.0266, 2.0264, 2.0243, 1.8227, 1.9229, 1.8019, 1.5914, 1.5663, 1.7614, 1.8208, 1.827, 1.7865, 1.8819, 1.7215, 1.3539, 1.7904, 0.6946, 0.4901, 1.5139, 1.2723, 0.6157, 0.4755, 0.6874, 1.5253, 0.3558, 0.4038, 1.2339, 0.6115, 0.5462, 0.734, 2.4298, 2.4285, 2.4284, 2.4282, 2.4281, 2.428, 2.4278, 2.4277, 2.4271, 2.427, 2.4264, 2.4262, 2.4258, 2.425, 2.4247, 2.4246, 2.4243, 2.4241, 2.4236, 2.4233, 2.4228, 2.4222, 2.422, 2.4218, 2.4205, 2.4204, 2.4196, 2.4191, 2.4188, 2.418, 2.4074, 2.3878, 2.3432, 2.0848, 2.2346, 2.0477, 1.9924, 2.1989, 1.9618, 2.1984, 1.9921, 1.2955, 1.2406, 1.4995, 1.0123, 1.5086, 1.5532, 0.2943, 0.83, 0.4493, 2.1883, 2.1883, 2.1883, 2.1883, 2.1877, 2.1877, 2.1875, 2.1873, 2.1871, 2.1868, 2.1867, 2.1867, 2.1863, 2.1859, 2.1856, 2.1855, 2.1841, 2.1839, 2.1832, 2.1831, 2.1822, 2.1809, 2.1808, 2.1807, 2.1804, 2.1798, 2.1797, 2.1789, 2.1788, 2.1788, 2.1783, 2.1788, 2.1677, 2.012, 1.9093, 1.6881, 1.865, 1.8296, 1.851, 1.5377, 2.053, 1.3104, 1.8952, 1.0254, 0.9506, 1.9269, 1.4217, 0.1121, 0.5872]}, \"token.table\": {\"Topic\": [7, 2, 5, 1, 1, 3, 5, 6, 8, 1, 1, 6, 10, 10, 2, 9, 2, 3, 2, 5, 9, 5, 8, 3, 4, 6, 3, 5, 6, 9, 2, 3, 4, 9, 3, 8, 1, 1, 2, 3, 5, 6, 7, 8, 9, 10, 2, 3, 4, 5, 10, 1, 4, 8, 2, 5, 4, 9, 3, 8, 5, 4, 3, 8, 7, 2, 7, 1, 2, 3, 4, 6, 10, 2, 1, 3, 8, 4, 7, 10, 10, 3, 2, 7, 10, 6, 2, 4, 5, 7, 5, 7, 2, 3, 5, 9, 1, 4, 8, 9, 1, 8, 1, 5, 5, 2, 4, 10, 2, 1, 5, 8, 7, 1, 7, 6, 1, 10, 10, 1, 5, 2, 6, 2, 5, 4, 3, 1, 3, 4, 5, 6, 8, 9, 10, 6, 8, 3, 7, 7, 9, 6, 6, 2, 7, 3, 4, 5, 6, 10, 1, 4, 5, 6, 8, 9, 10, 3, 6, 6, 1, 4, 6, 8, 8, 4, 2, 10, 10, 2, 3, 4, 5, 6, 8, 9, 7, 1, 5, 3, 8, 2, 2, 3, 5, 10, 1, 1, 5, 1, 1, 1, 5, 1, 6, 7, 8, 6, 2, 9, 9, 10, 7, 4, 7, 1, 4, 5, 6, 7, 9, 10, 5, 9, 6, 4, 2, 2, 5, 8, 1, 2, 3, 5, 6, 7, 8, 9, 10, 4, 6, 1, 3, 4, 2, 8, 4, 3, 8, 10, 5, 7, 8, 3, 2, 2, 9, 1, 2, 4, 5, 7, 9, 10, 1, 3, 4, 5, 6, 8, 10, 6, 6, 1, 10, 8, 8, 2, 5, 1, 5, 6, 8, 6, 8, 9, 5, 8, 6, 2, 4, 9, 7, 3, 7, 10, 10, 1, 3, 8, 4, 6, 10, 8, 6, 8, 1, 7, 10, 10, 10, 10, 2, 5, 6, 7, 10, 5, 6, 9, 1, 3, 6, 9, 10, 1, 2, 3, 4, 5, 6, 7, 9, 10, 2, 4, 7, 4, 5, 3, 1, 2, 4, 5, 6, 9, 3, 2, 3, 4, 6, 10, 3, 4, 7, 4, 9, 2, 3, 8, 9, 8, 5, 1, 2, 9, 10, 9, 6, 10, 9, 4, 2, 10, 8, 1, 6, 4, 10, 3, 4, 6, 8, 2, 8, 8, 6, 2, 7, 1, 7, 8, 9, 8, 9, 10, 7, 9, 4, 10, 3, 7, 4, 3, 7, 1, 3, 4, 5, 7, 10, 1, 4, 5, 7, 9, 10, 1, 3, 4, 6, 7, 8, 10, 6, 3, 10, 7, 1, 3, 4, 5, 6, 8, 10, 8, 4, 5, 10, 3, 9, 1, 7, 7, 8, 9, 8, 1, 2, 3, 4, 8, 9, 10, 1, 4, 6, 8, 10, 1, 5, 6, 9, 10, 9, 1, 3, 5, 6, 10, 5, 2, 4, 8, 1, 9, 10, 7, 3, 10, 2, 4, 10, 9, 10, 9, 2, 3, 8, 9, 1, 9, 10, 2, 4, 6, 7, 10, 4, 5, 7, 10, 1, 2, 3, 4, 5, 6, 7, 8, 10, 3, 4, 6, 9, 2, 4, 6, 7, 10, 5, 9, 2, 10, 5, 3, 6, 10, 1, 5, 6, 3, 8, 10, 1, 4, 6, 8, 9, 1, 7, 3, 8, 1, 3, 4, 6, 9, 9, 10, 4, 6, 10, 5, 5, 3, 4, 4, 2, 1, 3, 8, 10, 2, 10, 8, 3, 4, 6, 8, 9, 10, 1, 2, 8, 9, 10, 1, 2, 3, 4, 6, 8, 2, 2, 1, 2, 5, 8, 10, 1, 2, 4, 5, 6, 8, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 1, 5, 1, 3, 1, 3, 4, 6, 8, 9, 10, 7, 4, 9, 3, 3, 2, 7, 7, 3, 4, 8, 9, 10, 9, 1, 2, 8, 9, 9, 8, 6, 8, 5, 3, 8, 3, 6, 4, 3, 4, 7, 8, 6, 8, 10, 6, 5, 6, 3, 1, 3, 5, 6, 8, 9, 10, 3, 4, 6, 7, 10, 2, 8, 1, 2, 6, 1, 4, 7, 10, 4, 7, 5, 4, 8, 10, 8, 4, 5, 6, 1, 2, 1, 3, 9, 1, 4, 4, 5, 9, 1, 2, 3, 6, 5, 8, 3, 4, 8, 1, 2, 4, 5, 10, 4, 6, 5, 4, 4, 4, 10, 2, 8, 9, 1, 5, 6, 8, 3, 1, 4, 6, 8, 6, 10, 1, 2, 5, 6, 4, 6, 5, 6, 6, 7, 8, 10, 9, 2, 1, 8, 1, 3, 4, 6, 8, 9, 10, 6, 7, 3, 1, 3, 5, 8, 10, 3, 5, 3, 2, 9, 8, 3, 9, 1, 8, 1, 3, 5, 9, 2, 3, 1, 8, 6, 3, 4, 3, 9, 2, 3, 4, 6, 10, 3, 3, 4, 5, 7, 8, 3, 4, 3, 4, 8, 7, 7, 9, 10, 10, 8, 3, 7, 3, 4, 9, 2, 4, 8, 3, 4, 5, 6, 7, 10, 1, 4, 6, 2, 3, 4, 3, 1, 7, 1, 5, 8, 2, 9, 4, 10, 1, 2, 3, 4, 5, 6, 8, 6, 1, 8, 10, 5, 8, 5, 1, 2, 3, 4, 7, 5, 1, 5, 7, 3, 10, 9, 7, 8, 9, 4, 3, 4, 5, 8, 9, 10, 3, 4, 8, 4, 8, 7, 7, 8, 10, 1, 9, 8, 9, 10, 1, 1, 4, 5, 6, 8, 1, 2, 3, 4, 5, 7, 8, 9, 10, 1, 3, 7, 8, 2, 8, 10, 1, 2, 3, 4, 6, 7, 8, 9, 10, 1, 2, 3, 5], \"Freq\": [0.9988959021092304, 0.787614184456862, 0.20599140208871775, 0.9992332215015258, 0.08604925730639133, 0.2564438262299385, 0.5103317339260238, 0.14398341074039736, 0.0025559185338532076, 0.9992940463445185, 0.9976521780886082, 0.22508076159160376, 0.7704687608327975, 0.9928020851506512, 0.7206985233574623, 0.2775663231849686, 0.180203415582953, 0.8145194384349476, 0.7444848005196752, 0.24502031409508299, 0.9888885413955417, 0.990878304718827, 0.9905491997050577, 0.9842455472535284, 0.002512940090695723, 0.9963807459608542, 0.18031661656253814, 0.5521419155432202, 0.19399580816383413, 0.07461377237070543, 0.006154349169422115, 0.7754479953471864, 0.20924787176035192, 0.9938205513665339, 0.004164172791431697, 0.9952372971521755, 0.9949794838949272, 0.07690007408017477, 0.002136113168893744, 0.057675055560131076, 0.042722263377874874, 0.18156961935596821, 0.027769471195618668, 0.4464476522987924, 0.032041697533406154, 0.13457512964030585, 0.01707549317997416, 0.20490591815968995, 0.6796046285629717, 0.09220766317186048, 0.0034150986359948324, 0.04097036659832401, 0.16811978017932955, 0.7883263642022343, 0.00482125016866638, 0.9883562845766081, 0.97760305410283, 0.01136747737328872, 0.9802846198736193, 0.017662785943668817, 0.9887051694905025, 0.9928856807357644, 0.801857733601936, 0.19504647574101147, 0.9941232678772477, 0.9947159256754553, 0.9957570613858638, 0.2743806444249359, 0.06144431419554549, 0.1917486356792023, 0.00635630836505643, 0.38243788663089523, 0.083691393473243, 0.995875050368826, 0.14198779607955947, 0.7560227387744964, 0.10088606563547646, 0.9804150370994029, 0.9922699978241718, 0.9977478532946277, 0.9914740977722695, 0.9887087180815143, 0.13446388411694493, 0.5123537653421523, 0.3500697672699773, 0.9982178593272961, 0.981413902429461, 0.01502164136371624, 0.9918498705536077, 0.9918120911986343, 0.9985362660299497, 0.9969621802233617, 0.4852880429414707, 0.24788094279744186, 0.07680817945836227, 0.18852916776143466, 0.2647224713930825, 0.04938852078229152, 0.003951081662583322, 0.681561586795623, 0.9975978685552761, 0.0011297824105948766, 0.9903449639828702, 0.9966343644456497, 0.9898893758670397, 0.6838118103713594, 0.19335368431190164, 0.11789858799506198, 0.9892265529483564, 0.7860636191765026, 0.001177447002960609, 0.21241143933409387, 0.9932858616872791, 0.9921798341377486, 0.9962191314448124, 0.9879993981019863, 0.9899235802232176, 0.9994966916480805, 0.9880616527042254, 0.02513832735414397, 0.9732123875675737, 0.9967335452802851, 0.9943133848882383, 0.7809246275101445, 0.21793245418887752, 0.9864827981300944, 0.9913676135198368, 0.11836276185335336, 0.19760562783992044, 0.09930435104645748, 0.03410452460181368, 0.20763637036986562, 0.1404303954192328, 0.20161792485189853, 0.00100307425299452, 0.9966235486374305, 0.9922145485613816, 0.26214375889069386, 0.7328109623535305, 0.9915658866162332, 0.9956767284502205, 0.9945630297795667, 0.9902327498422967, 0.9968405559640803, 0.9982922338242345, 0.018058218862639124, 0.5218825251302707, 0.17877636674012734, 0.019864040748903036, 0.26184417350826733, 0.10922075441083859, 0.2566029772302834, 0.0671115478909972, 0.09606162737338816, 0.17896412770932588, 0.17106865148685563, 0.11974805604079894, 0.9852269265621982, 0.9954591011303372, 0.9978990391680691, 0.14592511581033066, 0.42610133816616547, 0.14884361812653726, 0.28017622235583484, 0.9904024766310385, 0.9875760311889932, 0.009592510351016577, 0.9784360558036909, 0.9963008644265093, 0.10181245671377956, 0.13574994228503942, 0.14762806223498035, 0.019514054203474414, 0.1365983794243209, 0.13744681656360241, 0.32155767578768707, 0.9953310507913121, 0.9920205646041707, 0.9814912935588428, 0.9932218266309565, 0.9964903148273846, 0.9951747420654463, 0.9944945555866233, 0.14462093042289012, 0.8151361532926534, 0.03944207193351549, 0.9918832209667535, 0.909081875925458, 0.08990919652010024, 0.9967089116645956, 0.9833528075098776, 0.7386638258797624, 0.2587675823145665, 0.17969090085789483, 0.12993034369724704, 0.06634740954753039, 0.6233892022070043, 0.9962799803349747, 0.9857025817099528, 0.9976819845380805, 0.9953886015401608, 0.9952160504625115, 0.9927515038467398, 0.9966459324159828, 0.9933963622804515, 0.9945971408109485, 0.19751689781833578, 0.22886878636092878, 0.006270377708518597, 0.3668170959483379, 0.0031351888542592984, 0.19751689781833578, 0.7693920232324755, 0.22676817526851908, 0.9985897560703013, 0.9899696242220947, 0.994045593297201, 0.7119298246322541, 0.2869130721826227, 0.9969721455853358, 0.0006740286588268822, 0.005392229270615057, 0.25343477571890766, 0.019546831105979583, 0.0006740286588268822, 0.43946668555512713, 0.25882700498952277, 0.016850716470672055, 0.005392229270615057, 0.1983994198630367, 0.7979107103187346, 0.17666271265834457, 0.07066508506333784, 0.7517303014496456, 0.6569681813939704, 0.3408537844889219, 0.9888510108900356, 0.5930336074109559, 0.21964207681887257, 0.1874279055521046, 0.998946983713575, 0.9901689155604545, 0.9913794258646874, 0.9878145637211555, 0.991393944677661, 0.08208820497668715, 0.9164028701033802, 0.9853352904158761, 0.12708640221475956, 0.00518720009039835, 0.5991216104410093, 0.07262080126557689, 0.031123200542390095, 0.163396802847548, 0.3317924574937947, 0.2224961185546623, 0.05952747031506316, 0.07514123302065351, 0.08489983471164747, 0.2244478388928611, 0.9989453126754684, 0.9988457990880628, 0.9919648828145163, 0.9881453543409411, 0.9991197836874827, 0.9944758014332135, 0.99313588045658, 0.994201818515773, 0.9964990006588661, 0.003803318179950753, 0.0003728743313677209, 0.19031505873008475, 0.8054831306205507, 0.2162175566866148, 0.7783832040718133, 0.9896910461154986, 0.9905075217935455, 0.9965120283794905, 0.998183795158743, 0.9912748703613486, 0.9935098586043528, 0.9966208815624095, 0.9943589587142103, 0.9748991746429216, 0.0022465237961327433, 0.9963333035848716, 0.9909985148867314, 0.1576128356220519, 0.7919558530638903, 0.046700099443570925, 0.992448633593499, 0.30093403081686926, 0.6986597089724976, 0.9898792993176218, 0.8149444471618195, 0.1824148907891282, 0.22729432169238475, 0.5273228263263326, 0.24093198099392785, 0.9920599183942151, 0.9992034851273968, 0.9940885619629704, 0.16189164552387567, 0.003372742615080743, 0.010118227845242229, 0.5936027002542108, 0.23271924044057127, 0.24970086271624745, 0.7491025881487423, 0.9933845315272459, 0.6849628444234097, 0.31070479540855694, 0.00392794681988973, 0.9584190240530941, 0.03535152137900757, 0.008285074116314226, 0.015816959676599886, 0.058748707370228144, 0.0753188556028566, 0.000753188556028566, 0.010544639784399923, 0.17172699077451303, 0.1378335057532276, 0.5212064807717677, 0.7704162924405434, 0.06010339870103531, 0.16391836009373265, 0.3354114671807544, 0.6637863301549195, 0.9774041167785709, 0.00856306744782527, 0.0363930366532574, 0.010703834309781588, 0.17340211581846174, 0.14343137975107328, 0.6251039236912448, 0.9916034069943688, 0.46396452090921514, 0.2270464676789776, 0.002467896387814974, 0.10611954467604388, 0.19743171102519794, 0.36393612210396165, 0.08480064981063185, 0.5512042237691069, 0.6197794371459545, 0.37771965697307097, 0.09741402596504685, 0.1725619888523687, 0.7292135657954936, 0.9924978762206434, 0.9946428732911939, 0.992559558135265, 0.9951038217963858, 0.11975987776745839, 0.41529635032263795, 0.463586623615968, 0.9959276326484363, 0.9985972800576223, 0.9907839946325058, 0.988414011753414, 0.9991496070041778, 0.0015368377411998757, 0.9974076940387193, 0.9882563656342849, 0.31138145721830673, 0.6883169054299412, 0.9933806709101022, 0.998280381919256, 0.5415725942420571, 0.0025850720488881005, 0.18354011547105512, 0.27143256513325054, 0.980987285559781, 0.016556747435608116, 0.9950529395045623, 0.9954485014153294, 0.992680071979019, 0.9881359220526241, 0.12060945270876636, 0.10378022674940361, 0.5974375215573775, 0.1739020015800817, 0.8571318645018151, 0.0646891973208917, 0.07547073020770699, 0.9956811504059924, 0.9915409028956028, 0.6685959081750344, 0.3270828903302327, 0.9760760498059537, 0.9960456346364194, 0.9837717833013612, 0.9872593744970878, 0.9930901521510993, 0.494644969935527, 0.00281848985718249, 0.1000563899299784, 0.08737318557265719, 0.07609922614392722, 0.2381623929319204, 0.06634893556563598, 0.1514116734702975, 0.05954391653326306, 0.38278232057097683, 0.14290539967983135, 0.1956442971807215, 0.14302048322042674, 0.29776395686875734, 0.13364209087810366, 0.07737173682416529, 0.2766625740985304, 0.07033794256742298, 0.990658046093788, 0.9924880243863516, 0.2758242092928871, 0.72284965193998, 0.9984252527209105, 0.06778434732829, 0.28404869356616763, 0.4217692722649156, 0.004303768084335874, 0.13772057869874796, 0.0053797101054198415, 0.07961970956021366, 0.9916382766455476, 0.03928801924705221, 0.21429828680210297, 0.746472365693992, 0.9937812841672641, 0.9978272902056542, 0.998416243879985, 0.9911166730664781, 0.7831564614266956, 0.21358812584364426, 0.9933972920140045, 0.996623666601096, 0.0018411637229164936, 0.019332219090623184, 0.13026233339634194, 0.13256378804998756, 0.24073215677133156, 0.059377530064056924, 0.4151824195176693, 0.7493732276816083, 0.002236935008004801, 0.06934498524814883, 0.0011184675040024005, 0.17671786563237926, 0.9980383524271809, 0.23336905363361996, 0.11900276244893203, 0.6444695057299307, 0.0015454904214147018, 0.9931882105462709, 0.2037977999003941, 0.52879096917677, 0.12051830027332276, 0.14624692617436919, 0.9994947448669792, 0.9908319194661215, 0.9953734994896035, 0.989828673393913, 0.9920196044797975, 0.002379875019710228, 0.7074178496088653, 0.28974978364972026, 0.9947229607445228, 0.989642018674547, 0.9942123419822817, 0.9951736931231931, 0.9915739298129795, 0.9935074766915153, 0.12319491091664896, 0.8740972250752712, 0.9987266847390606, 0.9874205266468943, 0.6380324057579249, 0.2962293312447508, 0.06456280296359954, 0.17547529224174185, 0.6453921765501354, 0.17547529224174185, 0.9900834655045877, 0.18399327272175559, 0.18799312647657637, 0.6239771857520408, 0.001999926877410387, 0.7799047425152349, 0.21937619048935997, 0.9899026127218973, 0.9915530938861465, 0.1105761533701163, 0.0333060702922037, 0.11590512461686889, 0.002664485623376296, 0.4876008690778622, 0.03863504153895629, 0.026644856233762962, 0.17319156551945925, 0.010657942493505185, 0.1816272736142703, 0.23129098124317232, 0.1915600151400507, 0.3944717348809933, 0.5637011334149242, 0.006333720600167687, 0.11084011050293453, 0.09817266930259916, 0.2248470813059529, 0.9898072782894192, 0.9902428999677257, 0.986600026046603, 0.9970269085529821, 0.9928394879113233, 0.8315589878901912, 0.1684128021368717, 0.9963597056077823, 0.004867390299332026, 0.8225889605871124, 0.17133213853648732, 0.1879582435550357, 0.8027383318496317, 0.003915796740729911, 0.6368134294422796, 0.13530030370586676, 0.22730451022585618, 0.9942895656472178, 0.9873477558614602, 0.4404533589739279, 0.5587841121311026, 0.9979910138355301, 0.0008926574363466279, 0.06829065487718403, 0.18603316328612202, 0.6240352945673713, 0.1224522087452955, 0.9930091785692615, 0.9890095385206101, 0.9912703462654073, 0.008638146213153662, 0.7895265638822447, 0.20126880676648035, 0.9939292759009417, 0.9889477803623357, 0.9949678091157343, 0.9938206109443389, 0.9933468819502885, 0.9979326870404713, 0.1550045497548473, 0.5138889577458, 0.1948030152324432, 0.135454426362344, 0.9938137319892422, 0.9914250321710224, 0.9861329137984267, 0.6587477635295846, 0.010606634490413092, 0.0011364251239728315, 0.20948103118565858, 0.11818821289317447, 0.0018940418732880523, 0.8238311952201666, 0.006590649561761332, 0.057118962868598216, 0.1113087481541914, 0.0007322943957512592, 0.03642474074376423, 0.1295101893111617, 0.004047193415973803, 0.5463711111564634, 0.004047193415973803, 0.27925634570219243, 0.9983925256589946, 0.9908721430304028, 0.12111779162445237, 0.03772521378466549, 0.6532418597449972, 0.1846549937880995, 0.001985537567613973, 0.0018380576723178602, 0.012866403706225021, 0.19483411326569317, 0.10109317197748231, 0.40621074558224707, 0.2812228238646326, 0.24121012572085637, 0.12647233618877335, 0.16167597615884427, 0.10561091991021279, 0.005215354069640138, 0.044330509591941174, 0.1551567835717941, 0.003911515552230104, 0.1551567835717941, 0.9858887492031372, 0.9969740665725381, 0.990059989834906, 0.9023738590557892, 0.09680831283922585, 0.15220156012229488, 0.150224916484343, 0.06819420550933991, 0.019766436379518814, 0.5040441276777298, 0.033602941845181984, 0.07214749278524367, 0.9905608089219476, 0.01947154017999697, 0.977471317035848, 0.9835717374859071, 0.9932739487710438, 0.9935002159072656, 0.9951720825349635, 0.9893762855090824, 0.4522774530515057, 0.05207141729211414, 0.29606320117516327, 0.037193869494367246, 0.16216527099544117, 0.9924973292209884, 0.2807393920586772, 0.0831820420914599, 0.2374154118027085, 0.3968476591446733, 0.9907075074465579, 0.991224157723745, 0.9986844255739181, 0.9980380878841015, 0.9907674583896516, 0.7197615910095959, 0.27203587691701264, 0.6707679182044259, 0.32444752565322776, 0.9933626943301823, 0.1131347143445584, 0.0685664935421566, 0.03771157144818613, 0.7782297017034775, 0.9985608307164044, 0.28553110947564936, 0.7138277736891233, 0.9980260378618622, 0.9894232085683474, 0.9872166440723178, 0.9949234793221013, 0.4174233152813786, 0.197512495523384, 0.05701391623355415, 0.08348466305627572, 0.16696932611255144, 0.002036211294055505, 0.0753398178800537, 0.1659956162670288, 0.12348454380839947, 0.7085178743104888, 0.8304233739340703, 0.16465291034899668, 0.187246328742607, 0.8100439004299738, 0.9885556864294257, 0.9921699948282282, 0.9980015833040868, 0.9860258469314271, 0.003505869677978408, 0.00876467419494602, 0.001752934838989204, 0.9900650253073267, 0.9887354069501139, 0.9997442985166629, 0.006230162752946044, 0.15367734790600243, 0.8369185298124187, 0.9965698806318248, 0.9887010413703965, 0.9981603887956646, 0.994541025394599, 0.3255406991939431, 0.6735324810909167, 0.9989758830938004, 0.9285928042323381, 0.06145099439772826, 0.9953986202085479, 0.9919008318301878, 0.9914764960481959, 0.9876585618926892, 0.9811762741115713, 0.7133403704873984, 0.0032060241370220153, 0.28213012405793736, 0.9980072944324868, 0.9965069041752754, 0.00195393510622603, 0.9157478268423994, 0.0596856125502495, 0.0238742450200998, 0.24513118942819637, 0.7507142676238514, 0.992531664794183, 0.7705622062698847, 0.22729973030136766, 0.9940753599277382, 0.9913362773299194, 0.9985549496074791, 0.9995800372016298, 0.993450571893518, 0.994935181454493, 0.998054342119072, 0.07179320234439882, 0.7565899016294337, 0.16843789780801263, 0.9945829858011596, 0.9938477360075947, 0.9946649519481375, 0.9895675645203472, 0.9748622428909003, 0.0062082611948733315, 0.2266015336128766, 0.6968773191245315, 0.06829087314360666, 0.9990517609151429, 0.9975658059072887, 0.40554922059353343, 0.11305133140439207, 0.29070342361129387, 0.19021335125183428, 0.8478746999980573, 0.1413124499996762, 0.9978554482018918, 0.994389312832577, 0.24124402898200656, 0.5573568945446359, 0.1996502308816606, 0.9882045181350769, 0.996517858591838, 0.990566748934689, 0.9940994201636156, 0.9911797739133983, 0.11721732360069857, 0.3785366780499623, 0.1354989245292479, 0.10108649925197859, 0.1258204299200159, 0.06344790910496528, 0.07742795687385594, 0.9845017703664976, 0.011187520117801109, 0.9893198601092846, 0.0002792156806274406, 0.0002792156806274406, 0.13290666397866174, 0.2607874457060296, 0.6058980269615462, 0.12105294373107546, 0.873850937558701, 0.9830552509425087, 0.20268319629698917, 0.7934831514605534, 0.9948748813238133, 0.17582837598592568, 0.8215429291756183, 0.9928944778644421, 0.9964677058472211, 0.9932371045402093, 0.1826244694191893, 0.8144064176801685, 0.9946738423395245, 0.993793098911726, 0.9807500377374656, 0.9965365508069541, 0.9909886611077096, 0.9915891323056847, 0.6692821457713346, 0.3265774325751693, 0.9887132584776838, 0.9969534339687404, 0.9876967183936944, 0.6381330019544925, 0.1209692331949356, 0.1152861148569185, 0.12543454046052047, 0.9870651118627889, 0.4898327673026439, 0.0854741741601929, 0.003287468236930496, 0.1577984753726638, 0.2597099907175092, 0.0006182430582360423, 0.9992868631288564, 0.9869070263499387, 0.9951398663456165, 0.9906966873656905, 0.9884012689400924, 0.6182949135968476, 0.07841789148057579, 0.3016072749252915, 0.9940714632969154, 0.9952419536053999, 0.9829985635848725, 0.9918936717587513, 0.9671142104864491, 0.9339472383569698, 0.06461270202469603, 0.00392175509150401, 0.6314025697321456, 0.3608014684183689, 0.19976862109612553, 0.145594079781922, 0.006771817664275441, 0.010157726496413161, 0.4096949686886642, 0.22346998292108958, 0.34038320865203336, 0.6515907137053211, 0.0048626172664576195, 0.10363466910936363, 0.6880860007144957, 0.20726933821872726, 0.9877795887372482, 0.9621932383793782, 0.030305298846594587, 0.12742673185742662, 0.8524408958738193, 0.017576100945851946, 0.9903690174834797, 0.9954451261355075, 0.8813214480268264, 0.11331275760344911, 0.11617409039043655, 0.06680010197450102, 0.12198279490995838, 0.14957414137768707, 0.045017460026294163, 0.3543309756908315, 0.14376543685816523, 0.9974128008623101, 0.003286037403917669, 0.8905161364616884, 0.10515319692536541, 0.5347674527178912, 0.4649461829268312, 0.9917160945002651, 0.02007155711512849, 0.08028622846051396, 0.1706082354785922, 0.48840788980146, 0.2408586853815419, 0.996316766394517, 0.7871694528185931, 0.048876534652134866, 0.16206429910971035, 0.8810813367324685, 0.11013516709155856, 0.9823198840792101, 0.0011635838291083386, 0.002327167658216677, 0.9960277577167378, 0.9953625440259227, 0.28296333400225643, 0.09432111133408548, 0.6219298278591261, 0.010001927101356764, 0.7901522410071844, 0.19503757847645692, 0.20959633405983075, 0.15102093271611378, 0.6391492772470884, 0.9885838143174912, 0.9943991197770314, 0.9910997737243613, 0.010891675003919852, 0.9802507503527866, 0.9979758846708832, 0.994764880245949, 0.982998747649383, 0.0015687977476526345, 0.2415948531385057, 0.7561605143685698, 0.9992740728588667, 0.10022239808368619, 0.02987398404417569, 0.5473684818416706, 0.08191253689532044, 0.23995554925805634, 0.0386459169009551, 0.11830382724782174, 0.1159377507028653, 0.06546145107712803, 0.04495545435417226, 0.08123529471017092, 0.14354197706069038, 0.3036464899360758, 0.08754483216338808, 0.3367857505484922, 0.0688879944303734, 0.002551407201124941, 0.5919264706609862, 0.7797891805399559, 0.2166081057055433, 0.9906210411469936, 0.010470499832496451, 0.028419928116776082, 0.16752799731994322, 0.09722606987318134, 0.119164259998412, 0.0004985952301188787, 0.18597602083434173, 0.07877804635878283, 0.31212061405441804, 0.9960675546057299, 0.9930164957880865, 0.9916966336976896, 0.9956320337919364], \"Term\": [\"..\", \"ability\", \"ability\", \"acting\", \"action\", \"action\", \"action\", \"action\", \"action\", \"actor\", \"actress\", \"adult\", \"adult\", \"affair\", \"air\", \"air\", \"alien\", \"alien\", \"america\", \"america\", \"american\", \"angle\", \"answer\", \"anybody\", \"anyone\", \"anyone\", \"anything\", \"anything\", \"anything\", \"anything\", \"appearance\", \"appearance\", \"appearance\", \"arm\", \"aspect\", \"aspect\", \"atmosphere\", \"attempt\", \"attempt\", \"attempt\", \"attempt\", \"attempt\", \"attempt\", \"attempt\", \"attempt\", \"attempt\", \"attention\", \"attention\", \"attention\", \"attention\", \"attention\", \"audience\", \"audience\", \"audience\", \"background\", \"background\", \"ball\", \"ball\", \"batman\", \"batman\", \"beast\", \"bed\", \"beginning\", \"beginning\", \"behavior\", \"belief\", \"bill\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"bomb\", \"book\", \"book\", \"book\", \"boring\", \"bos\", \"boy\", \"boyfriend\", \"break\", \"brother\", \"brother\", \"brother\", \"budget\", \"business\", \"business\", \"button\", \"cable\", \"camera\", \"car\", \"career\", \"career\", \"career\", \"career\", \"case\", \"case\", \"case\", \"case\", \"cast\", \"cast\", \"casting\", \"cat\", \"catherine\", \"century\", \"century\", \"century\", \"cgi\", \"character\", \"character\", \"character\", \"charlie\", \"charm\", \"chase\", \"cheesy\", \"chemistry\", \"child\", \"childhood\", \"cinematography\", \"cinematography\", \"city\", \"classic\", \"club\", \"club\", \"clue\", \"columbo\", \"comedy\", \"comedy\", \"comedy\", \"comedy\", \"comedy\", \"comedy\", \"comedy\", \"comedy\", \"comment\", \"comparison\", \"conclusion\", \"conclusion\", \"connection\", \"cop\", \"copy\", \"cost\", \"costume\", \"country\", \"couple\", \"couple\", \"couple\", \"couple\", \"couple\", \"course\", \"course\", \"course\", \"course\", \"course\", \"course\", \"course\", \"cousin\", \"cover\", \"crap\", \"credit\", \"credit\", \"credit\", \"credit\", \"criminal\", \"crowd\", \"dad\", \"dad\", \"daughter\", \"day\", \"day\", \"day\", \"day\", \"day\", \"day\", \"day\", \"decade\", \"decision\", \"degree\", \"demon\", \"depth\", \"design\", \"desire\", \"detail\", \"detail\", \"detail\", \"development\", \"dialog\", \"dialog\", \"dialogue\", \"dick\", \"direction\", \"direction\", \"director\", \"director\", \"director\", \"director\", \"disney\", \"display\", \"doctor\", \"documentary\", \"dog\", \"dollar\", \"doo\", \"door\", \"dozen\", \"dream\", \"dream\", \"dream\", \"dream\", \"dream\", \"dream\", \"drug\", \"drug\", \"dvd\", \"edge\", \"editing\", \"effect\", \"effect\", \"element\", \"end\", \"end\", \"end\", \"end\", \"end\", \"end\", \"end\", \"end\", \"end\", \"entertainment\", \"entertainment\", \"episode\", \"episode\", \"episode\", \"event\", \"event\", \"everybody\", \"everyone\", \"everyone\", \"everyone\", \"everything\", \"evil\", \"existence\", \"expectation\", \"extra\", \"eye\", \"eye\", \"f\", \"face\", \"face\", \"face\", \"face\", \"face\", \"face\", \"fact\", \"fact\", \"fact\", \"fact\", \"fact\", \"fact\", \"family\", \"fan\", \"fantasy\", \"fashion\", \"father\", \"festival\", \"fiction\", \"field\", \"fight\", \"film\", \"film\", \"film\", \"film\", \"filmmaker\", \"filmmaker\", \"finger\", \"flashback\", \"flaw\", \"flick\", \"folk\", \"food\", \"force\", \"ford\", \"freak\", \"friend\", \"friend\", \"friendship\", \"fun\", \"fun\", \"fun\", \"funny\", \"game\", \"game\", \"gay\", \"genre\", \"genre\", \"george\", \"george\", \"george\", \"ghost\", \"girl\", \"girlfriend\", \"god\", \"god\", \"god\", \"god\", \"god\", \"gore\", \"gore\", \"government\", \"guess\", \"guess\", \"gun\", \"gun\", \"gun\", \"guy\", \"guy\", \"guy\", \"guy\", \"guy\", \"guy\", \"guy\", \"guy\", \"guy\", \"hair\", \"hair\", \"hair\", \"half\", \"half\", \"hate\", \"head\", \"head\", \"head\", \"head\", \"head\", \"head\", \"health\", \"heart\", \"heart\", \"heart\", \"heart\", \"heart\", \"hell\", \"hell\", \"hell\", \"hero\", \"hero\", \"history\", \"history\", \"history\", \"hit\", \"hitchcock\", \"hoffman\", \"hole\", \"home\", \"home\", \"home\", \"hope\", \"horror\", \"horse\", \"hotel\", \"hour\", \"house\", \"house\", \"humanity\", \"humor\", \"humor\", \"hunter\", \"husband\", \"idea\", \"idea\", \"idea\", \"idea\", \"image\", \"image\", \"imagination\", \"imdb\", \"information\", \"intention\", \"interest\", \"interest\", \"interest\", \"interest\", \"issue\", \"issue\", \"issue\", \"jack\", \"jackson\", \"james\", \"james\", \"jazz\", \"jeff\", \"jerry\", \"jet\", \"jim\", \"job\", \"job\", \"job\", \"job\", \"job\", \"job\", \"john\", \"john\", \"john\", \"john\", \"john\", \"john\", \"joke\", \"joke\", \"joke\", \"joke\", \"joke\", \"joke\", \"jr\", \"keaton\", \"kid\", \"kid\", \"killer\", \"kind\", \"kind\", \"kind\", \"kind\", \"kind\", \"kind\", \"kind\", \"knife\", \"lady\", \"lady\", \"lady\", \"language\", \"laugh\", \"lead\", \"leader\", \"lee\", \"lee\", \"let\", \"level\", \"life\", \"life\", \"life\", \"life\", \"life\", \"life\", \"life\", \"line\", \"line\", \"line\", \"line\", \"line\", \"location\", \"look\", \"look\", \"look\", \"look\", \"loss\", \"lot\", \"lot\", \"lot\", \"lot\", \"love\", \"lynch\", \"machine\", \"magic\", \"maker\", \"man\", \"man\", \"man\", \"mark\", \"market\", \"marriage\", \"match\", \"max\", \"meet\", \"memory\", \"memory\", \"men\", \"mention\", \"message\", \"message\", \"message\", \"michael\", \"michael\", \"michael\", \"mile\", \"mind\", \"mind\", \"mind\", \"mind\", \"minute\", \"minute\", \"mission\", \"mom\", \"moment\", \"moment\", \"moment\", \"moment\", \"moment\", \"moment\", \"moment\", \"moment\", \"moment\", \"money\", \"money\", \"money\", \"money\", \"monster\", \"monster\", \"monster\", \"monster\", \"monster\", \"montage\", \"month\", \"moore\", \"mother\", \"motion\", \"movie\", \"movie\", \"mr\", \"music\", \"music\", \"music\", \"mystery\", \"mystery\", \"mystery\", \"name\", \"name\", \"name\", \"nature\", \"network\", \"none\", \"none\", \"nothing\", \"nothing\", \"number\", \"number\", \"number\", \"number\", \"office\", \"officer\", \"oh\", \"one\", \"one\", \"one\", \"opening\", \"opera\", \"opinion\", \"opportunity\", \"pain\", \"parent\", \"part\", \"part\", \"part\", \"part\", \"party\", \"past\", \"path\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"period\", \"period\", \"period\", \"period\", \"period\", \"period\", \"person\", \"phone\", \"picture\", \"picture\", \"picture\", \"picture\", \"picture\", \"piece\", \"piece\", \"piece\", \"piece\", \"piece\", \"piece\", \"place\", \"place\", \"place\", \"place\", \"place\", \"place\", \"place\", \"place\", \"place\", \"planet\", \"play\", \"pleasure\", \"plot\", \"plot\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"pointless\", \"police\", \"police\", \"population\", \"porn\", \"presence\", \"president\", \"prison\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"process\", \"production\", \"production\", \"production\", \"production\", \"program\", \"puppet\", \"quality\", \"question\", \"rape\", \"rate\", \"rate\", \"rating\", \"rating\", \"reaction\", \"reality\", \"reality\", \"reality\", \"reality\", \"reason\", \"relationship\", \"relationship\", \"release\", \"reno\", \"rent\", \"research\", \"rest\", \"rest\", \"rest\", \"rest\", \"rest\", \"rest\", \"rest\", \"review\", \"review\", \"review\", \"richard\", \"richard\", \"right\", \"right\", \"robin\", \"robot\", \"rock\", \"role\", \"role\", \"role\", \"role\", \"running\", \"scale\", \"scene\", \"school\", \"school\", \"school\", \"science\", \"scooby\", \"score\", \"scream\", \"screen\", \"screen\", \"script\", \"seagal\", \"seagal\", \"season\", \"seat\", \"second\", \"section\", \"see\", \"sense\", \"sense\", \"sense\", \"sequel\", \"sequence\", \"sequence\", \"series\", \"series\", \"series\", \"set\", \"set\", \"setting\", \"sex\", \"sex\", \"shakespeare\", \"shame\", \"shot\", \"show\", \"sight\", \"sign\", \"sister\", \"situation\", \"situation\", \"situation\", \"skill\", \"skin\", \"slasher\", \"smile\", \"snowman\", \"someone\", \"someone\", \"someone\", \"someone\", \"something\", \"son\", \"song\", \"song\", \"song\", \"song\", \"sorry\", \"sorry\", \"sound\", \"soundtrack\", \"space\", \"space\", \"space\", \"spirit\", \"spoiler\", \"spot\", \"stage\", \"stand\", \"star\", \"star\", \"star\", \"star\", \"star\", \"star\", \"star\", \"store\", \"store\", \"storm\", \"story\", \"story\", \"story\", \"story\", \"story\", \"storyline\", \"storyline\", \"streep\", \"street\", \"street\", \"student\", \"stuff\", \"stuff\", \"sub\", \"subject\", \"subtitle\", \"success\", \"success\", \"suit\", \"surface\", \"tactic\", \"talent\", \"task\", \"taste\", \"television\", \"television\", \"tell\", \"theater\", \"theory\", \"thing\", \"thing\", \"thing\", \"thing\", \"think\", \"thriller\", \"thriller\", \"thriller\", \"thriller\", \"thriller\", \"time\", \"time\", \"tongue\", \"top\", \"topic\", \"torture\", \"town\", \"town\", \"town\", \"tracy\", \"tragedy\", \"transformation\", \"treatment\", \"trek\", \"trouble\", \"trouble\", \"truth\", \"truth\", \"truth\", \"try\", \"try\", \"try\", \"try\", \"try\", \"try\", \"turn\", \"turn\", \"turn\", \"tv\", \"tv\", \"tv\", \"twin\", \"twist\", \"twist\", \"use\", \"use\", \"use\", \"v\", \"value\", \"van\", \"van\", \"version\", \"version\", \"version\", \"version\", \"version\", \"version\", \"version\", \"video\", \"view\", \"view\", \"view\", \"viewer\", \"viewer\", \"viewing\", \"villain\", \"villain\", \"villain\", \"villain\", \"villain\", \"violence\", \"voice\", \"voice\", \"voice\", \"wait\", \"wait\", \"walker\", \"war\", \"war\", \"war\", \"waste\", \"watch\", \"watch\", \"watch\", \"water\", \"water\", \"water\", \"way\", \"way\", \"way\", \"wayne\", \"well\", \"west\", \"whole\", \"whole\", \"wife\", \"winner\", \"wish\", \"woman\", \"woman\", \"woman\", \"word\", \"work\", \"work\", \"work\", \"work\", \"work\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"writer\", \"writer\", \"writer\", \"writer\", \"writing\", \"writing\", \"yeah\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"yes\", \"york\", \"you.s\", \"zombie\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el294481241067965022566529873082\", ldavis_el294481241067965022566529873082_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el294481241067965022566529873082\", ldavis_el294481241067965022566529873082_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el294481241067965022566529873082\", ldavis_el294481241067965022566529873082_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyLDAvis.gensim\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "#########################################\n",
    "# SOLUCIÓ: Visualitzar el millor model\n",
    "#########################################\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "lda_display = gensimvis.prepare(lda_model_10, corpus, dictionary, sort_topics=False)\n",
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YF6i9Y4Lodhq",
   "metadata": {
    "id": "YF6i9Y4Lodhq"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<strong>Exercici opcional:</strong> Prenent com a base els resultats de cada model LDA, calculeu les mètriques de qualitat anomenades perplexitat i coherència, les quals estan definides en el paquet gensim.\n",
    "<br>\n",
    "Tant la perplexitat com la coherència són mètriques complementàries. Una perplexitat baixa indica que el model pot generalitzar bé noves dades, mentre que una alta coherència indica que els temes generats són interpretables i diferents entre si. Quan avaluem el rendiment d‟un model LDA, se suggereix triar models que evidenciïn un equilibri entre ambdues mètriques.\n",
    "<br>\n",
    "Com indica l'enunciat aquest exercici és opcional, però ha estat incorporat a la pràctica per si algú vol aprendre una mica més el tema. Les mètriques esmentades ens poden ajudar a tenir un criteri addicional per triar el model de temes més adequats. Per a una introducció bàsica d'aquest tema podrien revisar el post següent (https://medium.com/@iqra.bismi/topic-modelling-using-lda-fe81a2a806e0)\n",
    "<br>\n",
    "<b>Sortida esperada:</b>\n",
    "<br>\n",
    "- Valors de coherència i perplexitat de cada model (pots fer servir el valor absolut calculat per a una millor interpretació) de cadascun dels 3 models de LDA.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ggDQcxhpoexZ",
   "metadata": {
    "id": "ggDQcxhpoexZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model amb 5 tòpics - Perplexitat: -8.45419249190778 , Coherència: 0.4489999529243489\n",
      "Model amb 10 tòpics - Perplexitat: -9.235541584951802 , Coherència: 0.43606961172031616\n",
      "Model amb 15 tòpics - Perplexitat: -10.293089876701881 , Coherència: 0.3525516505614296\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "def compute_metrics(model, corpus, dictionary, texts):\n",
    "    # Perplexitat\n",
    "    perplexity = model.log_perplexity(corpus)\n",
    "    \n",
    "    # Coherència\n",
    "    coherence_model_lda = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "    coherence = coherence_model_lda.get_coherence()\n",
    "    \n",
    "    return perplexity, coherence\n",
    "\n",
    "perplexity_5, coherence_5 = compute_metrics(lda_model_5, corpus, dictionary, noun_and_collocation_stream)\n",
    "perplexity_10, coherence_10 = compute_metrics(lda_model_10, corpus, dictionary, noun_and_collocation_stream)\n",
    "perplexity_15, coherence_15 = compute_metrics(lda_model_15, corpus, dictionary, noun_and_collocation_stream)\n",
    "\n",
    "print(\"Model amb 5 tòpics - Perplexitat:\", perplexity_5, \", Coherència:\", coherence_5)\n",
    "print(\"Model amb 10 tòpics - Perplexitat:\", perplexity_10, \", Coherència:\", coherence_10)\n",
    "print(\"Model amb 15 tòpics - Perplexitat:\", perplexity_15, \", Coherència:\", coherence_15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6ed8c2",
   "metadata": {
    "id": "1f6ed8c2"
   },
   "source": [
    "# 4. Classificació automàtica d'opinions positives i negatives\n",
    "\n",
    "L'objectiu d'aquesta part serà crear un classificador que permeti, donat un text, identificar la polaritat de la vostra opinió.\n",
    "\n",
    "## 4.1 Classificació binària de sentiments segons Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32290b6e",
   "metadata": {
    "id": "32290b6e"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Exercici 4.1.1:</strong> Crear un classificador automàtic d'opinions positives i negatives.\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "<b>Passos a seguir:</b>\n",
    "\n",
    "1. Crear dues llistes, una amb els textos i una altra amb les etiquetes de valoració (0 i 1).\n",
    "2. Vectoritzar les opinions amb un vectoritzador tf.idf. Feu servir 'word' com a analyzer\n",
    "3. Preparar el corpus d'entrenament i avaluació i entrenar el classificador amb Logistic Regression.\n",
    "4. Utilitzar el model entrenat per predir la categoria 1 (positiu) o 0 (negatiu) de les opinions del conjunt de test i mostrar les paraules més informatives per a cada categoria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a45ae89",
   "metadata": {
    "id": "3a45ae89"
   },
   "source": [
    "<div style=\"background-color: #F8F7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<i>Primer pas</i>: Crear dues llistes. Una amb els textos i una altra amb les etiquetes de valoració (0 i 1).\n",
    "\n",
    "<b>Sortida esperada:</b> Llista de les 3 primeres opinions.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ec874492",
   "metadata": {
    "id": "ec874492"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "yeah i watched this mini series with my mom and dad as a kid. it was one of the few mini series that my 9 year old mind actually could follow. i recall it was very well done and did not necessarily have the feel of the typical crap mini series. it was more or less an original concept that really grabbed your attention. i would recommend this miniseries to anyone who is a fan of history and plot twists. although most twists in this movie are either spelled out or predictable it is still worth the time. i have not checked to see if you can get it through netflix yet however. i would imagine not. they should play it on the history channel or something.\n",
      "\n",
      "i was initially forced to attend by my wife as she is fascinated by the royal families of britain and their history and she will not go to the cinema without me. although viewers should not expect to be electrified this film is very well made and the visual aspect is second to none. in many ways it helps dispel the myth that victoria was the miserable unsmiling dumpy woman usually seen in photographs. she was a bright intelligent and according to the history of her early years a fun loving happy young woman. her love of albert was the essence of true love and even if you only count the number of children she bore 9 they must have had a passionate relationship. all of this is well borne out in the film. to this end the cast has been well selected with both emily blunt and rupert friend giving sound performances as victoria and albert. spoiler alert the historical accuracy is somewhat questionable as at no time did prince albert get shot while defending victoria. there was at least one assassination attempt when they were out together but nobody was struck by the shot/s. i also found it odd that little was done to expand on the allegedly intimate relationship between victoria's mother and sir john conroy. it is quite likely that this relationship was the true reason for victoria's distaste for both her mother and conroy. i also found it odd that there was an attempt to portray the relationship between victoria and lord melbourne as erring on the romantic or at least having the potential to become romantic. he was already in his late 50's when victoria came to the throne and while marriages between older men and young women were common in that era the movie portrays melbourne as being a dashing 30 something and rival to prince albert. there were apparently rivals to albert but she could never have married even slightly below her station in life and albert was one of only a handful who would have been acceptable in any case.all in all i have spent worse times at the cinema and brownie points with my wife cannot be a bad thing either.\n",
      "\n",
      "this work is striking in its accurate depiction of teenage life at the time of its execution. though this is a broad generalization parents of that time were too self absorbed to be real parents and those who were home tended to be far too distracted from the real issues where their children were concerned. this film teaches us how to let go even when it is painful and does so with a sweet melancholy but informed style whereby foster talks philosophically about feeling the pain of life. i loved that scene. it was my favorite scene in the movie actually.the transition from funeral to wedding was meant to show that life does go on and so must we. baio's skateboarding through a pack of goons and outrunning them was meant to show us that the troubled times will pass and we are meant to get through them to better times.the whole metaphor of moving on and the procession of life is present throughout the film and serves to give us hope in the end.i like this movie though i do not watch it often as it tends to make me melancholy.it should not be viewed by young children and probably only those raised in the 1970's 80's would want to.it rates a 7.4/10 from...the fiend :.\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# SOLUCIÓ                                   #\n",
    "#############################################\n",
    "\n",
    "texts = df['text'].tolist()\n",
    "labels = df['Positive'].tolist()\n",
    "\n",
    "for opinion in texts[:3]:\n",
    "    print(f'\\n{opinion}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9720bc32",
   "metadata": {
    "id": "9720bc32"
   },
   "source": [
    "<div style=\"background-color: #F8F7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<i>Segon pas</i>: Vectoritzar les opinions amb un vectoritzador tf.idf. Usar 'word' com a analyzer.\n",
    "<br>\n",
    "\n",
    "<b>Sortida esperada:</b> Imprimir la matriu dels vectors correpsonents a les primeres 5 opinions.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9fbcfdd4",
   "metadata": {
    "id": "9fbcfdd4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>00015</th>\n",
       "      <th>001</th>\n",
       "      <th>007</th>\n",
       "      <th>007s</th>\n",
       "      <th>0080</th>\n",
       "      <th>0083</th>\n",
       "      <th>009</th>\n",
       "      <th>00am</th>\n",
       "      <th>...</th>\n",
       "      <th>émigrés</th>\n",
       "      <th>état</th>\n",
       "      <th>étienne</th>\n",
       "      <th>étoile</th>\n",
       "      <th>óli</th>\n",
       "      <th>önsjön</th>\n",
       "      <th>über</th>\n",
       "      <th>üvegtigris</th>\n",
       "      <th>þór</th>\n",
       "      <th>żmijewski</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46443 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000  00015  001  007  007s  0080  0083  009  00am  ...  émigrés  état  \\\n",
       "0  0.0  0.0    0.0  0.0  0.0   0.0   0.0   0.0  0.0   0.0  ...      0.0   0.0   \n",
       "1  0.0  0.0    0.0  0.0  0.0   0.0   0.0   0.0  0.0   0.0  ...      0.0   0.0   \n",
       "2  0.0  0.0    0.0  0.0  0.0   0.0   0.0   0.0  0.0   0.0  ...      0.0   0.0   \n",
       "3  0.0  0.0    0.0  0.0  0.0   0.0   0.0   0.0  0.0   0.0  ...      0.0   0.0   \n",
       "4  0.0  0.0    0.0  0.0  0.0   0.0   0.0   0.0  0.0   0.0  ...      0.0   0.0   \n",
       "\n",
       "   étienne  étoile  óli  önsjön  über  üvegtigris  þór  żmijewski  \n",
       "0      0.0     0.0  0.0     0.0   0.0         0.0  0.0        0.0  \n",
       "1      0.0     0.0  0.0     0.0   0.0         0.0  0.0        0.0  \n",
       "2      0.0     0.0  0.0     0.0   0.0         0.0  0.0        0.0  \n",
       "3      0.0     0.0  0.0     0.0   0.0         0.0  0.0        0.0  \n",
       "4      0.0     0.0  0.0     0.0   0.0         0.0  0.0        0.0  \n",
       "\n",
       "[5 rows x 46443 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################################\n",
    "# SOLUCIÓ                                   #\n",
    "#############################################\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer='word')\n",
    "tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "tfidf_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3122e026",
   "metadata": {
    "id": "3122e026"
   },
   "source": [
    "<div style=\"background-color: #F8F7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<i>Tercer pas</i>: Preparar el corpus d'entrenament i avaluació, i entrenar el classificador amb Logistic Regression.\n",
    "<br>\n",
    "<b>Sortida esperada:</b> Temps d'execució que comporta fer l'entrenament (fit()).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0b251acc",
   "metadata": {
    "id": "0b251acc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'execució per a l'entrenament: 1.2823 segons\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "model = LogisticRegression()\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Temps d'execució per a l'entrenament: {execution_time:.4f} segons\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c78a34d",
   "metadata": {
    "id": "8c78a34d"
   },
   "source": [
    "<div style=\"background-color: #F8F7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<i>Quart pas</i>: Utilitzar el model entrenat per predir la categoria 1 (positiu) o 0 (negatiu) de les opinions del conjunt de test i mostrar les paraules més informatives per a cada categoria.\n",
    "<br>\n",
    "<b>Sortida esperada:</b> Llista de les 10 paraules més informatives de cada categoria.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "160fc014",
   "metadata": {
    "id": "160fc014"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paraules més negatives:\n",
      "bad: -5.1729\n",
      "worst: -4.5954\n",
      "awful: -3.6089\n",
      "boring: -3.4134\n",
      "no: -3.3310\n",
      "waste: -3.1437\n",
      "terrible: -3.1001\n",
      "stupid: -2.8504\n",
      "poor: -2.7563\n",
      "even: -2.7477\n",
      "\n",
      "Paraules més positives:\n",
      "great: 5.7687\n",
      "excellent: 3.3523\n",
      "best: 3.2279\n",
      "well: 3.0849\n",
      "and: 2.9277\n",
      "love: 2.5109\n",
      "wonderful: 2.5008\n",
      "amazing: 2.4633\n",
      "it: 2.3196\n",
      "also: 2.1701\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "coefs_with_fns = sorted(zip(model.coef_[0], feature_names))\n",
    "\n",
    "# Les 10 paraules més negatives\n",
    "top_negative_words = coefs_with_fns[:10]\n",
    "# Les 10 paraules més positives\n",
    "top_positive_words = coefs_with_fns[-10:]\n",
    "\n",
    "print(\"Paraules més negatives:\")\n",
    "for coef, word in top_negative_words:\n",
    "    print(f\"{word}: {coef:.4f}\")\n",
    "\n",
    "print(\"\\nParaules més positives:\")\n",
    "for coef, word in reversed(top_positive_words):\n",
    "    print(f\"{word}: {coef:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af23001",
   "metadata": {
    "id": "4af23001"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "    \n",
    "<strong>Exercici 4.1.2:</strong> Identificar sobre quins aspectes es fan valoracions negatives.\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "<b>Passos a seguir: </b>\n",
    "\n",
    "1. Triar dues paraules més informatives de la categoria 0 i un conjunt d'opinions en què apareguin aquestes paraules. Preprocessar les opinions traient els caràcters de salt de línia.\n",
    "2. Utilitzar el diccionari d'opinions (arxiu AFINN-111) per extreure la polaritat de cada opinió com a mitjana dels valors de les opinion words del text.\n",
    "3. Seleccionar opinions amb polaritat negativa que exemplifiquin els aspectes més mal valorats. Comenta quins són aquests aspectes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8eb0943",
   "metadata": {
    "id": "d8eb0943"
   },
   "source": [
    "<div style=\"background-color: #F8F7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<i>Primer pas</i>: Triar dues paraules més informatives de la categoria 0 i un conjunt d'opinions en què apareguin aquestes paraules. Preprocessar les opinions traient els caràcters de salt de línia.\n",
    "<br>\n",
    "<b>Sortida esperada:</b> Llista de les 3 primeres opinions en què apareguin els termes seleccionats.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7eb6ab69",
   "metadata": {
    "id": "7eb6ab69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les dues paraules seleccionades son:\n",
      "bad\n",
      "worst\n",
      "\n",
      "\n",
      "3 primeres opinions amb paraules seleccionades:\n",
      "\n",
      "I was initially forced to attend by my wife as she is fascinated by the Royal families of Britain and their history, and she won't go to the cinema without me. Although viewers shouldn't expect to be electrified, this film is very well made and the visual aspect is second to none. In many ways it helps dispel the myth that Victoria was the miserable unsmiling dumpy woman usually seen in photographs. She was a bright intelligent and according to the history of her early years, a fun loving happy young woman. Her love of Albert was the essence of true love, and even if you only count the number of children she bore (9), they must have had a passionate relationship. All of this is well borne out in the film. To this end, the cast has been well selected with both Emily Blunt and Rupert Friend giving sound performances as Victoria and Albert.<br /><br />(SPOILER ALERT) The historical accuracy is somewhat questionable as at no time did Prince Albert get shot while defending Victoria. There was at least one assassination attempt when they were out together, but nobody was struck by the shot/s. I also found it odd that little was done to expand on the allegedly intimate relationship between Victoria's mother and Sir John Conroy. It is quite likely that this relationship was the true reason for Victoria's distaste for both her mother and Conroy. I also found it odd that there was an attempt to portray the relationship between Victoria and Lord Melbourne as erring on the romantic, or at least having the potential to become romantic. He was already in his late 50's when Victoria came to the throne, and while marriages between older men and young women were common in that era, the movie portrays Melbourne as being a dashing 30 something and rival to Prince Albert. There were apparently rivals to Albert, but she could never have married even slightly below her station in life, and Albert was one of only a handful who would have been acceptable in any case.<br /><br />All in all I have spent worse times at the cinema, and brownie points with my wife can't be a bad thing either.\n",
      "\n",
      "\n",
      "\"Atlantis: The Lost Empire\" was everything the previews indicated it would be. It is not often you find that. Most of the time, the previews show only the best parts and then the rest of the movie is terrible. Not so with this one. I was pleased with the original plot, even though the sub-plots were not. The animation was not break through like \"Shrek\" but it was good, none the less. The plot and the story line were well presented and there were only a few slow spots in them. This keeps you interested. I found myself enjoying this one. \"Atlantis\" gets and keeps your attention. You also have to think a little bit, but not too much. Once you think about it a little, you can figure out what needs to happen but you really don't know for sure how it is going to happen.<br /><br />The casting was also good. Michael J. Fox, as Milo was an excellent choice. His personality fits nicely. The gruff natured Commander Rourke was also well chosen with James Garner. His character reminded me of his performance in \"Maverick\" which I also liked. I really liked the casting of Claudia Christian as Helga Sinclair. Her ability to play a no nonsense personality makes the film more interesting. It's just too bad she is a villain.<br /><br />Over all, definitely worth you while (8 out of 10).\n",
      "\n",
      "\n",
      "Just like most people, I couldn't wait to see this Ocean's 11 sequel but it really stinks, I must say. It stinks because there's simply no good screenplay,it was just cheap. I hope the producers donate all the money this movie has made (or will make) to the tsunami-victims in Asia so this movie will have at least one good reason to exist. It is so bad I even can't write a decent comment about it but....i still advise the creators of this thing to make \"Ocean's 13\". Ocean's 13 will be about the same thieves who are trying to steal a screenplay well hidden somewhere in Hollywood. The 13th member will be a foreign (maybe,Russian) screenplay-writer who knows all tricks to write a copy of this well hidden screenplay, so they can replace the original they'll have to steal. Or they need to find at least 13 people to write a decent screenplay for a movie in which not only Julia Roberts plays herself but even all other star-members of the Ocean's-films. 13 People because it's the lucky number of Andy Garcia's character.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# SOLUCIÓ                                   #\n",
    "#############################################\n",
    "\n",
    "# Seleccionar\n",
    "selected_words = [word for _, word in top_negative_words[:2]]\n",
    "print(\"Les dues paraules seleccionades son:\")\n",
    "for word in selected_words[:2]:\n",
    "    print(word)\n",
    "\n",
    "print(\"\\n\")\n",
    "# Trobar opinions\n",
    "selected_reviews = []\n",
    "for review in df['review']:\n",
    "    if any(word in review for word in selected_words):\n",
    "        processed_review = review.replace('\\n', ' ')  # Eliminar salts de línia\n",
    "        selected_reviews.append(processed_review)\n",
    "\n",
    "print(\"3 primeres opinions amb paraules seleccionades:\\n\")\n",
    "for review in selected_reviews[:3]:\n",
    "    print(review)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c24dbb",
   "metadata": {
    "id": "b5c24dbb"
   },
   "source": [
    "<div style=\"background-color: #F8F7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<i>Segon pas</i>: Utilitzar el diccionari d'opinions (arxiu AFINN-111) per extreure la polaritat de cada opinió com la mitjana dels valors de les opinion words del text.\n",
    "<br>\n",
    "<b>Sortida esperada:</b> Llista de les 3 primeres opionions i la respectiva puntuació de polaritat.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "895f6b09",
   "metadata": {
    "id": "895f6b09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opinions i puntuacions de polaritat:\n",
      "\n",
      "Opinió: I was initially forced to attend by my wife as she is fascinated by the Royal families of Britain and their history, and she won't go to the cinema without me. Although viewers shouldn't expect to be electrified, this film is very well made and the visual aspect is second to none. In many ways it helps dispel the myth that Victoria was the miserable unsmiling dumpy woman usually seen in photographs. She was a bright intelligent and according to the history of her early years, a fun loving happy young woman. Her love of Albert was the essence of true love, and even if you only count the number of children she bore (9), they must have had a passionate relationship. All of this is well borne out in the film. To this end, the cast has been well selected with both Emily Blunt and Rupert Friend giving sound performances as Victoria and Albert.<br /><br />(SPOILER ALERT) The historical accuracy is somewhat questionable as at no time did Prince Albert get shot while defending Victoria. There was at least one assassination attempt when they were out together, but nobody was struck by the shot/s. I also found it odd that little was done to expand on the allegedly intimate relationship between Victoria's mother and Sir John Conroy. It is quite likely that this relationship was the true reason for Victoria's distaste for both her mother and Conroy. I also found it odd that there was an attempt to portray the relationship between Victoria and Lord Melbourne as erring on the romantic, or at least having the potential to become romantic. He was already in his late 50's when Victoria came to the throne, and while marriages between older men and young women were common in that era, the movie portrays Melbourne as being a dashing 30 something and rival to Prince Albert. There were apparently rivals to Albert, but she could never have married even slightly below her station in life, and Albert was one of only a handful who would have been acceptable in any case.<br /><br />All in all I have spent worse times at the cinema, and brownie points with my wife can't be a bad thing either.\n",
      "Puntuació de Polaritat: 3\n",
      "--------------------------------------------------------------------------------\n",
      "Opinió: \"Atlantis: The Lost Empire\" was everything the previews indicated it would be. It is not often you find that. Most of the time, the previews show only the best parts and then the rest of the movie is terrible. Not so with this one. I was pleased with the original plot, even though the sub-plots were not. The animation was not break through like \"Shrek\" but it was good, none the less. The plot and the story line were well presented and there were only a few slow spots in them. This keeps you interested. I found myself enjoying this one. \"Atlantis\" gets and keeps your attention. You also have to think a little bit, but not too much. Once you think about it a little, you can figure out what needs to happen but you really don't know for sure how it is going to happen.<br /><br />The casting was also good. Michael J. Fox, as Milo was an excellent choice. His personality fits nicely. The gruff natured Commander Rourke was also well chosen with James Garner. His character reminded me of his performance in \"Maverick\" which I also liked. I really liked the casting of Claudia Christian as Helga Sinclair. Her ability to play a no nonsense personality makes the film more interesting. It's just too bad she is a villain.<br /><br />Over all, definitely worth you while (8 out of 10).\n",
      "Puntuació de Polaritat: 10\n",
      "--------------------------------------------------------------------------------\n",
      "Opinió: Just like most people, I couldn't wait to see this Ocean's 11 sequel but it really stinks, I must say. It stinks because there's simply no good screenplay,it was just cheap. I hope the producers donate all the money this movie has made (or will make) to the tsunami-victims in Asia so this movie will have at least one good reason to exist. It is so bad I even can't write a decent comment about it but....i still advise the creators of this thing to make \"Ocean's 13\". Ocean's 13 will be about the same thieves who are trying to steal a screenplay well hidden somewhere in Hollywood. The 13th member will be a foreign (maybe,Russian) screenplay-writer who knows all tricks to write a copy of this well hidden screenplay, so they can replace the original they'll have to steal. Or they need to find at least 13 people to write a decent screenplay for a movie in which not only Julia Roberts plays herself but even all other star-members of the Ocean's-films. 13 People because it's the lucky number of Andy Garcia's character.\n",
      "Puntuació de Polaritat: 7\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# SOLUCIÓ                                   #\n",
    "#############################################\n",
    "\n",
    "afinn_scores = {}\n",
    "with open(\"AFINN-111.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        term, score = line.split(\"\\t\")\n",
    "        afinn_scores[term] = int(score)\n",
    "\n",
    "def calculate_sentiment_sum(review):\n",
    "    words = review.lower().split()\n",
    "    scores = [afinn_scores.get(word, 0) for word in words]\n",
    "    return sum(scores)\n",
    "\n",
    "review_sentiments = [(review, calculate_sentiment_sum(review)) for review in selected_reviews]\n",
    "\n",
    "print(\"Opinions i puntuacions de polaritat:\\n\")\n",
    "for review, sentiment in review_sentiments[:3]:\n",
    "    print(f\"Opinió: {review}\\nPuntuació de Polaritat: {sentiment}\\n{'-'*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1561cfe1",
   "metadata": {
    "id": "1561cfe1"
   },
   "source": [
    "<div style=\"background-color: #F8F7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<i>Tercer pas:</i> Seleccionar opinions amb polaritat negativa que exemplifiquin els aspectes pitjor valorats (utilitzar un llindar per seleccionar les pitjors ressenyes). Comenta quins són aquests aspectes.\n",
    "<br>\n",
    "<b>Sortida esperada: </b>\n",
    "<br>\n",
    "- Llista de les tres primeres opinions negatives.\n",
    "<br>\n",
    "- Resposta a la pregunta Quins són els aspectes més mal valorats pels clients?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "412f2bf5",
   "metadata": {
    "id": "412f2bf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opinió:\n",
      "This is quite possibly THE worst movie I have ever seen. Again I made the mistake of buying the movie because the synapse on the back sounded cool and the front cover looked pretty cool too (After buying this and the movie \"Malevolence\" which I reviewed on here as well, I have learned my lesson). I love horror movies that take place in the woods or in the desert or on a farm. This supposedly takes place in the woods of Texas but was probably filmed in the director's backyard. The production was probably the worst I ever seen. The actors were absolutely the WORST. The story didn't have anything to do with what the back cover said. I even tried to sell it to F.Y.E and some other \"mom and pop\" store that buys used DVDs and neither would take it. Thats how awful this poor miserable excuse for a movie was. I have seen some bad movies before (Troll 2 for example) but this definitely takes the cake. I didn't think there was a worse movie than \"Troll 2\". Boy was I wrong! Do not buy this movie unless someone hands it to you for free but even than your stuck with it unless you throw it out which is what I am about to do!!!!\n",
      "Puntuació de Polaritat: -18\n",
      "--------------------------------------------------------------------------------\n",
      "Opinió:\n",
      "bad acting , combats are very awful , 3-4 second between each text , bad music , bad effect and always the same plan during the movie. if you want laugh go it 2/10 ( for the fool laugh)\n",
      "Puntuació de Polaritat: -13\n",
      "--------------------------------------------------------------------------------\n",
      "Opinió:\n",
      "This is quite possibly the worst Christmas film ever. The plot is virtually non-existent, the acting (Affleck in particular) is poor at best. Ben Affleck fans will probably defend this film but deep down they must agree. As far as I could gather the plot consisted of Ben Affleck, a millionaire salesman, is told by a shrink to go to a place that reminds him of his childhood and burn a list of things he wanted to forget from his childhood. On doing this he ends up paying the family currently living in the house to be his family for Christmas... and that is it. The film goes on and eventually he gets together with the daughter of the family.... blah blah blah.\n",
      "Puntuació de Polaritat: -10\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# SOLUCIÓ                                   #\n",
    "#############################################\n",
    "\n",
    "llindar_negatiu = -2\n",
    "\n",
    "\n",
    "opinions_negatives = [(review, score) for review, score in review_sentiments if score < llindar_negatiu]\n",
    "\n",
    "for review, score in opinions_negatives[:3]:\n",
    "    print(f\"Opinió:\\n{review}\\nPuntuació de Polaritat: {score}\\n{'-'*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69314cde-03a6-4828-a25b-3de337809448",
   "metadata": {},
   "source": [
    " * Actuacions i interpretacions dolentes\n",
    " * Argument/trama molt fluixa, confús o inexistent\n",
    " * Producció de qualitat tècnica molt baixa\n",
    " * Prometien més del que donen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd22b5d6-b863-4ff6-92a6-a4e35325fa38",
   "metadata": {
    "id": "fd22b5d6-b863-4ff6-92a6-a4e35325fa38"
   },
   "source": [
    "# 5. Avaluació: comparació de models i discussió de resultats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69d8d2f",
   "metadata": {
    "id": "b69d8d2f"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<strong>Exercici 5.1:</strong> Obtingueu els resultats de les mètriques d'avaluació del classificador basat en regressió logística.\n",
    "\n",
    "<b>Sortida esperada: </b> Mètriques de rediment del model de regressió logística (per classe).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "afc6ad8f",
   "metadata": {
    "id": "afc6ad8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mètriques d'avaluació del model de regressió logística:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Negativa (0)       0.87      0.84      0.86       730\n",
      "Positiva (1)       0.86      0.88      0.87       768\n",
      "\n",
      "    accuracy                           0.86      1498\n",
      "   macro avg       0.86      0.86      0.86      1498\n",
      "weighted avg       0.86      0.86      0.86      1498\n",
      "\n",
      "Matriu de confusió:\n",
      "[[616 114]\n",
      " [ 91 677]]\n"
     ]
    }
   ],
   "source": [
    "##############################################\n",
    "# SOLUCIÓ MODEL REGRESSIÓ LOGÍSTICA #\n",
    "##############################################\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_true = y_test\n",
    "\n",
    "print(\"Mètriques d'avaluació del model de regressió logística:\\n\")\n",
    "print(classification_report(y_true, y_pred, target_names=['Negativa (0)', 'Positiva (1)']))\n",
    "\n",
    "print(\"Matriu de confusió:\")\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c5988e-ce7e-4b4c-afca-023941c34fa7",
   "metadata": {
    "id": "82c5988e-ce7e-4b4c-afca-023941c34fa7"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<strong>Exercici 5.2:</strong> Obtenir també els resultats de les mètriques d'avaluació per a un classificador diferent. Per exemple, utilitzar SVM.\n",
    "<br>\n",
    "<b>Sortida esperada: </b>\n",
    "<br>\n",
    "- Temps d'execució que comporta fer l'entrenament (fit()).\n",
    "<br>\n",
    "- Mètriques de rediment del model SVM (per classe).\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "210a7df8",
   "metadata": {
    "id": "210a7df8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Temps d'entrenament del model SVM: 23.44 segons\n",
      "\n",
      "Mètriques d'avaluació del model SVM:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Negativa (0)       0.88      0.85      0.86       730\n",
      "Positiva (1)       0.86      0.89      0.88       768\n",
      "\n",
      "    accuracy                           0.87      1498\n",
      "   macro avg       0.87      0.87      0.87      1498\n",
      "weighted avg       0.87      0.87      0.87      1498\n",
      "\n",
      "Matriu de confusió:\n",
      "[[620 110]\n",
      " [ 85 683]]\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# SOLUCIÓ  MODELO SVM                       #\n",
    "#############################################\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# model SVM\n",
    "svm_model = SVC(kernel='linear')\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "svm_model.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "print(f\"\\nTemps d'entrenament del model SVM: {training_time:.2f} segons\\n\")\n",
    "\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Mètriques d'avaluació del model SVM:\\n\")\n",
    "print(classification_report(y_test, y_pred_svm, target_names=['Negativa (0)', 'Positiva (1)']))\n",
    "\n",
    "print(\"Matriu de confusió:\")\n",
    "print(confusion_matrix(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0b203a-c869-4ed2-baf8-68765ece0b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
