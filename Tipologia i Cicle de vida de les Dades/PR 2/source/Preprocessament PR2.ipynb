{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db844203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arxiu guardat com 'barcelona_compra_idealista_tags.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "\n",
    "# 1. Carregar el dataset original\n",
    "file_path = 'barcelona_compra_idealista.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# 2. Filtrar les dades\n",
    "df_train = data.dropna(subset=['tags']).copy()  # Dades amb 'tags' existents\n",
    "df_missing = data[data['tags'].isna()].copy()  # Dades amb 'tags' buits\n",
    "\n",
    "# 3. Configurar el model BERT multilingüe\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = AutoModel.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "# Funció per generar embeddings BERT\n",
    "def generate_bert_embeddings(text_list):\n",
    "    inputs = tokenizer(text_list, return_tensors='pt', padding=True, truncation=True, max_length=32)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "    return embeddings\n",
    "\n",
    "# 4. Generar embeddings per entrenament\n",
    "X_train = generate_bert_embeddings(df_train['tags'].tolist())\n",
    "y_train = df_train['tags'].tolist()\n",
    "\n",
    "# Entrenar el model KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# 5. Generar embeddings per files sense 'tags'\n",
    "if 'description' in data.columns:\n",
    "    X_missing = generate_bert_embeddings(df_missing['description'].fillna(\"empty\").tolist())\n",
    "else:\n",
    "    X_missing = generate_bert_embeddings([\"unknown\"] * len(df_missing))\n",
    "\n",
    "# Predir els tags\n",
    "predicted_tags = knn.predict(X_missing)\n",
    "\n",
    "# 6. Assignar els valors predits\n",
    "data.loc[data['tags'].isna(), 'tags'] = predicted_tags\n",
    "\n",
    "# 7. Guardar el dataset actualitzat\n",
    "data.to_csv('barcelona_compra_idealista_tags.csv', index=False)\n",
    "print(\"Arxiu guardat com 'barcelona_compra_idealista_tags.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6350afb",
   "metadata": {},
   "source": [
    "### Passos seguits per completar el procés d'assignació de valors a la columna 'tags' utilitzant embeddings BERT multilingües:\n",
    "\n",
    "1. **Càrrega del dataset original**  \n",
    "   Hem carregat el dataset `barcelona_compra_idealista.csv` per treballar amb les dades i identificar aquelles files que tenien valors buits a la columna 'tags'.\n",
    "\n",
    "2. **Filtrat de les dades**  \n",
    "   Hem dividit el dataset en dues parts:  \n",
    "   - Dades que ja contenien un valor assignat a la columna 'tags', que hem utilitzat com a conjunt d'entrenament (`df_train`).  \n",
    "   - Dades amb valors buits a la columna 'tags', que necessitaven ser omplertes (`df_missing`).\n",
    "\n",
    "3. **Configuració del model BERT multilingüe**  \n",
    "   Hem utilitzat el model `bert-base-multilingual-cased` de Hugging Face, que suporta diversos idiomes, ja que tenim text tant en català com en castellà.\n",
    "   - Hem inicialitzat el **tokenizer** per convertir el text en entrades processables pel model.  \n",
    "   - Hem carregat el **model preentrenat** per generar embeddings de les descripcions.\n",
    "\n",
    "4. **Generació d'embeddings per al conjunt d'entrenament**  \n",
    "   Hem creat una funció per generar embeddings a partir de text utilitzant el model BERT.  \n",
    "   - Hem aplicat aquesta funció al text present a la columna 'tags' del conjunt d'entrenament (`df_train`) per obtenir representacions vectorials.  \n",
    "   - Aquests embeddings s'han utilitzat com a conjunt de característiques (`X_train`), mentre que els valors originals de 'tags' s'han utilitzat com a etiquetes (`y_train`).\n",
    "\n",
    "5. **Entrenament del model KNN**  \n",
    "   Hem entrenat un classificador KNN (K-Nearest Neighbors) amb els embeddings generats i les etiquetes associades.  \n",
    "   - Hem seleccionat `n_neighbors=3` per definir el nombre de veïns a considerar en les prediccions.\n",
    "\n",
    "6. **Generació d'embeddings per a les files amb valors buits**  \n",
    "   Hem aplicat la mateixa funció d'embeddings a la columna 'description' del conjunt de dades sense valors a 'tags'.  \n",
    "   - Per evitar errors, hem substituït els valors buits de la columna 'description' per textos per defecte, com ara \"empty\" o \"unknown\".\n",
    "\n",
    "7. **Predicció dels valors de 'tags' per a les files amb valors buits**  \n",
    "   Amb el model KNN entrenat, hem predit els valors més probables de la columna 'tags' per a les files sense valor assignat (`df_missing`).\n",
    "\n",
    "8. **Assignació dels valors predits i guardat del dataset**  \n",
    "   Hem assignat els valors predits de 'tags' a les files corresponents del dataset original i hem guardat el dataset actualitzat en un fitxer CSV anomenat `barcelona_compra_idealista_tags.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f295c2f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
